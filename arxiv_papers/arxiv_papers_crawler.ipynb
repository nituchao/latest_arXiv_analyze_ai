{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef88771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdedba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://arxiv.org\"\n",
    "target_url = f\"{base_url}/list/cs.AI/new\"\n",
    "\n",
    "# 设置请求头模拟浏览器\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# 获取页面内容\n",
    "response = requests.get(target_url, headers=headers)\n",
    "\n",
    "# 检查请求是否成功\n",
    "response.raise_for_status() \n",
    "\n",
    "# 解析HTML\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60bbc250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head> <title>Artificial Intelligence  </title>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<link href=\"/static/browse/0.3.4/images/icons/apple-touch-icon.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/>\n",
       "<link href=\"/static/browse/0.3.4/images/icons/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/>\n",
       "<link href=\"/static/browse/0.3.4/images/icons/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/>\n",
       "<link href=\"/static/browse/0.3.4/images/icons/site.webmanifest\" rel=\"manifest\"/>\n",
       "<link color=\"#5bbad5\" href=\"/static/browse/0.3.4/images/icons/safari-pinned-tab.svg\" rel=\"mask-icon\"/>\n",
       "<meta content=\"#da532c\" name=\"msapplication-TileColor\"/>\n",
       "<meta content=\"#ffffff\" name=\"theme-color\"/>\n",
       "<link href=\"/static/browse/0.3.4/css/arXiv.css?v=20241206\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"/static/browse/0.3.4/css/arXiv-print.css?v=20200611\" media=\"print\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"/static/browse/0.3.4/css/browse_search.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<script language=\"javascript\" src=\"/static/browse/0.3.4/js/accordion.js\"></script>\n",
       "<script src=\"/static/browse/0.3.4/js/mathjaxToggle.min.js\" type=\"text/javascript\"></script>\n",
       "<script language=\"javascript\" type=\"text/javascript\">mathjaxToggle();</script>\n",
       "</head>\n",
       "<body class=\"with-cu-identity\">\n",
       "<div class=\"flex-wrap-footer\">\n",
       "<header>\n",
       "<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n",
       "<!-- start desktop header -->\n",
       "<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n",
       "<div class=\"column\" id=\"cu-logo\">\n",
       "<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n",
       "</div>\n",
       "<!-- /from April 7 at 1:00 AM to May 29 at 21:40 --><!-- /from May 2 at 1:00 AM to May 5 at 9:45 AM --><div class=\"column\" id=\"support-ack\">\n",
       "<span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors.</span>\n",
       "<a class=\"btn-header-donate\" href=\"https://info.arxiv.org/about/donate.html\">Donate</a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"is-hidden-mobile\" id=\"header\">\n",
       "<a aria-hidden=\"true\" href=\"/IgnoreMe\" tabindex=\"-1\"></a>\n",
       "<div class=\"header-breadcrumbs\">\n",
       "<a href=\"/\"><img alt=\"arxiv logo\" src=\"/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\" style=\"height:40px;\"/></a> <span>&gt;</span>\n",
       "<a href=\"/list/cs.AI/recent\">cs.AI</a>\n",
       "</div>\n",
       "<div class=\"search-block level-right\">\n",
       "<form action=\"https://arxiv.org/search\" class=\"level-item mini-search\" method=\"GET\">\n",
       "<div class=\"field has-addons\">\n",
       "<div class=\"control\">\n",
       "<input aria-label=\"Search term or terms\" class=\"input is-small\" name=\"query\" placeholder=\"Search...\" type=\"text\"/>\n",
       "<p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\n",
       "</div>\n",
       "<div class=\"control\">\n",
       "<div class=\"select is-small\">\n",
       "<select aria-label=\"Field to search\" name=\"searchtype\">\n",
       "<option selected=\"selected\" value=\"all\">All fields</option>\n",
       "<option value=\"title\">Title</option>\n",
       "<option value=\"author\">Author</option>\n",
       "<option value=\"abstract\">Abstract</option>\n",
       "<option value=\"comments\">Comments</option>\n",
       "<option value=\"journal_ref\">Journal reference</option>\n",
       "<option value=\"acm_class\">ACM classification</option>\n",
       "<option value=\"msc_class\">MSC classification</option>\n",
       "<option value=\"report_num\">Report number</option>\n",
       "<option value=\"paper_id\">arXiv identifier</option>\n",
       "<option value=\"doi\">DOI</option>\n",
       "<option value=\"orcid\">ORCID</option>\n",
       "<option value=\"author_id\">arXiv author ID</option>\n",
       "<option value=\"help\">Help pages</option>\n",
       "<option value=\"full_text\">Full text</option>\n",
       "</select>\n",
       "</div>\n",
       "</div>\n",
       "<input name=\"source\" type=\"hidden\" value=\"header\"/>\n",
       "<button class=\"button is-small is-cul-darker\">Search</button>\n",
       "</div>\n",
       "</form>\n",
       "</div>\n",
       "</div><!-- /end desktop header -->\n",
       "<div class=\"mobile-header\">\n",
       "<div class=\"columns is-mobile\">\n",
       "<div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img alt=\"arXiv logo\" src=\"/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" style=\"height:60px;\"/></a></div>\n",
       "<div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\n",
       "<picture>\n",
       "<source media=\"(min-width: 501px)\" sizes=\"400w\" srcset=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n",
       "<source srcset=\"/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n",
       "<img alt=\"Cornell University Logo\" src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n",
       "</picture>\n",
       "</a></div>\n",
       "<div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n",
       "<button class=\"toggle-control\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n",
       "<div class=\"mobile-toggle-block toggle-target\">\n",
       "<form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n",
       "<div class=\"field has-addons\">\n",
       "<input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\"/>\n",
       "<input name=\"source\" type=\"hidden\" value=\"header\"/>\n",
       "<input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n",
       "<button class=\"button\">GO</button>\n",
       "</div>\n",
       "</form>\n",
       "</div>\n",
       "<button class=\"toggle-control\"><svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"></path></svg></button>\n",
       "<div class=\"mobile-toggle-block toggle-target\">\n",
       "<nav aria-labelledby=\"mobilemenulabel\" class=\"mobile-menu\">\n",
       "<h2 id=\"mobilemenulabel\">quick links</h2>\n",
       "<ul>\n",
       "<li><a href=\"https://arxiv.org/login\">Login</a></li>\n",
       "<li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\n",
       "<li><a href=\"https://info.arxiv.org/about\">About</a></li>\n",
       "</ul>\n",
       "</nav>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div><!-- /end mobile-header -->\n",
       "</header>\n",
       "<main>\n",
       "<div id=\"content\">\n",
       "<div id=\"content-inner\">\n",
       "<div id=\"dlpage\">\n",
       "<h1>Artificial Intelligence</h1>\n",
       "<ul>\n",
       "<li><a href=\"#item0\">New submissions</a></li>\n",
       "<li><a href=\"#item46\">Cross-lists</a></li>\n",
       "<li><a href=\"#item183\">Replacements</a></li>\n",
       "</ul>\n",
       "<p>See <a aria-labelledby=\"recent-cs.AI\" href=\"/list/cs.AI/recent\" id=\"recent-cs.AI\">recent</a> articles</p>\n",
       "<h3>Showing new listings for Wednesday, 18 June 2025</h3>\n",
       "<div class=\"paging\">Total of 291 entries \n",
       "    </div>\n",
       "<div class=\"morefewer\">Showing up to 2000 entries per page:\n",
       "          <a href=\"/list/cs.AI/new?skip=0&amp;show=1000\" rel=\"nofollow\">\n",
       "      fewer</a>\n",
       " |\n",
       "          <span style=\"color: #454545\">more</span>\n",
       " |\n",
       "          <span style=\"color: #454545\">all</span>\n",
       "</div>\n",
       "<dl id=\"articles\">\n",
       "<h3>New submissions (showing 45 of 45 entries)</h3>\n",
       "<dt>\n",
       "<a name=\"item1\">[1]</a>\n",
       "<a href=\"/abs/2506.13768\" id=\"2506.13768\" title=\"Abstract\">\n",
       "        arXiv:2506.13768\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13768\" href=\"/pdf/2506.13768\" id=\"pdf-2506.13768\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13768\" href=\"https://arxiv.org/html/2506.13768v1\" id=\"html-2506.13768\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13768\" href=\"/format/2506.13768\" id=\"oth-2506.13768\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          'Memory States' from Almost Nothing: Representing and Computing in a Non-associative Algebra\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Reimann,+S\">Stefan Reimann</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          27 pages, 6 figures, journal article (accepted)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          This note presents a non-associative algebraic framework for the representation and computation of information items in high-dimensional space. This framework is consistent with the principles of spatial computing and with the empirical findings in cognitive science about memory. Computations are performed through a process of multiplication-like binding and non-associative interference-like bundling. Models that rely on associative bundling typically lose order information, which necessitates the use of auxiliary order structures, such as position markers, to represent sequential information that is important for cognitive tasks. In contrast, the non-associative bundling proposed allows the construction of sparse representations of arbitrarily long sequences that maintain their temporal structure across arbitrary lengths. In this operation, noise is a constituent element of the representation of order information, rather than a means of obscuring it. The non-associative nature of the proposed framework results in the representation of a single sequence by two distinct states. The L-state, generated through left-associative bundling, continuously updates and emphasises a recency effect, while the R-state, formed through right-associative bundling, encodes finite sequences or chunks, capturing a primacy effect. The construction of these states may be associated with activity in the prefrontal cortex in relation to short-term memory and hippocampal encoding in long-term memory, respectively. The accuracy of retrieval is contingent upon a decision-making process that is based on the mutual information between the memory states and the cue. The model is able to replicate the Serial Position Curve, which reflects the empirical recency and primacy effects observed in cognitive experiments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item2\">[2]</a>\n",
       "<a href=\"/abs/2506.13773\" id=\"2506.13773\" title=\"Abstract\">\n",
       "        arXiv:2506.13773\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13773\" href=\"/pdf/2506.13773\" id=\"pdf-2506.13773\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13773\" href=\"https://arxiv.org/html/2506.13773v1\" id=\"html-2506.13773\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13773\" href=\"/format/2506.13773\" id=\"oth-2506.13773\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Representing Time-Continuous Behavior of Cyber-Physical Systems in Knowledge Graphs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gill,+M+S\">Milapji Singh Gill</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jeleniewski,+T\">Tom Jeleniewski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gehlhoff,+F\">Felix Gehlhoff</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fay,+A\">Alexander Fay</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Time-continuous dynamic models are essential for various Cyber-Physical System (CPS) applications. To ensure effective usability in different lifecycle phases, such behavioral information in the form of differential equations must be contextualized and integrated with further CPS information. While knowledge graphs provide a formal description and structuring mechanism for this task, there is a lack of reusable ontological artifacts and methods to reduce manual instantiation effort. Hence, this contribution introduces two artifacts: Firstly, a modular semantic model based on standards is introduced to represent differential equations directly within knowledge graphs and to enrich them semantically. Secondly, a method for efficient knowledge graph generation is presented. A validation of these artifacts was conducted in the domain of aviation maintenance. Results show that differential equations of a complex Electro-Hydraulic Servoactuator can be formally represented in a knowledge graph and be contextualized with other lifecycle data, proving the artifacts' practical applicability.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item3\">[3]</a>\n",
       "<a href=\"/abs/2506.13774\" id=\"2506.13774\" title=\"Abstract\">\n",
       "        arXiv:2506.13774\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13774\" href=\"/pdf/2506.13774\" id=\"pdf-2506.13774\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13774\" href=\"/format/2506.13774\" id=\"oth-2506.13774\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Watson,+N\">Nell Watson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Amer,+A\">Ahmed Amer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Harris,+E\">Evan Harris</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ravindra,+P\">Preeti Ravindra</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S\">Shujun Zhang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          39 pages, 5 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Multiagent Systems (cs.MA)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Agentic AI systems, possessing capabilities for autonomous planning and action, exhibit immense potential across diverse domains. However, their practical deployment is significantly hampered by challenges in aligning their behavior with varied human values, complex safety requirements, and specific compliance needs. Existing alignment methodologies often falter when faced with the intricate task of providing deep, personalized contextual information without inducing confabulation or operational inefficiencies. This paper introduces a novel solution: a 'superego' agent, designed as a personalized oversight mechanism for agentic AI. This system dynamically steers AI planning by referencing user-selected \"Creed Constitutions\"-encapsulating diverse rule sets-with adjustable adherence levels to fit non-negotiable values. A real-time compliance enforcer validates plans against these constitutions and a universal ethical floor before execution. We present a functional system, including a demonstration interface (<a class=\"link-external link-http\" href=\"http://www.Creed.Space\" rel=\"external noopener nofollow\">this http URL</a>) with a prototypical constitution-sharing portal, and successful integration with third-party models via the Model Context Protocol (MCP). Comprehensive benchmark evaluations (HarmBench, AgentHarm) demonstrate that our Superego agent dramatically reduces harmful outputs, achieving up to a 98.3% harm score reduction and near-perfect refusal rates (e.g., 100% with Claude Sonnet 4 on AgentHarm's harmful set) for leading LLMs like Gemini 2.5 Flash and GPT-4o. This approach substantially simplifies personalized AI alignment, rendering agentic systems more reliably attuned to individual and cultural contexts, while also enabling substantial safety improvements. An overview on this research with examples is available at <a class=\"link-external link-https\" href=\"https://superego.creed.space\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item4\">[4]</a>\n",
       "<a href=\"/abs/2506.13776\" id=\"2506.13776\" title=\"Abstract\">\n",
       "        arXiv:2506.13776\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13776\" href=\"/pdf/2506.13776\" id=\"pdf-2506.13776\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13776\" href=\"https://arxiv.org/html/2506.13776v1\" id=\"html-2506.13776\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13776\" href=\"/format/2506.13776\" id=\"oth-2506.13776\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Recommendations and Reporting Checklist for Rigorous &amp; Transparent Human Baselines in Model Evaluations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wei,+K+L\">Kevin L. Wei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Paskov,+P\">Patricia Paskov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dev,+S\">Sunishchal Dev</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Byun,+M+J\">Michael J. Byun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Reuel,+A\">Anka Reuel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roberts-Gaal,+X\">Xavier Roberts-Gaal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Calcott,+R\">Rachel Calcott</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Coxon,+E\">Evie Coxon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Deshpande,+C\">Chinmay Deshpande</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          A version of this paper has been accepted to ICML 2025 as a position paper (spotlight), with the title: \"Position: Human Baselines in Model Evaluations Need Rigor and Transparency (With Recommendations &amp; Reporting Checklist).\"\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In this position paper, we argue that human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. AI performance, and we provide recommendations and a reporting checklist towards this end. Human performance baselines are vital for the machine learning community, downstream users, and policymakers to interpret AI evaluations. Models are often claimed to achieve \"super-human\" performance, but existing baselining methods are neither sufficiently rigorous nor sufficiently well-documented to robustly measure and assess performance differences. Based on a meta-review of the measurement theory and AI evaluation literatures, we derive a framework with recommendations for designing, executing, and reporting human baselines. We synthesize our recommendations into a checklist that we use to systematically review 115 human baselines (studies) in foundation model evaluations and thus identify shortcomings in existing baselining methods; our checklist can also assist researchers in conducting human baselines and reporting results. We hope our work can advance more rigorous AI evaluation practices that can better serve both the research community and policymakers. Data is available at: <a class=\"link-external link-https\" href=\"https://github.com/kevinlwei/human-baselines\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item5\">[5]</a>\n",
       "<a href=\"/abs/2506.13790\" id=\"2506.13790\" title=\"Abstract\">\n",
       "        arXiv:2506.13790\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13790\" href=\"/pdf/2506.13790\" id=\"pdf-2506.13790\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13790\" href=\"https://arxiv.org/html/2506.13790v1\" id=\"html-2506.13790\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13790\" href=\"/format/2506.13790\" id=\"oth-2506.13790\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          The NordDRG AI Benchmark for Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pitk%C3%A4ranta,+T\">Tapio Pitkäranta</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          15 pages, 4 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) are already being piloted for clinical coding and decision support. However, until now, no open benchmark has targeted the hospital funding layer where Diagnosis-Related Groups (DRG) determine reimbursement across many countries. We release NordDRG-AI-Benchmark, the first public test-bed that captures a complete DRG rule set and evaluates an LLM's ability to reason over multilingual diagnosis, procedure, and tariff logic.\n",
       "<br/>The benchmark bundles three classes of artefacts: (i) definition tables with 20 interlinked tables covering DRG logic, ICD and NCSP codes, age/sex splits, and country flags; (ii) expert manuals and changelog templates describing real governance workflows; and (iii) a prompt pack of 14 CaseMix tasks that span code lookup, cross-table inference, multilingual terminology, and quality-assurance audits.\n",
       "<br/>All artefacts are available at: <a class=\"link-external link-https\" href=\"https://github.com/longshoreforrest/norddrg-ai-benchmark\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "<br/>A baseline demonstration shows that five state-of-the-art LLMs perform very differently on the nine automatically verifiable tasks: o3 (OpenAI) scores 9 out of 9, GPT-4o and o4-mini-high score 7 out of 9, while Gemini 2.5 Pro and Gemini 2.5 Flash solve only 5 out of 9 and 3 out of 9, respectively. These results confirm that NordDRG-AI-Benchmark highlights domain-specific strengths and weaknesses that remain hidden in generic LLM benchmarks, offering a reproducible baseline for research on trustworthy automation in hospital funding.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item6\">[6]</a>\n",
       "<a href=\"/abs/2506.13792\" id=\"2506.13792\" title=\"Abstract\">\n",
       "        arXiv:2506.13792\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13792\" href=\"/pdf/2506.13792\" id=\"pdf-2506.13792\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13792\" href=\"https://arxiv.org/html/2506.13792v1\" id=\"html-2506.13792\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13792\" href=\"/format/2506.13792\" id=\"oth-2506.13792\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \\&amp; a ML Ensemble on Longitudinal Identity Resolution\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=de+Carvalho,+G+H\">Gonçalo Hora de Carvalho</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Popov,+L+S\">Lazar S. Popov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaatee,+S\">Sander Kaatee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Th%C3%B3risson,+K+R\">Kristinn R. Thórisson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+T\">Tangrui Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bj%C3%B6rnsson,+P+H\">Pétur Húni Björnsson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dibangoye,+J+S\">Jilles S. Dibangoye</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Applications (stat.AP)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We introduce ICE-ID, a novel benchmark dataset for historical identity resolution, comprising 220 years (1703-1920) of Icelandic census records. ICE-ID spans multiple generations of longitudinal data, capturing name variations, demographic changes, and rich genealogical links. To the best of our knowledge, this is the first large-scale, open tabular dataset specifically designed to study long-term person-entity matching in a real-world population. We define identity resolution tasks (within and across census waves) with clearly documented metrics and splits. We evaluate a range of methods: handcrafted rule-based matchers, a ML ensemble as well as LLMs for structured data (e.g. transformer-based tabular networks) against a novel approach to tabular data called NARS (Non-Axiomatic Reasoning System) - a general-purpose AI framework designed to reason with limited knowledge and resources. Its core is Non-Axiomatic Logic (NAL), a term-based logic. Our experiments show that NARS is suprisingly simple and competitive with other standard approaches, achieving SOTA at our task. By releasing ICE-ID and our code, we enable reproducible benchmarking of identity resolution approaches in longitudinal settings and hope that ICE-ID opens new avenues for cross-disciplinary research in data linkage and historical analytics.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item7\">[7]</a>\n",
       "<a href=\"/abs/2506.13793\" id=\"2506.13793\" title=\"Abstract\">\n",
       "        arXiv:2506.13793\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13793\" href=\"/pdf/2506.13793\" id=\"pdf-2506.13793\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13793\" href=\"https://arxiv.org/html/2506.13793v1\" id=\"html-2506.13793\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13793\" href=\"/format/2506.13793\" id=\"oth-2506.13793\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Med-REFL: Medical Reasoning Enhancement via Self-Corrected Fine-grained Reflection\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Z\">Zongxian Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qian,+J\">Jiayu Qian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+Z\">Zegao Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+H\">Haoyu Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+Z\">Zhi-An Huang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Large reasoning models have recently made significant strides in mathematical and code reasoning, yet their success has not transferred smoothly to the medical domain. While multiple factors contribute to this disparity, a critical issue is the inadequate focus on the quality of intermediate reflection steps, which is particularly crucial in high-stakes medical scenarios. To address this challenge, we propose Med-REFL, a \\underline{\\textbf{Med}}ical \\underline{\\textbf{R}}easoning \\underline{\\textbf{E}}nhancement via self-corrected \\underline{\\textbf{F}}ine-grained ref\\underline{\\textbf{L}}ection. Our method leverages a tree-of-thought approach to decompose medical questions into fine-grained reasoning paths, quantitatively evaluating each step and its subsequent reflections. These assessments enable automatic construction of direct preference optimization data, reducing reliance on expensive expert annotations while guiding models to identify and correct reasoning errors. Experimental results on the MedQA-USMLE benchmark demonstrate Med-REFL achieves consistent improvements, with average gains up to 4.11\\%. Notably, it further boosts the state-of-the-art performance of 7B/8B models by an additional 4.13\\%. Furthermore, Med-REFL exhibits strong generalization capabilities and robustness across several challenging medical question-answering datasets. Our work illustrates that prioritizing reflection quality leads to more accurate and trustworthy reasoning in medical AI applications. Checkpoints, code, and data can be found \\href{<a class=\"link-external link-https\" href=\"https://github.com/TianYin123/Med-REFL\" rel=\"external noopener nofollow\">this https URL</a>}{here}.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item8\">[8]</a>\n",
       "<a href=\"/abs/2506.13795\" id=\"2506.13795\" title=\"Abstract\">\n",
       "        arXiv:2506.13795\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13795\" href=\"/pdf/2506.13795\" id=\"pdf-2506.13795\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13795\" href=\"https://arxiv.org/html/2506.13795v1\" id=\"html-2506.13795\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13795\" href=\"/format/2506.13795\" id=\"oth-2506.13795\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          BotTrans: A Multi-Source Graph Domain Adaptation Approach for Social Bot Detection\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+B\">Boshen Shi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yongqing Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+F\">Fangda Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shao,+J\">Jiangli Shao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+H\">Huawei Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+X\">Xueqi Cheng</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accetpted to ECML-PKDD 2025 Research Track as oral; Code&amp;data: <a class=\"link-external link-https\" href=\"https://github.com/Skyorca/BotTrans\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Transferring extensive knowledge from relevant social networks has emerged as a promising solution to overcome label scarcity in detecting social bots and other anomalies with GNN-based models. However, effective transfer faces two critical challenges. Firstly, the network heterophily problem, which is caused by bots hiding malicious behaviors via indiscriminately interacting with human users, hinders the model's ability to learn sufficient and accurate bot-related knowledge from source domains. Secondly, single-source transfer might lead to inferior and unstable results, as the source network may embody weak relevance to the task and provide limited knowledge. To address these challenges, we explore multiple source domains and propose a multi-source graph domain adaptation model named \\textit{BotTrans}. We initially leverage the labeling knowledge shared across multiple source networks to establish a cross-source-domain topology with increased network homophily. We then aggregate cross-domain neighbor information to enhance the discriminability of source node embeddings. Subsequently, we integrate the relevance between each source-target pair with model optimization, which facilitates knowledge transfer from source networks that are more relevant to the detection task. Additionally, we propose a refinement strategy to improve detection performance by utilizing semantic knowledge within the target domain. Extensive experiments on real-world datasets demonstrate that \\textit{BotTrans} outperforms the existing state-of-the-art methods, revealing its efficacy in leveraging multi-source knowledge when the target detection task is unlabeled.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item9\">[9]</a>\n",
       "<a href=\"/abs/2506.13799\" id=\"2506.13799\" title=\"Abstract\">\n",
       "        arXiv:2506.13799\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13799\" href=\"/pdf/2506.13799\" id=\"pdf-2506.13799\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13799\" href=\"https://arxiv.org/html/2506.13799v1\" id=\"html-2506.13799\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13799\" href=\"/format/2506.13799\" id=\"oth-2506.13799\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Feedforward Ordering in Neural Connectomes via Feedback Arc Minimization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vahidi,+S\">Soroush Vahidi</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This is a preliminary paper\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          We present a suite of scalable algorithms for minimizing feedback arcs in large-scale weighted directed graphs, with the goal of revealing biologically meaningful feedforward structure in neural connectomes. Using the FlyWire Connectome Challenge dataset, we demonstrate the effectiveness of our ranking strategies in maximizing the total weight of forward-pointing edges. Our methods integrate greedy heuristics, gain-aware local refinements, and global structural analysis based on strongly connected components. Experiments show that our best solution improves the forward edge weight over previous top-performing methods. All algorithms are implemented efficiently in Python and validated using cloud-based execution on Google Colab Pro+.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item10\">[10]</a>\n",
       "<a href=\"/abs/2506.13803\" id=\"2506.13803\" title=\"Abstract\">\n",
       "        arXiv:2506.13803\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13803\" href=\"/pdf/2506.13803\" id=\"pdf-2506.13803\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13803\" href=\"https://arxiv.org/html/2506.13803v1\" id=\"html-2506.13803\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13803\" href=\"/format/2506.13803\" id=\"oth-2506.13803\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Causality in the human niche: lessons for machine learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lange,+R+D\">Richard D. Lange</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kording,+K+P\">Konrad P. Kording</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          23 pages, 2 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Humans interpret the world around them in terms of cause and effect and communicate their understanding of the world to each other in causal terms. These causal aspects of human cognition are thought to underlie humans' ability to generalize and learn efficiently in new domains, an area where current machine learning systems are weak. Building human-like causal competency into machine learning systems may facilitate the construction of effective and interpretable AI. Indeed, the machine learning community has been importing ideas on causality formalized by the Structural Causal Model (SCM) framework, which provides a rigorous formal language for many aspects of causality and has led to significant advances. However, the SCM framework fails to capture some salient aspects of human causal cognition and has likewise not yet led to advances in machine learning in certain critical areas where humans excel. We contend that the problem of causality in the ``human niche'' -- for a social, autonomous, and goal-driven agent sensing and acting in the world in which humans live -- is quite different from the kind of causality captured by SCMs. For example, everyday objects come in similar types that have similar causal properties, and so humans readily generalize knowledge of one type of object (cups) to another related type (bowls) by drawing causal analogies between objects with similar properties, but such analogies are at best awkward to express in SCMs. We explore how such causal capabilities are adaptive in, and motivated by, the human niche. By better appreciating properties of human causal cognition and, crucially, how those properties are adaptive in the niche in which humans live, we hope that future work at the intersection of machine learning and causality will leverage more human-like inductive biases to create more capable, controllable, and interpretable systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item11\">[11]</a>\n",
       "<a href=\"/abs/2506.13810\" id=\"2506.13810\" title=\"Abstract\">\n",
       "        arXiv:2506.13810\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13810\" href=\"/pdf/2506.13810\" id=\"pdf-2506.13810\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13810\" href=\"https://arxiv.org/html/2506.13810v1\" id=\"html-2506.13810\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13810\" href=\"/format/2506.13810\" id=\"oth-2506.13810\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Bridging Pattern-Aware Complexity with NP-Hard Optimization: A Unifying Framework and Empirical Study\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Saidi,+O\">Olivier Saidi</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          NP hard optimization problems like the Traveling Salesman Problem (TSP) defy efficient solutions in the worst case, yet real-world instances often exhibit exploitable patterns. We propose a novel patternaware complexity framework that quantifies and leverages structural regularities e.g., clustering, symmetry to reduce effective computational complexity across domains, including financial forecasting and LLM optimization. With rigorous definitions, theorems, and a meta learning driven solver pipeline, we introduce metrics like Pattern Utilization Efficiency (PUE) and achieve up to 79 percent solution quality gains in TSP benchmarks (22 to 2392 cities). Distinct from theoretical NP hardness, our approach offers a unified, practical lens for pattern-driven efficiency.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item12\">[12]</a>\n",
       "<a href=\"/abs/2506.13825\" id=\"2506.13825\" title=\"Abstract\">\n",
       "        arXiv:2506.13825\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13825\" href=\"/pdf/2506.13825\" id=\"pdf-2506.13825\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13825\" href=\"https://arxiv.org/html/2506.13825v1\" id=\"html-2506.13825\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13825\" href=\"/format/2506.13825\" id=\"oth-2506.13825\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=N'guessan,+G+L+R\">Gnankan Landry Regis N'guessan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Karambal,+I\">Issa Karambal</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Research on artificial consciousness lacks the equivalent of the perceptron: a small, trainable module that can be copied, benchmarked, and iteratively improved. We introduce the Reflexive Integrated Information Unit (RIIU), a recurrent cell that augments its hidden state $h$ with two additional vectors: (i) a meta-state $\\mu$ that records the cell's own causal footprint, and (ii) a broadcast buffer $B$ that exposes that footprint to the rest of the network. A sliding-window covariance and a differentiable Auto-$\\Phi$ surrogate let each RIIU maximize local information integration online. We prove that RIIUs (1) are end-to-end differentiable, (2) compose additively, and (3) perform $\\Phi$-monotone plasticity under gradient ascent. In an eight-way Grid-world, a four-layer RIIU agent restores $&gt;90\\%$ reward within 13 steps after actuator failure, twice as fast as a parameter-matched GRU, while maintaining a non-zero Auto-$\\Phi$ signal. By shrinking \"consciousness-like\" computation down to unit scale, RIIUs turn a philosophical debate into an empirical mathematical problem.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item13\">[13]</a>\n",
       "<a href=\"/abs/2506.13841\" id=\"2506.13841\" title=\"Abstract\">\n",
       "        arXiv:2506.13841\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13841\" href=\"/pdf/2506.13841\" id=\"pdf-2506.13841\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13841\" href=\"https://arxiv.org/html/2506.13841v1\" id=\"html-2506.13841\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13841\" href=\"/format/2506.13841\" id=\"oth-2506.13841\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Koda,+M\">Miho Koda</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+Y\">Yu Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+R\">Ruixian Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+M\">Mingyang Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pansare,+D\">Devesh Pansare</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Duarte,+F\">Fabio Duarte</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Santi,+P\">Paolo Santi</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advances in large language models (LLMs), particularly those enhanced through reinforced post-training, have demonstrated impressive reasoning capabilities, as exemplified by models such as OpenAI o1 and DeepSeek-R1. However, these capabilities are predominantly benchmarked on domains like mathematical problem solving and code generation -- leaving open the question of whether such reasoning skills generalize to complex, real-world scenarios. In this paper, we introduce LocationReasoner, a benchmark designed to evaluate LLMs' reasoning abilities in the context of real-world site selection, where models must identify feasible locations by reasoning over diverse and complicated spatial, environmental, and logistical constraints. The benchmark comprises over 300 carefully crafted queries of varying difficulty levels, supported by a sandbox environment with in-house tools for constraint-based location search. Extensive evaluations reveal that state-of-the-art reasoning models offer limited improvement over their non-reasoning predecessors in real-world contexts, with even the latest OpenAI o4 model failing on 30% of site selection tasks. Moreover, agentic strategies such as ReAct and Reflexion often suffer from over-reasoning, leading to worse outcomes than direct code-generation prompting. With key limitations of LLMs in holistic and non-linear reasoning highlighted, we release LocationReasoner to foster the development of LLMs and agents capable of robust, grounded reasoning in real-world decision-making tasks. Codes and data for our benchmark are available at <a class=\"link-external link-https\" href=\"https://github.com/miho-koda/LocationReasoner\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item14\">[14]</a>\n",
       "<a href=\"/abs/2506.13917\" id=\"2506.13917\" title=\"Abstract\">\n",
       "        arXiv:2506.13917\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13917\" href=\"/pdf/2506.13917\" id=\"pdf-2506.13917\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13917\" href=\"https://arxiv.org/html/2506.13917v1\" id=\"html-2506.13917\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13917\" href=\"/format/2506.13917\" id=\"oth-2506.13917\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Evaluating Explainability: A Framework for Systematic Assessment and Reporting of Explainable AI Features\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lago,+M+A\">Miguel A. Lago</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zamzmi,+G\">Ghada Zamzmi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Eich,+B\">Brandon Eich</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Delfino,+J+G\">Jana G. Delfino</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Explainability features are intended to provide insight into the internal mechanisms of an AI device, but there is a lack of evaluation techniques for assessing the quality of provided explanations. We propose a framework to assess and report explainable AI features. Our evaluation framework for AI explainability is based on four criteria: 1) Consistency quantifies the variability of explanations to similar inputs, 2) Plausibility estimates how close the explanation is to the ground truth, 3) Fidelity assesses the alignment between the explanation and the model internal mechanisms, and 4) Usefulness evaluates the impact on task performance of the explanation. Finally, we developed a scorecard for AI explainability methods that serves as a complete description and evaluation to accompany this type of algorithm. We describe these four criteria and give examples on how they can be evaluated. As a case study, we use Ablation CAM and Eigen CAM to illustrate the evaluation of explanation heatmaps on the detection of breast lesions on synthetic mammographies. The first three criteria are evaluated for clinically-relevant scenarios. Our proposed framework establishes criteria through which the quality of explanations provided by AI models can be evaluated. We intend for our framework to spark a dialogue regarding the value provided by explainability features and help improve the development and evaluation of AI-based medical devices.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item15\">[15]</a>\n",
       "<a href=\"/abs/2506.13920\" id=\"2506.13920\" title=\"Abstract\">\n",
       "        arXiv:2506.13920\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13920\" href=\"/pdf/2506.13920\" id=\"pdf-2506.13920\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13920\" href=\"https://arxiv.org/html/2506.13920v1\" id=\"html-2506.13920\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13920\" href=\"/format/2506.13920\" id=\"oth-2506.13920\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Integrating Knowledge Graphs and Bayesian Networks: A Hybrid Approach for Explainable Disease Risk Prediction\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nzomo,+M\">Mbithe Nzomo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Moodley,+D\">Deshendran Moodley</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This work has been accepted for presentation at the 49th IEEE International Conference on Computers, Software, and Applications (COMPSAC 2025). The final published version will be available via IEEE Xplore\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Multimodal electronic health record (EHR) data is useful for disease risk prediction based on medical domain knowledge. However, general medical knowledge must be adapted to specific healthcare settings and patient populations to achieve practical clinical use. Additionally, risk prediction systems must handle uncertainty from incomplete data and non-deterministic health outcomes while remaining explainable. These challenges can be alleviated by the integration of knowledge graphs (KGs) and Bayesian networks (BNs). We present a novel approach for constructing BNs from ontology-based KGs and multimodal EHR data for explainable disease risk prediction. Through an application use case of atrial fibrillation and real-world EHR data, we demonstrate that the approach balances generalised medical knowledge with patient-specific context, effectively handles uncertainty, is highly explainable, and achieves good predictive performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item16\">[16]</a>\n",
       "<a href=\"/abs/2506.13980\" id=\"2506.13980\" title=\"Abstract\">\n",
       "        arXiv:2506.13980\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13980\" href=\"/pdf/2506.13980\" id=\"pdf-2506.13980\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13980\" href=\"https://arxiv.org/html/2506.13980v1\" id=\"html-2506.13980\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13980\" href=\"/format/2506.13980\" id=\"oth-2506.13980\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ProfiLLM: An LLM-Based Framework for Implicit Profiling of Chatbot Users\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=David,+S\">Shahaf David</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Meidan,+Y\">Yair Meidan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hersko,+I\">Ido Hersko</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Varnovitzky,+D\">Daniel Varnovitzky</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mimran,+D\">Dudu Mimran</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Elovici,+Y\">Yuval Elovici</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shabtai,+A\">Asaf Shabtai</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite significant advancements in conversational AI, large language model (LLM)-powered chatbots often struggle with personalizing their responses according to individual user characteristics, such as technical expertise, learning style, and communication preferences. This lack of personalization is particularly problematic in specialized knowledge-intense domains like IT/cybersecurity (ITSec), where user knowledge levels vary widely. Existing approaches for chatbot personalization primarily rely on static user categories or explicit self-reported information, limiting their adaptability to an evolving perception of the user's proficiency, obtained in the course of ongoing interactions. In this paper, we propose ProfiLLM, a novel framework for implicit and dynamic user profiling through chatbot interactions. This framework consists of a taxonomy that can be adapted for use in diverse domains and an LLM-based method for user profiling in terms of the taxonomy. To demonstrate ProfiLLM's effectiveness, we apply it in the ITSec domain where troubleshooting interactions are used to infer chatbot users' technical proficiency. Specifically, we developed ProfiLLM[ITSec], an ITSec-adapted variant of ProfiLLM, and evaluated its performance on 1,760 human-like chatbot conversations from 263 synthetic users. Results show that ProfiLLM[ITSec] rapidly and accurately infers ITSec profiles, reducing the gap between actual and predicted scores by up to 55--65\\% after a single prompt, followed by minor fluctuations and further refinement. In addition to evaluating our new implicit and dynamic profiling framework, we also propose an LLM-based persona simulation methodology, a structured taxonomy for ITSec proficiency, our codebase, and a dataset of chatbot interactions to support future research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item17\">[17]</a>\n",
       "<a href=\"/abs/2506.13983\" id=\"2506.13983\" title=\"Abstract\">\n",
       "        arXiv:2506.13983\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13983\" href=\"/pdf/2506.13983\" id=\"pdf-2506.13983\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13983\" href=\"https://arxiv.org/html/2506.13983v1\" id=\"html-2506.13983\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13983\" href=\"/format/2506.13983\" id=\"oth-2506.13983\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta,+A\">Adarsh Gupta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mali,+B\">Bhabesh Mali</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Karfa,+C\">Chandan Karfa</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Adarsh Gupta and Bhabesh Mali contributed equally to this work\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advancements in the field of reasoning using Large Language Models (LLMs) have created new possibilities for more complex and automatic Hardware Assertion Generation techniques. This paper introduces SANGAM, a SystemVerilog Assertion Generation framework using LLM-guided Monte Carlo Tree Search for the automatic generation of SVAs from industry-level specifications. The proposed framework utilizes a three-stage approach: Stage 1 consists of multi-modal Specification Processing using Signal Mapper, SPEC Analyzer, and Waveform Analyzer LLM Agents. Stage 2 consists of using the Monte Carlo Tree Self-Refine (MCTSr) algorithm for automatic reasoning about SVAs for each signal, and finally, Stage 3 combines the MCTSr-generated reasoning traces to generate SVA assertions for each signal. The results demonstrated that our framework, SANGAM, can generate a robust set of SVAs, performing better in the evaluation process in comparison to the recent methods.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item18\">[18]</a>\n",
       "<a href=\"/abs/2506.13990\" id=\"2506.13990\" title=\"Abstract\">\n",
       "        arXiv:2506.13990\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.13990\" href=\"/pdf/2506.13990\" id=\"pdf-2506.13990\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13990\" href=\"https://arxiv.org/html/2506.13990v1\" id=\"html-2506.13990\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13990\" href=\"/format/2506.13990\" id=\"oth-2506.13990\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Machine Mirages: Defining the Undefined\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tembine,+H\">Hamidou Tembine</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Submitted\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          As multimodal machine intelligence systems started achieving average animal-level and average human-level fluency in many measurable tasks in processing images, language, and sound, they began to exhibit a new class of cognitive aberrations: machine mirages. These include delusion, illusion, confabulation, hallucination, misattribution error, semantic drift, semantic compression, exaggeration, causal inference failure, uncanny valley of perception, bluffing-patter-bullshitting, cognitive stereotypy, pragmatic misunderstanding, hypersignification, semantic reheating-warming, simulated authority effect, fallacious abductive leap, contextual drift, referential hallucination, semiotic Frankenstein effect, calibration failure, spurious correlation, bias amplification, concept drift sensitivity, misclassification under uncertainty, adversarial vulnerability, overfitting, prosodic misclassification, accent bias, turn boundary failure, semantic boundary confusion, noise overfitting, latency-induced decision drift, ambiguity collapse and other forms of error that mimic but do not replicate human or animal fallibility. This article presents some of the errors and argues that these failures must be explicitly defined and systematically assessed. Understanding machine mirages is essential not only for improving machine intelligence reliability but also for constructing a multiscale ethical, co-evolving intelligence ecosystem that respects the diverse forms of life, cognition, and expression it will inevitably touch.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item19\">[19]</a>\n",
       "<a href=\"/abs/2506.14045\" id=\"2506.14045\" title=\"Abstract\">\n",
       "        arXiv:2506.14045\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14045\" href=\"/pdf/2506.14045\" id=\"pdf-2506.14045\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14045\" href=\"/format/2506.14045\" id=\"oth-2506.14045\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Klissarov,+M\">Martin Klissarov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bagaria,+A\">Akhil Bagaria</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+Z\">Ziyan Luo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Konidaris,+G\">George Konidaris</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Precup,+D\">Doina Precup</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Machado,+M+C\">Marlos C. Machado</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Developing agents capable of exploring, planning and learning in complex open-ended environments is a grand challenge in artificial intelligence (AI). Hierarchical reinforcement learning (HRL) offers a promising solution to this challenge by discovering and exploiting the temporal structure within a stream of experience. The strong appeal of the HRL framework has led to a rich and diverse body of literature attempting to discover a useful structure. However, it is still not clear how one might define what constitutes good structure in the first place, or the kind of problems in which identifying it may be helpful. This work aims to identify the benefits of HRL from the perspective of the fundamental challenges in decision-making, as well as highlight its impact on the performance trade-offs of AI agents. Through these benefits, we then cover the families of methods that discover temporal structure in HRL, ranging from learning directly from online experience to offline datasets, to leveraging large language models (LLMs). Finally, we highlight the challenges of temporal structure discovery and the domains that are particularly well-suited for such endeavours.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item20\">[20]</a>\n",
       "<a href=\"/abs/2506.14070\" id=\"2506.14070\" title=\"Abstract\">\n",
       "        arXiv:2506.14070\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14070\" href=\"/pdf/2506.14070\" id=\"pdf-2506.14070\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14070\" href=\"https://arxiv.org/html/2506.14070v1\" id=\"html-2506.14070\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14070\" href=\"/format/2506.14070\" id=\"oth-2506.14070\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Into the Unknown: Applying Inductive Spatial-Semantic Location Embeddings for Predicting Individuals' Mobility Beyond Visited Places\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xinglei Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+T\">Tao Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Law,+S\">Stephen Law</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+Z\">Zichao Zeng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ilyankou,+I\">Ilya Ilyankou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J\">Junyuan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+L\">Lu Yin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+W\">Weiming Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jongwiriyanurak,+N\">Natchapon Jongwiriyanurak</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 5 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Predicting individuals' next locations is a core task in human mobility modelling, with wide-ranging implications for urban planning, transportation, public policy and personalised mobility services. Traditional approaches largely depend on location embeddings learned from historical mobility patterns, limiting their ability to encode explicit spatial information, integrate rich urban semantic context, and accommodate previously unseen locations. To address these challenges, we explore the application of CaLLiPer -- a multimodal representation learning framework that fuses spatial coordinates and semantic features of points of interest through contrastive learning -- for location embedding in individual mobility prediction. CaLLiPer's embeddings are spatially explicit, semantically enriched, and inductive by design, enabling robust prediction performance even in scenarios involving emerging locations. Through extensive experiments on four public mobility datasets under both conventional and inductive settings, we demonstrate that CaLLiPer consistently outperforms strong baselines, particularly excelling in inductive scenarios. Our findings highlight the potential of multimodal, inductive location embeddings to advance the capabilities of human mobility prediction systems. We also release the code and data (<a class=\"link-external link-https\" href=\"https://github.com/xlwang233/Into-the-Unknown\" rel=\"external noopener nofollow\">this https URL</a>) to foster reproducibility and future research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item21\">[21]</a>\n",
       "<a href=\"/abs/2506.14079\" id=\"2506.14079\" title=\"Abstract\">\n",
       "        arXiv:2506.14079\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14079\" href=\"/pdf/2506.14079\" id=\"pdf-2506.14079\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14079\" href=\"https://arxiv.org/html/2506.14079v1\" id=\"html-2506.14079\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14079\" href=\"/format/2506.14079\" id=\"oth-2506.14079\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          FormGym: Doing Paperwork with Agents\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toles,+M\">Matthew Toles</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+R\">Rattandeep Singh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+I+S+Z\">Isaac Song Zhou Yu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Completing paperwork is a challenging and time-consuming problem. Form filling is especially challenging in the pure-image domain without access to OCR, typeset PDF text, or a DOM. For computer agents, it requires multiple abilities, including multi-modal understanding, information retrieval, and tool-use. We present a novel form-filling benchmark consisting of 432 fields spread across 55 documents and 3 tasks, requiring knowledge of 236 features per user. We find that baseline VLAs achieve less than 1% accuracy in most cases, primarily due to poor localization ability. GUI agents also struggle, scoring between 10.6-68.0% despite high cost and latency. Therefore, we also contribute FieldFinder, a tool to assist LLMs in identifying where to place text on a form. With FieldFinder, all models achieve equal or better performance in all six study conditions, with a maximum increase from 2% to 56%.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item22\">[22]</a>\n",
       "<a href=\"/abs/2506.14084\" id=\"2506.14084\" title=\"Abstract\">\n",
       "        arXiv:2506.14084\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14084\" href=\"/pdf/2506.14084\" id=\"pdf-2506.14084\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14084\" href=\"https://arxiv.org/html/2506.14084v1\" id=\"html-2506.14084\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14084\" href=\"/format/2506.14084\" id=\"oth-2506.14084\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Lightweight Relevance Grader in RAG\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jeong,+T\">Taehee Jeong</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Retrieval-Augmented Generation (RAG) addresses limitations of large language models (LLMs) by leveraging a vector database to provide more accurate and up-to-date information. When a user submits a query, RAG executes a vector search to find relevant documents, which are then used to generate a response. However, ensuring the relevance of retrieved documents with a query would be a big challenge. To address this, a secondary model, known as a relevant grader, can be served to verify its relevance. To reduce computational requirements of a relevant grader, a lightweight small language model is preferred. In this work, we finetuned llama-3.2-1b as a relevant grader and achieved a significant increase in precision from 0.1301 to 0.7750. Its precision is comparable to that of llama-3.1-70b. Our code is available at <a class=\"link-external link-https\" href=\"https://github.com/taeheej/Lightweight-Relevance-Grader-in-RAG\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item23\">[23]</a>\n",
       "<a href=\"/abs/2506.14092\" id=\"2506.14092\" title=\"Abstract\">\n",
       "        arXiv:2506.14092\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14092\" href=\"/pdf/2506.14092\" id=\"pdf-2506.14092\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14092\" href=\"https://arxiv.org/html/2506.14092v1\" id=\"html-2506.14092\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14092\" href=\"/format/2506.14092\" id=\"oth-2506.14092\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Fragile Preferences: A Deep Dive Into Order Effects in Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+H\">Haonan Yin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vardi,+S\">Shai Vardi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Choudhary,+V\">Vidyanand Choudhary</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) are increasingly used in decision-support systems across high-stakes domains such as hiring and university admissions, where decisions often involve selecting among competing alternatives. While prior work has noted positional order biases in LLM-driven comparisons, these biases have not been systematically dissected or linked to underlying preference structures. We provide the first comprehensive investigation of positional biases across multiple LLM architectures and domains, uncovering strong and consistent order effects, including a novel centrality bias not previously documented in human or machine decision-making. We also find a quality-dependent shift: when options are high quality, models exhibit primacy bias, but favor latter options when option quality is low. We further identify a previously undocumented bias favoring certain names over others. To distinguish superficial tie-breaking from true distortions of judgment, we introduce a framework that classifies pairwise preferences as robust, fragile, or indifferent. We show that order effects can lead models to select strictly inferior options, and that positional biases are typically stronger than gender biases. These findings suggest that LLMs are not merely inheriting human-like biases, but exhibit distinct failure modes not seen in human decision-making. We propose targeted mitigation strategies, including a novel use of the temperature parameter, to reduce order-driven distortions.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item24\">[24]</a>\n",
       "<a href=\"/abs/2506.14125\" id=\"2506.14125\" title=\"Abstract\">\n",
       "        arXiv:2506.14125\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14125\" href=\"/pdf/2506.14125\" id=\"pdf-2506.14125\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14125\" href=\"https://arxiv.org/html/2506.14125v1\" id=\"html-2506.14125\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14125\" href=\"/format/2506.14125\" id=\"oth-2506.14125\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Situational-Constrained Sequential Resources Allocation via Reinforcement Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+L\">Libo Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Y\">Yang Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Takisaka,+T\">Toru Takisaka</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+K\">Kaiqi Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+W\">Weidong Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J\">Jiamou Liu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Sequential Resource Allocation with situational constraints presents a significant challenge in real-world applications, where resource demands and priorities are context-dependent. This paper introduces a novel framework, SCRL, to address this problem. We formalize situational constraints as logic implications and develop a new algorithm that dynamically penalizes constraint violations. To handle situational constraints effectively, we propose a probabilistic selection mechanism to overcome limitations of traditional constraint reinforcement learning (CRL) approaches. We evaluate SCRL across two scenarios: medical resource allocation during a pandemic and pesticide distribution in agriculture. Experiments demonstrate that SCRL outperforms existing baselines in satisfying constraints while maintaining high resource efficiency, showcasing its potential for real-world, context-sensitive decision-making tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item25\">[25]</a>\n",
       "<a href=\"/abs/2506.14146\" id=\"2506.14146\" title=\"Abstract\">\n",
       "        arXiv:2506.14146\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14146\" href=\"/pdf/2506.14146\" id=\"pdf-2506.14146\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14146\" href=\"https://arxiv.org/html/2506.14146v1\" id=\"html-2506.14146\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14146\" href=\"/format/2506.14146\" id=\"oth-2506.14146\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Collaborative Editable Model\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+K\">Kaiwen Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+A\">Aitong Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yao Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+G\">Guangda Sun</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Vertical-domain large language models (LLMs) play a crucial role in specialized scenarios such as finance, healthcare, and law; however, their training often relies on large-scale annotated data and substantial computational resources, impeding rapid development and continuous iteration. To address these challenges, we introduce the Collaborative Editable Model (CoEM), which constructs a candidate knowledge pool from user-contributed domain snippets, leverages interactive user-model dialogues combined with user ratings and attribution analysis to pinpoint high-value knowledge fragments, and injects these fragments via in-context prompts for lightweight domain adaptation. With high-value knowledge, the LLM can generate more accurate and domain-specific content. In a financial information scenario, we collect 15k feedback from about 120 users and validate CoEM with user ratings to assess the quality of generated insights, demonstrating significant improvements in domain-specific generation while avoiding the time and compute overhead of traditional fine-tuning workflows.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item26\">[26]</a>\n",
       "<a href=\"/abs/2506.14212\" id=\"2506.14212\" title=\"Abstract\">\n",
       "        arXiv:2506.14212\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14212\" href=\"/pdf/2506.14212\" id=\"pdf-2506.14212\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14212\" href=\"https://arxiv.org/html/2506.14212v1\" id=\"html-2506.14212\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14212\" href=\"/format/2506.14212\" id=\"oth-2506.14212\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          What's in the Box? Reasoning about Unseen Objects from Multimodal Cues\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ying,+L\">Lance Ying</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+D\">Daniel Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+A\">Alicia Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Collins,+K+M\">Katherine M. Collins</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Siegel,+M+H\">Max H. Siegel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tenenbaum,+J+B\">Joshua B. Tenenbaum</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Paper published at CogSci 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          People regularly make inferences about objects in the world that they cannot see by flexibly integrating information from multiple sources: auditory and visual cues, language, and our prior beliefs and knowledge about the scene. How are we able to so flexibly integrate many sources of information to make sense of the world around us, even if we have no direct knowledge? In this work, we propose a neurosymbolic model that uses neural networks to parse open-ended multimodal inputs and then applies a Bayesian model to integrate different sources of information to evaluate different hypotheses. We evaluate our model with a novel object guessing game called ``What's in the Box?'' where humans and models watch a video clip of an experimenter shaking boxes and then try to guess the objects inside the boxes. Through a human experiment, we show that our model correlates strongly with human judgments, whereas unimodal ablated models and large multimodal neural model baselines show poor correlation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item27\">[27]</a>\n",
       "<a href=\"/abs/2506.14224\" id=\"2506.14224\" title=\"Abstract\">\n",
       "        arXiv:2506.14224\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14224\" href=\"/pdf/2506.14224\" id=\"pdf-2506.14224\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14224\" href=\"https://arxiv.org/html/2506.14224v1\" id=\"html-2506.14224\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14224\" href=\"/format/2506.14224\" id=\"oth-2506.14224\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+X\">Xinyang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Siqi Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zou,+B\">Bochao Zou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jiansheng Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+H\">Huimin Ma</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          24 pages, 22 figures, accepted at ICML 2025, project page: see <a class=\"link-external link-https\" href=\"https://annaisavailable.github.io/GridToM/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          As large language models evolve, there is growing anticipation that they will emulate human-like Theory of Mind (ToM) to assist with routine tasks. However, existing methods for evaluating machine ToM focus primarily on unimodal models and largely treat these models as black boxes, lacking an interpretative exploration of their internal mechanisms. In response, this study adopts an approach based on internal mechanisms to provide an interpretability-driven assessment of ToM in multimodal large language models (MLLMs). Specifically, we first construct a multimodal ToM test dataset, GridToM, which incorporates diverse belief testing tasks and perceptual information from multiple perspectives. Next, our analysis shows that attention heads in multimodal large models can distinguish cognitive information across perspectives, providing evidence of ToM capabilities. Furthermore, we present a lightweight, training-free approach that significantly enhances the model's exhibited ToM by adjusting in the direction of the attention head.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item28\">[28]</a>\n",
       "<a href=\"/abs/2506.14231\" id=\"2506.14231\" title=\"Abstract\">\n",
       "        arXiv:2506.14231\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14231\" href=\"/pdf/2506.14231\" id=\"pdf-2506.14231\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14231\" href=\"https://arxiv.org/html/2506.14231v1\" id=\"html-2506.14231\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14231\" href=\"/format/2506.14231\" id=\"oth-2506.14231\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ImpReSS: Implicit Recommender System for Support Conversations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Haller,+O\">Omri Haller</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Meidan,+Y\">Yair Meidan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mimran,+D\">Dudu Mimran</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Elovici,+Y\">Yuval Elovici</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shabtai,+A\">Asaf Shabtai</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Following recent advancements in large language models (LLMs), LLM-based chatbots have transformed customer support by automating interactions and providing consistent, scalable service. While LLM-based conversational recommender systems (CRSs) have attracted attention for their ability to enhance the quality of recommendations, limited research has addressed the implicit integration of recommendations within customer support interactions. In this work, we introduce ImpReSS, an implicit recommender system designed for customer support conversations. ImpReSS operates alongside existing support chatbots, where users report issues and chatbots provide solutions. Based on a customer support conversation, ImpReSS identifies opportunities to recommend relevant solution product categories (SPCs) that help resolve the issue or prevent its recurrence -- thereby also supporting business growth. Unlike traditional CRSs, ImpReSS functions entirely implicitly and does not rely on any assumption of a user's purchasing intent. Our empirical evaluation of ImpReSS's ability to recommend relevant SPCs that can help address issues raised in support conversations shows promising results, including an MRR@1 (and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for information security support, and 0.85 (0.67) for cybersecurity troubleshooting. To support future research, our data and code will be shared upon request.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item29\">[29]</a>\n",
       "<a href=\"/abs/2506.14239\" id=\"2506.14239\" title=\"Abstract\">\n",
       "        arXiv:2506.14239\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14239\" href=\"/pdf/2506.14239\" id=\"pdf-2506.14239\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14239\" href=\"/format/2506.14239\" id=\"oth-2506.14239\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vervoort,+L\">Louis Vervoort</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nikolaev,+V\">Vitaly Nikolaev</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by Journal for General Philosophy of Science\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We propose a test for abstract causal reasoning in AI, based on scholarship in the philosophy of causation, in particular on the neuron diagrams popularized by D. Lewis. We illustrate the test on advanced Large Language Models (ChatGPT, DeepSeek and Gemini). Remarkably, these chatbots are already capable of correctly identifying causes in cases that are hotly debated in the literature. In order to assess the results of these LLMs and future dedicated AI, we propose a definition of cause in neuron diagrams with a wider validity than published hitherto, which challenges the widespread view that such a definition is elusive. We submit that these results are an illustration of how future philosophical research might evolve: as an interplay between human and artificial expertise.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item30\">[30]</a>\n",
       "<a href=\"/abs/2506.14245\" id=\"2506.14245\" title=\"Abstract\">\n",
       "        arXiv:2506.14245\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14245\" href=\"/pdf/2506.14245\" id=\"pdf-2506.14245\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14245\" href=\"https://arxiv.org/html/2506.14245v1\" id=\"html-2506.14245\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14245\" href=\"/format/2506.14245\" id=\"oth-2506.14245\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wen,+X\">Xumeng Wen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z\">Zihan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+S\">Shun Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Z\">Zhijian Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ye,+S\">Shengyu Ye</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Z\">Zhirong Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+X\">Xiao Liang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yang Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+J\">Junjie Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Miao,+Z\">Ziming Miao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bian,+J\">Jiang Bian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+M\">Mao Yang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Preprint\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned models often underperform their base models on the $Pass@K$ metric for solution-finding, leading to the hypothesis that RLVR merely re-weights existing reasoning paths at the cost of reasoning diversity. In this work, we resolve this contradiction by identifying the source of the problem: the $Pass@K$ metric itself is a flawed measure of reasoning, as it credits correct final answers that probably arise from inaccurate or incomplete chains of thought (CoTs). To address this, we introduce a more precise evaluation metric, $CoT$-$Pass@K$, which mandates that both the reasoning path and the final answer be correct. We provide a new theoretical foundation that formalizes how RLVR, unlike traditional RL, is uniquely structured to incentivize logical integrity. Our empirical results are supportive: using $CoT$-$Pass@K$, we observe that RLVR can incentivize the generalization of correct reasoning for all values of $K$. Furthermore, by analyzing the training dynamics, we find that this enhanced reasoning capability emerges early in the training process and smoothly generalizes. Our work provides a clear perspective on the role of RLVR, offers a more reliable method for its evaluation, and confirms its potential to genuinely advance machine reasoning.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item31\">[31]</a>\n",
       "<a href=\"/abs/2506.14246\" id=\"2506.14246\" title=\"Abstract\">\n",
       "        arXiv:2506.14246\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14246\" href=\"/pdf/2506.14246\" id=\"pdf-2506.14246\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14246\" href=\"https://arxiv.org/html/2506.14246v1\" id=\"html-2506.14246\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14246\" href=\"/format/2506.14246\" id=\"oth-2506.14246\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+L\">Lingfeng Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yunlong Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yongyi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+Q\">Qifan Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+W\">Wenxin Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          People need to internalize the skills of AI agents to improve their own capabilities. Our paper focuses on Mahjong, a multiplayer game involving imperfect information and requiring effective long-term decision-making amidst randomness and hidden information. Through the efforts of AI researchers, several impressive Mahjong AI agents have already achieved performance levels comparable to those of professional human players; however, these agents are often treated as black boxes from which few insights can be gleaned. This paper introduces Mxplainer, a parameterized search algorithm that can be converted into an equivalent neural network to learn the parameters of black-box agents. Experiments conducted on AI and human player data demonstrate that the learned parameters provide human-understandable insights into these agents' characteristics and play styles. In addition to analyzing the learned parameters, we also showcase how our search-based framework can locally explain the decision-making processes of black-box agents for most Mahjong game states.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item32\">[32]</a>\n",
       "<a href=\"/abs/2506.14276\" id=\"2506.14276\" title=\"Abstract\">\n",
       "        arXiv:2506.14276\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14276\" href=\"/pdf/2506.14276\" id=\"pdf-2506.14276\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14276\" href=\"https://arxiv.org/html/2506.14276v1\" id=\"html-2506.14276\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14276\" href=\"/format/2506.14276\" id=\"oth-2506.14276\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Don't throw the baby out with the bathwater: How and why deep learning for ARC\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cole,+J\">Jack Cole</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Osman,+M\">Mohamed Osman</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          13 pages, 6 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The Abstraction and Reasoning Corpus (ARC-AGI) presents a formidable challenge for AI systems. Despite the typically low performance on ARC, the deep learning paradigm remains the most effective known strategy for generating skillful (state-of-the-art) neural networks (NN) across varied modalities and tasks in vision, language etc. The deep learning paradigm has proven to be able to train these skillful neural networks and learn the abstractions needed in these diverse domains. Our work doubles down on that and continues to leverage this paradigm by incorporating on-the-fly NN training at test time. We demonstrate that fully committing to deep learning's capacity to acquire novel abstractions yields state-of-the-art performance on ARC. Specifically, we treat both the neural network and the optimizer (rather than just a pre-trained network) as integral components of the inference process, fostering generalization to unseen tasks. Concretely, we propose a methodology for training on ARC, starting from pretrained LLMs, and enhancing their ARC reasoning. We also propose Test-Time Fine-Tuning (TTFT) and the Augment Inference Reverse-Augmentation and Vote (AIRV) as effective test-time techniques. We are the first to propose and show deep learning can be used effectively for ARC, showing boosts of up to 260% in accuracy with AIRV and a further 300% boost with TTFT. An early version of this approach secured first place in the 2023 ARCathon competition, while the final version achieved the current best score on the ARC private test-set (58%). Our findings highlight the key ingredients of a robust reasoning system in unfamiliar domains, underscoring the central mechanisms that improve broad perceptual reasoning.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item33\">[33]</a>\n",
       "<a href=\"/abs/2506.14299\" id=\"2506.14299\" title=\"Abstract\">\n",
       "        arXiv:2506.14299\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14299\" href=\"/pdf/2506.14299\" id=\"pdf-2506.14299\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14299\" href=\"https://arxiv.org/html/2506.14299v1\" id=\"html-2506.14299\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14299\" href=\"/format/2506.14299\" id=\"oth-2506.14299\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+F\">Fanzhi Zeng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+S\">Siqi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+C\">Chuzhao Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+L\">Li Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          How to construct an interpretable autonomous driving decision-making system has become a focal point in academic research. In this study, we propose a novel approach that leverages large language models (LLMs) to generate executable, rule-based decision systems to address this challenge. Specifically, harnessing the strong reasoning and programming capabilities of LLMs, we introduce the ADRD(LLM-Driven Autonomous Driving Based on Rule-based Decision Systems) framework, which integrates three core modules: the Information Module, the Agents Module, and the Testing Module. The framework operates by first aggregating contextual driving scenario information through the Information Module, then utilizing the Agents Module to generate rule-based driving tactics. These tactics are iteratively refined through continuous interaction with the Testing Module. Extensive experimental evaluations demonstrate that ADRD exhibits superior performance in autonomous driving decision tasks. Compared to traditional reinforcement learning approaches and the most advanced LLM-based methods, ADRD shows significant advantages in terms of interpretability, response speed, and driving performance. These results highlight the framework's ability to achieve comprehensive and accurate understanding of complex driving scenarios, and underscore the promising future of transparent, rule-based decision systems that are easily modifiable and broadly applicable. To the best of our knowledge, this is the first work that integrates large language models with rule-based systems for autonomous driving decision-making, and our findings validate its potential for real-world deployment.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item34\">[34]</a>\n",
       "<a href=\"/abs/2506.14336\" id=\"2506.14336\" title=\"Abstract\">\n",
       "        arXiv:2506.14336\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14336\" href=\"/pdf/2506.14336\" id=\"pdf-2506.14336\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14336\" href=\"https://arxiv.org/html/2506.14336v1\" id=\"html-2506.14336\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14336\" href=\"/format/2506.14336\" id=\"oth-2506.14336\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AviationLLM: An LLM-based Knowledge System for Aviation Training\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wan,+J\">Jia'ang Wan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+F\">Feng Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+F\">Fujuan Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+Y\">Yanjin Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yan Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S\">Shiwen Zhang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Aviation training is a core link in ensuring flight safety, improving industry efficiency and promoting sustainable development. It not only involves flight simulation but also requires the learning of a great deal of professional aviation theory knowledge. In the existing training system, the knowledge is mainly imparted by the the instructors. However, the number of instructors is limited and the professional answers obtained from the Internet are not accurate enough, resulting in low training efficiency. To address this, we introduced LLM, but the basic pre-trained model cannot provide accurate answers to professional fields, so we fine-tuned it. Traditional Supervised Fine-Tuning (SFT) risk generating superficially plausible but factually incorrect responses due to insufficient data coverage. To address this, we employ Direct Preference Optimization(DPO). This paper proposes Retrieval-Augmented LLM Alignment via Direct Preference Optimization(RALA-DPO). We select open source pre-trained LLM Qwen and adapt it to aviation theory training through DPO-based domain alignment. Simultaneously, to mitigate hallucinations caused by training data biases, knowledge obsolescence, or domain knowledge gaps, we implement Retrieval-Augmented Generation(RAG) technology that combines generative and retrieval models. RALA-DPO effectively retrieves relevant information from external knowledge bases and delivers precise and high-quality responses through the generative model. Experimental results demonstrate that RALA-DPO can improve accuracy in response to professional aviation knowledge. With integrated RAG mechanisms, this system can further improve the accuracy of answers and achieve zero-cost knowledge updates simultaneously.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item35\">[35]</a>\n",
       "<a href=\"/abs/2506.14387\" id=\"2506.14387\" title=\"Abstract\">\n",
       "        arXiv:2506.14387\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14387\" href=\"/pdf/2506.14387\" id=\"pdf-2506.14387\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14387\" href=\"https://arxiv.org/html/2506.14387v1\" id=\"html-2506.14387\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14387\" href=\"/format/2506.14387\" id=\"oth-2506.14387\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+W+F\">William F. Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu,+X\">Xinchi Qiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cancedda,+N\">Nicola Cancedda</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lane,+N+D\">Nicholas D. Lane</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Existing work on mitigating catastrophic forgetting in large language model (LLM) fine-tuning has primarily focused on preserving specific data or tasks, while critically overlooking the degradation of essential capabilities instilled through safety alignment, particularly the model's ability to faithfully express ignorance. In this work, we show that this capability is significantly degraded during conventional fine-tuning, leading to undesired behaviors such as hallucinations. To address this novel but highly practical problem, we propose SEAT, a simple and effective fine-tuning approach that preserves both fine-tuning performance and the model's inherent ability to acknowledge its ignorance. SEAT integrates two key components: (1) sparse training that constrains activation drift, and (2) a novel entity perturbation method with KL-divergence regularization, designed to counter knowledge entanglement. Experimental results demonstrate that SEAT significantly outperforms baselines in preserving ignorance awareness while retaining fine-tuning performance, offering a more robust solution for LLM fine-tuning.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item36\">[36]</a>\n",
       "<a href=\"/abs/2506.14470\" id=\"2506.14470\" title=\"Abstract\">\n",
       "        arXiv:2506.14470\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14470\" href=\"/pdf/2506.14470\" id=\"pdf-2506.14470\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14470\" href=\"https://arxiv.org/html/2506.14470v1\" id=\"html-2506.14470\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14470\" href=\"/format/2506.14470\" id=\"oth-2506.14470\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zixian Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Saber,+T\">Takfarinas Saber</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          As one of the most detrimental code smells, code clones significantly increase software maintenance costs and heighten vulnerability risks, making their detection a critical challenge in software engineering. Abstract Syntax Trees (ASTs) dominate deep learning-based code clone detection due to their precise syntactic structure representation, but they inherently lack semantic depth. Recent studies address this by enriching AST-based representations with semantic graphs, such as Control Flow Graphs (CFGs) and Data Flow Graphs (DFGs). However, the effectiveness of various enriched AST-based representations and their compatibility with different graph-based machine learning techniques remains an open question, warranting further investigation to unlock their full potential in addressing the complexities of code clone detection. In this paper, we present a comprehensive empirical study to rigorously evaluate the effectiveness of AST-based hybrid graph representations in Graph Neural Network (GNN)-based code clone detection. We systematically compare various hybrid representations ((CFG, DFG, Flow-Augmented ASTs (FA-AST)) across multiple GNN architectures. Our experiments reveal that hybrid representations impact GNNs differently: while AST+CFG+DFG consistently enhances accuracy for convolution- and attention-based models (Graph Convolutional Networks (GCN), Graph Attention Networks (GAT)), FA-AST frequently introduces structural complexity that harms performance. Notably, GMN outperforms others even with standard AST representations, highlighting its superior cross-code similarity detection and reducing the need for enriched structures.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item37\">[37]</a>\n",
       "<a href=\"/abs/2506.14477\" id=\"2506.14477\" title=\"Abstract\">\n",
       "        arXiv:2506.14477\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14477\" href=\"/pdf/2506.14477\" id=\"pdf-2506.14477\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14477\" href=\"https://arxiv.org/html/2506.14477v1\" id=\"html-2506.14477\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14477\" href=\"/format/2506.14477\" id=\"oth-2506.14477\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J\">Jingqi Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+Z\">Zhilong Song</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jiawei Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+M\">Mingli Song</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+S\">Sheng Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=sun,+l\">linjun sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang,+X\">Xiaogang Ouyang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+C\">Chun Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+C\">Can Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 4 figures, submitted to NIPS 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          The development of high-quality datasets is crucial for benchmarking and advancing research in Graphical User Interface (GUI) agents. Despite their importance, existing datasets are often constructed under idealized conditions, overlooking the diverse anomalies frequently encountered in real-world deployments. To address this limitation, we introduce GUI-Robust, a novel dataset designed for comprehensive GUI agent evaluation, explicitly incorporating seven common types of anomalies observed in everyday GUI interactions. Furthermore, we propose a semi-automated dataset construction paradigm that collects user action sequences from natural interactions via RPA tools and then generate corresponding step and task descriptions for these actions with the assistance of MLLMs. This paradigm significantly reduces annotation time cost by a factor of over 19 times. Finally, we assess state-of-the-art GUI agents using the GUI-Robust dataset, revealing their substantial performance degradation in abnormal scenarios. We anticipate that our work will highlight the importance of robustness in GUI agents and inspires more future research in this direction. The dataset and code are available at <a class=\"link-external link-https\" href=\"https://github.com/chessbean1/GUI-Robust\" rel=\"external noopener nofollow\">this https URL</a>..\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item38\">[38]</a>\n",
       "<a href=\"/abs/2506.14496\" id=\"2506.14496\" title=\"Abstract\">\n",
       "        arXiv:2506.14496\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14496\" href=\"/pdf/2506.14496\" id=\"pdf-2506.14496\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14496\" href=\"https://arxiv.org/html/2506.14496v1\" id=\"html-2506.14496\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14496\" href=\"/format/2506.14496\" id=\"oth-2506.14496\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman,+M+A+U\">Muhammad Atta Ur Rahman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schranz,+M\">Melanie Schranz</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This is the author's version of a paper submitted to IEEE Intelligent Systems. 6 Tables, 3 Figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Swarm intelligence traditionally refers to systems of simple, decentralized agents whose local interactions lead to emergent, collective behavior. Recently, the term 'swarm' has been extended to describe AI systems like OpenAI's Swarm, where large language models (LLMs) act as collaborative agents. This paper contrasts traditional swarm algorithms with LLM-driven swarms exploring how decentralization, scalability, and emergence are redefined in modern artificial intelligence (AI). We implement and compare both paradigms using Boids and Ant Colony Optimization (ACO), evaluating latency, resource usage, and behavioral accuracy. The suitability of both cloud-based and local LLMs is assessed for the agent-based use in swarms. Although LLMs offer powerful reasoning and abstraction capabilities, they introduce new constraints in computation and coordination that challenge traditional notions of swarm design. This study highlights the opportunities and limitations of integrating LLMs into swarm systems and discusses the evolving definition of 'swarm' in modern AI research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item39\">[39]</a>\n",
       "<a href=\"/abs/2506.14502\" id=\"2506.14502\" title=\"Abstract\">\n",
       "        arXiv:2506.14502\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14502\" href=\"/pdf/2506.14502\" id=\"pdf-2506.14502\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14502\" href=\"https://arxiv.org/html/2506.14502v1\" id=\"html-2506.14502\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14502\" href=\"/format/2506.14502\" id=\"oth-2506.14502\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xiao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+J\">Junru Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+J\">Jun Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Q\">Qiong Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vacic,+L\">Ljubo Vacic</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+C\">Changyin Sun</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite the recent advancements in artificial intelligence technologies have shown great potential in improving transport efficiency and safety, autonomous vehicles(AVs) still face great challenge of driving in time-varying traffic flow, especially in dense and interactive situations. Meanwhile, human have free wills and usually do not make the same decisions even situate in the exactly same scenarios, leading to the data-driven methods suffer from poor migratability and high search cost problems, decreasing the efficiency and effectiveness of the behavior policy. In this research, we propose a safety-first human-like decision-making framework(SF-HLDM) for AVs to drive safely, comfortably, and social compatiblely in effiency. The framework integrates a hierarchical progressive framework, which combines a spatial-temporal attention (S-TA) mechanism for other road users' intention inference, a social compliance estimation module for behavior regulation, and a Deep Evolutionary Reinforcement Learning(DERL) model for expanding the search space efficiently and effectively to make avoidance of falling into the local optimal trap and reduce the risk of overfitting, thus make human-like decisions with interpretability and flexibility. The SF-HLDM framework enables autonomous driving AI agents dynamically adjusts decision parameters to maintain safety margins and adhering to contextually appropriate driving behaviors at the same time.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item40\">[40]</a>\n",
       "<a href=\"/abs/2506.14539\" id=\"2506.14539\" title=\"Abstract\">\n",
       "        arXiv:2506.14539\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14539\" href=\"/pdf/2506.14539\" id=\"pdf-2506.14539\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14539\" href=\"https://arxiv.org/html/2506.14539v1\" id=\"html-2506.14539\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14539\" href=\"/format/2506.14539\" id=\"oth-2506.14539\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kang,+D\">Daewon Kang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shin,+Y\">YeongHwan Shin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+D\">Doyeon Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jung,+K\">Kyu-Hwan Jung</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Son,+M+H\">Meong Hi Son</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Since the advent of large language models, prompt engineering now enables the rapid, low-effort creation of diverse autonomous agents that are already in widespread use. Yet this convenience raises urgent concerns about the safety, robustness, and behavioral consistency of the underlying prompts, along with the pressing challenge of preventing those prompts from being exposed to user's attempts. In this paper, we propose the ''Doppelgänger method'' to demonstrate the risk of an agent being hijacked, thereby exposing system instructions and internal information. Next, we define the ''Prompt Alignment Collapse under Adversarial Transfer (PACAT)'' level to evaluate the vulnerability to this adversarial transfer attack. We also propose a ''Caution for Adversarial Transfer (CAT)'' prompt to counter the Doppelgänger method. The experimental results demonstrate that the Doppelgänger method can compromise the agent's consistency and expose its internal information. In contrast, CAT prompts enable effective defense against this adversarial attack.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item41\">[41]</a>\n",
       "<a href=\"/abs/2506.14568\" id=\"2506.14568\" title=\"Abstract\">\n",
       "        arXiv:2506.14568\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14568\" href=\"/pdf/2506.14568\" id=\"pdf-2506.14568\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14568\" href=\"https://arxiv.org/html/2506.14568v1\" id=\"html-2506.14568\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14568\" href=\"/format/2506.14568\" id=\"oth-2506.14568\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Thomas,+E\">Eliott Thomas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Coustaty,+M\">Mickael Coustaty</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Joseph,+A\">Aurelie Joseph</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Deloin,+G\">Gaspar Deloin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Carel,+E\">Elodie Carel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=D'Andecy,+V+P\">Vincent Poulain D'Andecy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ogier,+J\">Jean-Marc Ogier</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at ICDAR 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Automating table extraction (TE) from business documents is critical for industrial workflows but remains challenging due to sparse annotations and error-prone multi-stage pipelines. While semi-supervised learning (SSL) can leverage unlabeled data, existing methods rely on confidence scores that poorly reflect extraction quality. We propose QUEST, a Quality-aware Semi-supervised Table extraction framework designed for business documents. QUEST introduces a novel quality assessment model that evaluates structural and contextual features of extracted tables, trained to predict F1 scores instead of relying on confidence metrics. This quality-aware approach guides pseudo-label selection during iterative SSL training, while diversity measures (DPP, Vendi score, IntDiv) mitigate confirmation bias. Experiments on a proprietary business dataset (1000 annotated + 10000 unannotated documents) show QUEST improves F1 from 64% to 74% and reduces empty predictions by 45% (from 12% to 6.5%). On the DocILE benchmark (600 annotated + 20000 unannotated documents), QUEST achieves a 50% F1 score (up from 42%) and reduces empty predictions by 19% (from 27% to 22%). The framework's interpretable quality assessments and robustness to annotation scarcity make it particularly suited for business documents, where structural consistency and data completeness are paramount.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item42\">[42]</a>\n",
       "<a href=\"/abs/2506.14569\" id=\"2506.14569\" title=\"Abstract\">\n",
       "        arXiv:2506.14569\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14569\" href=\"/pdf/2506.14569\" id=\"pdf-2506.14569\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14569\" href=\"https://arxiv.org/html/2506.14569v1\" id=\"html-2506.14569\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14569\" href=\"/format/2506.14569\" id=\"oth-2506.14569\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Enhancing Symbolic Machine Learning by Subsymbolic Representations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roth,+S\">Stephen Roth</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Baur,+L\">Lennart Baur</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Boer,+D\">Derian Boer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kramer,+S\">Stefan Kramer</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The goal of neuro-symbolic AI is to integrate symbolic and subsymbolic AI approaches, to overcome the limitations of either. Prominent systems include Logic Tensor Networks (LTN) or DeepProbLog, which offer neural predicates and end-to-end learning. The versatility of systems like LTNs and DeepProbLog, however, makes them less efficient in simpler settings, for instance, for discriminative machine learning, in particular in domains with many constants. Therefore, we follow a different approach: We propose to enhance symbolic machine learning schemes by giving them access to neural embeddings. In the present paper, we show this for TILDE and embeddings of constants used by TILDE in similarity predicates. The approach can be fine-tuned by further refining the embeddings depending on the symbolic theory. In experiments in three real-world domain, we show that this simple, yet effective, approach outperforms all other baseline methods in terms of the F1 score. The approach could be useful beyond this setting: Enhancing symbolic learners in this way could be extended to similarities between instances (effectively working like kernels within a logical language), for analogical reasoning, or for propositionalization.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item43\">[43]</a>\n",
       "<a href=\"/abs/2506.14570\" id=\"2506.14570\" title=\"Abstract\">\n",
       "        arXiv:2506.14570\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14570\" href=\"/pdf/2506.14570\" id=\"pdf-2506.14570\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14570\" href=\"https://arxiv.org/html/2506.14570v1\" id=\"html-2506.14570\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14570\" href=\"/format/2506.14570\" id=\"oth-2506.14570\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hashemi,+M\">Mohammad Hashemi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zufle,+A\">Andreas Zufle</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Capturing human mobility is essential for modeling how people interact with and move through physical spaces, reflecting social behavior, access to resources, and dynamic spatial patterns. To support scalable and transferable analysis across diverse geographies and contexts, there is a need for a generalizable foundation model for spatiotemporal data. While foundation models have transformed language and vision, they remain limited in handling the unique challenges posed by the spatial, temporal, and semantic complexity of mobility data. This vision paper advocates for a new class of spatial foundation models that integrate geolocation semantics with human mobility across multiple scales. Central to our vision is a shift from modeling discrete points of interest to understanding places: dynamic, context-rich regions shaped by human behavior and mobility that may comprise many places of interest. We identify key gaps in adaptability, scalability, and multi-granular reasoning, and propose research directions focused on modeling places and enabling efficient learning. Our goal is to guide the development of scalable, context-aware models for next-generation geospatial intelligence. These models unlock powerful applications ranging from personalized place discovery and logistics optimization to urban planning, ultimately enabling smarter and more responsive spatial decision-making.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item44\">[44]</a>\n",
       "<a href=\"/abs/2506.14728\" id=\"2506.14728\" title=\"Abstract\">\n",
       "        arXiv:2506.14728\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14728\" href=\"/pdf/2506.14728\" id=\"pdf-2506.14728\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14728\" href=\"https://arxiv.org/html/2506.14728v1\" id=\"html-2506.14728\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14728\" href=\"/format/2506.14728\" id=\"oth-2506.14728\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu,+J\">Jiahao Qiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Juan,+X\">Xinzhe Juan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yimin Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+L\">Ling Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qi,+X\">Xuan Qi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+T\">Tongcheng Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+J\">Jiacheng Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yifu Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+Z\">Zixin Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Hongru Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Shilong Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+X\">Xun Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Leqi,+L\">Liu Leqi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+M\">Mengdi Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 5 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          While knowledge distillation has become a mature field for compressing large language models (LLMs) into smaller ones by aligning their outputs or internal representations, the distillation of LLM-based agents, which involve planning, memory, and tool use, remains relatively underexplored. Existing agent distillation methods typically replay full teacher trajectories or imitate step-by-step teacher tool usage, but they often struggle to train student agents to dynamically plan and act in novel environments. We propose AgentDistill, a novel, training-free agent distillation framework that enables efficient and scalable knowledge transfer via direct reuse of Model-Context-Protocols (MCPs), which are structured and reusable task-solving modules autonomously generated by teacher agents. The reuse of these distilled MCPs enables student agents to generalize their capabilities across domains and solve new problems with minimal supervision or human intervention. Experiments on biomedical and mathematical benchmarks demonstrate that our distilled student agents, built on small language models, can achieve performance comparable to advanced systems using large LLMs such as OctoTools (GPT-4o), highlighting the effectiveness of our framework in building scalable and cost-efficient intelligent agents.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item45\">[45]</a>\n",
       "<a href=\"/abs/2506.14755\" id=\"2506.14755\" title=\"Abstract\">\n",
       "        arXiv:2506.14755\n",
       "      </a>\n",
       "      \n",
       "        [<a aria-labelledby=\"pdf-2506.14755\" href=\"/pdf/2506.14755\" id=\"pdf-2506.14755\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14755\" href=\"https://arxiv.org/html/2506.14755v1\" id=\"html-2506.14755\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14755\" href=\"/format/2506.14755\" id=\"oth-2506.14755\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Optimizing Length Compression in Large Reasoning Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+Z\">Zhengxiang Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+D\">Dongping Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+M\">Mingyang Fu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+T\">Tianyi Zhou</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          16 pages, 7 figures, 4 tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Reasoning Models (LRMs) have achieved remarkable success, yet they often suffer from producing unnecessary and verbose reasoning chains. We identify a core aspect of this issue as \"invalid thinking\" -- models tend to repeatedly double-check their work after having derived the correct answer. To address this specific inefficiency, we move beyond the general principles of Efficacy and Efficiency to propose two new, fine-grained principles: Brevity, which advocates for eliminating redundancy, and Sufficiency, which ensures critical reasoning steps are preserved. Guided by these principles, we introduce LC-R1, a post-training method based on Group Relative Policy Optimization (GRPO). LC-R1 employs a novel combination of a Length Reward for overall conciseness and a Compress Reward that is specifically designed to remove the invalid portion of the thinking process. Extensive experiments on multiple reasoning benchmarks demonstrate that LC-R1 achieves a significant reduction in sequence length (~50%) with only a marginal (~2%) drop in accuracy, achieving a favorable trade-off point on the Pareto frontier that prioritizes high compression. Our analysis further validates the robustness of LC-R1 and provides valuable insights for developing more powerful yet computationally efficient LRMs. Our code is released at <a class=\"link-external link-https\" href=\"https://github.com/zxiangx/LC-R1\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "</dl>\n",
       "<dl id=\"articles\">\n",
       "<h3>Cross submissions (showing 137 of 137 entries)</h3>\n",
       "<dt>\n",
       "<a name=\"item46\">[46]</a>\n",
       "<a href=\"/abs/2506.13769\" id=\"2506.13769\" title=\"Abstract\">\n",
       "        arXiv:2506.13769\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13769\" href=\"/pdf/2506.13769\" id=\"pdf-2506.13769\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13769\" href=\"https://arxiv.org/html/2506.13769v1\" id=\"html-2506.13769\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13769\" href=\"/format/2506.13769\" id=\"oth-2506.13769\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Non-planar Object Detection and Identification by Features Matching and Triangulation Growth\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Leveni,+F\">Filippo Leveni</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Master's thesis at Politecnico di Milano\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Object detection and identification is surely a fundamental topic in the computer vision field; it plays a crucial role in many applications such as object tracking, industrial robots control, image retrieval, etc. We propose a feature-based approach for detecting and identifying distorted occurrences of a given template in a scene image by incremental grouping of feature matches between the image and the template. For this purpose, we consider the Delaunay triangulation of template features as an useful tool through which to be guided in this iterative approach. The triangulation is treated as a graph and, starting from a single triangle, neighboring nodes are considered and the corresponding features are identified; then matches related to them are evaluated to determine if they are worthy to be grouped. This evaluation is based on local consistency criteria derived from geometric and photometric properties of local features. Our solution allows the identification of the object in situations where geometric models (e.g. homography) does not hold, thus enable the detection of objects such that the template is non planar or when it is planar but appears distorted in the image. We show that our approach performs just as well or better than application of homography-based RANSAC in scenarios in which distortion is nearly absent, while when the deformation becomes relevant our method shows better description performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item47\">[47]</a>\n",
       "<a href=\"/abs/2506.13771\" id=\"2506.13771\" title=\"Abstract\">\n",
       "        arXiv:2506.13771\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13771\" href=\"/pdf/2506.13771\" id=\"pdf-2506.13771\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13771\" href=\"https://arxiv.org/html/2506.13771v1\" id=\"html-2506.13771\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13771\" href=\"/format/2506.13771\" id=\"oth-2506.13771\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LittleBit: Ultra Low-Bit Quantization via Latent Factorization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+B\">Banseok Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+D\">Dongkyu Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=You,+Y\">Youngcheon You</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+Y\">Youngmin Kim</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Deploying large language models (LLMs) often faces challenges from substantial memory and computational costs. Quantization offers a solution, yet performance degradation in the sub-1-bit regime remains particularly difficult. This paper introduces LittleBit, a novel method for extreme LLM compression. It targets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$ memory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents weights in a low-rank form using latent matrix factorization, subsequently binarizing these factors. To counteract information loss from this extreme precision, it integrates a multi-scale compensation mechanism. This includes row, column, and an additional latent dimension that learns per-rank importance. Two key contributions enable effective training: Dual Sign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware training (QAT) initialization, and integrated Residual Compensation to mitigate errors. Extensive experiments confirm LittleBit's superiority in sub-1-bit quantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading method's 0.7 BPW. This establishes a superior size-performance trade-off, with kernel-level benchmarks indicating potential for a 5$\\times$ speedup compared to FP16. LittleBit paves the way for deploying powerful LLMs in resource-constrained environments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item48\">[48]</a>\n",
       "<a href=\"/abs/2506.13772\" id=\"2506.13772\" title=\"Abstract\">\n",
       "        arXiv:2506.13772\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13772\" href=\"/pdf/2506.13772\" id=\"pdf-2506.13772\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13772\" href=\"https://arxiv.org/html/2506.13772v1\" id=\"html-2506.13772\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13772\" href=\"/format/2506.13772\" id=\"oth-2506.13772\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Z\">Zhenyan Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+D\">Daliang Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cai,+D\">Dongqi Cai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zexi Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+W\">Wei Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+F\">Fangming Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+S\">Shangguang Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+M\">Mengwei Xu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) are deployed on mobile devices to power killer applications such as intelligent assistants. LLMs pre-trained on general corpora often hallucinate when handling personalized or unseen queries, leading to incorrect or outdated responses. Knowledge editing addresses this by identifying and adjusting a small crucial portion of model weights, without compromising the general knowledge. However, prior knowledge editing methods are impractical to run on local devices due to the resource-heavy backpropagation (BP) needed for updates. We present MobiEdit, the first mobile knowledge editing framework that enables efficient LLM personalization on commercial off-the-shelf (COTS) mobile devices. MobiEdit replaces full-precision BP with quantized forward-only gradient estimation, thus compatible with the energy-efficient mobile neural processing units (NPUs). MobiEdit replaces full-precision backpropagation with quantized forward-only gradient estimation, making it compatible with energy-efficient mobile NPUs. To further improve gradient estimation efficiency, we introduce two optimizations: an early stoping mechanism that adaptively terminates editing upon success and a prefix cache that reuses computation across steps. Our approach enables real-time editing of a 3B-parameter model (Qwen2.5-3B-Instruct) on COTS mobile devices with 7.6$\\times$ less memory, 14.7 $\\times$ less energy and 3.6$\\times$ less latency compared to previous knowledge editing methods.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item49\">[49]</a>\n",
       "<a href=\"/abs/2506.13777\" id=\"2506.13777\" title=\"Abstract\">\n",
       "        arXiv:2506.13777\n",
       "      </a>\n",
       "          (cross-list from physics.soc-ph)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13777\" href=\"/pdf/2506.13777\" id=\"pdf-2506.13777\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13777\" href=\"https://arxiv.org/html/2506.13777v1\" id=\"html-2506.13777\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13777\" href=\"/format/2506.13777\" id=\"oth-2506.13777\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Survey of Physics-Informed AI for Complex Urban Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Xu,+E\">En Xu</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Wang,+H\">Huandong Wang</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Zhang,+Y\">Yunke Zhang</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Li,+S\">Sibo Li</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Tang,+Y\">Yinzhou Tang</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Zhou,+Z\">Zhilun Zhou</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Lin,+Y\">Yuming Lin</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Yuan,+Y\">Yuan Yuan</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Fan,+X\">Xiaochen Fan</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Ding,+J\">Jingtao Ding</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Li,+Y\">Yong Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Urban systems are typical examples of complex systems, where the integration of physics-based modeling with artificial intelligence (AI) presents a promising paradigm for enhancing predictive accuracy, interpretability, and decision-making. In this context, AI excels at capturing complex, nonlinear relationships, while physics-based models ensure consistency with real-world laws and provide interpretable insights. We provide a comprehensive review of physics-informed AI methods in urban applications. The proposed taxonomy categorizes existing approaches into three paradigms - Physics-Integrated AI, Physics-AI Hybrid Ensemble, and AI-Integrated Physics - and further details seven representative methods. This classification clarifies the varying degrees and directions of physics-AI integration, guiding the selection and development of appropriate methods based on application needs and data availability. We systematically examine their applications across eight key urban domains: energy, environment, economy, transportation, information, public services, emergency management, and the urban system as a whole. Our analysis highlights how these methodologies leverage physical laws and data-driven models to address urban challenges, enhancing system reliability, efficiency, and adaptability. By synthesizing existing methodologies and their urban applications, we identify critical gaps and outline future research directions, paving the way toward next-generation intelligent urban system modeling.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item50\">[50]</a>\n",
       "<a href=\"/abs/2506.13778\" id=\"2506.13778\" title=\"Abstract\">\n",
       "        arXiv:2506.13778\n",
       "      </a>\n",
       "          (cross-list from cs.IR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13778\" href=\"/pdf/2506.13778\" id=\"pdf-2506.13778\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13778\" href=\"/format/2506.13778\" id=\"oth-2506.13778\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Eponon,+A+A\">Anvi Alex Eponon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shahiki-Tash,+M\">Moein Shahiki-Tash</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Batyrshin,+I\">Ildar Batyrshin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Maldonado-Sifuentes,+C+E\">Christian E. Maldonado-Sifuentes</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sidorov,+G\">Grigori Sidorov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gelbukh,+A\">Alexander Gelbukh</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This study presents a question-based knowledge encoding approach that improves retrieval-augmented generation (RAG) systems without requiring fine-tuning or traditional chunking. We encode textual content using generated questions that span the lexical and semantic space, creating targeted retrieval cues combined with a custom syntactic reranking method.\n",
       "<br/>In single-hop retrieval over 109 scientific papers, our approach achieves a Recall@3 of 0.84, outperforming traditional chunking methods by 60 percent. We also introduce \"paper-cards\", concise paper summaries under 300 characters, which enhance BM25 retrieval, increasing MRR@3 from 0.56 to 0.85 on simplified technical queries.\n",
       "<br/>For multihop tasks, our reranking method reaches an F1 score of 0.52 with LLaMA2-Chat-7B on the LongBench 2WikiMultihopQA dataset, surpassing chunking and fine-tuned baselines which score 0.328 and 0.412 respectively.\n",
       "<br/>This method eliminates fine-tuning requirements, reduces retrieval latency, enables intuitive question-driven knowledge access, and decreases vector storage demands by 80%, positioning it as a scalable and efficient RAG alternative.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item51\">[51]</a>\n",
       "<a href=\"/abs/2506.13780\" id=\"2506.13780\" title=\"Abstract\">\n",
       "        arXiv:2506.13780\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13780\" href=\"/pdf/2506.13780\" id=\"pdf-2506.13780\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13780\" href=\"https://arxiv.org/html/2506.13780v1\" id=\"html-2506.13780\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13780\" href=\"/format/2506.13780\" id=\"oth-2506.13780\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Hidden Bias in the Machine: Stereotypes in Text-to-Image Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Porikli,+S\">Sedat Porikli</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Porikli,+V\">Vedat Porikli</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Equal contribution by both authors, Published at CVPR 2025 Workshop on Experimental Model Auditing via Controllable Synthesis (EMACS) and Workshop on Demographic Diversity in Computer Vision (DemoDiv)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item52\">[52]</a>\n",
       "<a href=\"/abs/2506.13781\" id=\"2506.13781\" title=\"Abstract\">\n",
       "        arXiv:2506.13781\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13781\" href=\"/pdf/2506.13781\" id=\"pdf-2506.13781\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13781\" href=\"https://arxiv.org/html/2506.13781v1\" id=\"html-2506.13781\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13781\" href=\"/format/2506.13781\" id=\"oth-2506.13781\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Solving the Job Shop Scheduling Problem with Graph Neural Networks: A Customizable Reinforcement Learning Environment\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fern%C3%A1ndez,+P+A\">Pablo Ariño Fernández</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gonz%C3%A1lez,+C+Q\">Carlos Quesada González</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Bachelor's thesis, Universidad Politécnica de Madrid, 2025. 150 pages, 23 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The job shop scheduling problem is an NP-hard combinatorial optimization problem relevant to manufacturing and timetabling. Traditional approaches use priority dispatching rules based on simple heuristics. Recent work has attempted to replace these with deep learning models, particularly graph neural networks (GNNs), that learn to assign priorities from data. However, training such models requires customizing numerous factors: graph representation, node features, action space, and reward functions. The lack of modular libraries for experimentation makes this research time-consuming. This work introduces JobShopLib, a modular library that allows customizing these factors and creating new components with its reinforcement learning environment. We trained several dispatchers through imitation learning to demonstrate the environment's utility. One model outperformed various graph-based dispatchers using only individual operation features, highlighting the importance of feature customization. Our GNN model achieved near state-of-the-art results on large-scale problems. These results suggest significant room for improvement in developing such models. JobShopLib provides the necessary tools for future experimentation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item53\">[53]</a>\n",
       "<a href=\"/abs/2506.13782\" id=\"2506.13782\" title=\"Abstract\">\n",
       "        arXiv:2506.13782\n",
       "      </a>\n",
       "          (cross-list from cs.IR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13782\" href=\"/pdf/2506.13782\" id=\"pdf-2506.13782\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13782\" href=\"https://arxiv.org/html/2506.13782v1\" id=\"html-2506.13782\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13782\" href=\"/format/2506.13782\" id=\"oth-2506.13782\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          XGraphRAG: Interactive Visual Analysis for Graph-based Retrieval-Augmented Generation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Ke Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pan,+B\">Bo Pan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+Y\">Yingchaojie Feng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yuwei Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jieyi Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+M\">Minfeng Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+W\">Wei Chen</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted to IEEE Pacific Visualization Conference 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Graph-based Retrieval-Augmented Generation (RAG) has shown great capability in enhancing Large Language Model (LLM)'s answer with an external knowledge base. Compared to traditional RAG, it introduces a graph as an intermediate representation to capture better structured relational knowledge in the corpus, elevating the precision and comprehensiveness of generation results. However, developers usually face challenges in analyzing the effectiveness of GraphRAG on their dataset due to GraphRAG's complex information processing pipeline and the overwhelming amount of LLM invocations involved during graph construction and query, which limits GraphRAG interpretability and accessibility. This research proposes a visual analysis framework that helps RAG developers identify critical recalls of GraphRAG and trace these recalls through the GraphRAG pipeline. Based on this framework, we develop XGraphRAG, a prototype system incorporating a set of interactive visualizations to facilitate users' analysis process, boosting failure cases collection and improvement opportunities identification. Our evaluation demonstrates the effectiveness and usability of our approach. Our work is open-sourced and available at <a class=\"link-external link-https\" href=\"https://github.com/Gk0Wk/XGraphRAG\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item54\">[54]</a>\n",
       "<a href=\"/abs/2506.13786\" id=\"2506.13786\" title=\"Abstract\">\n",
       "        arXiv:2506.13786\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13786\" href=\"/pdf/2506.13786\" id=\"pdf-2506.13786\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13786\" href=\"https://arxiv.org/html/2506.13786v1\" id=\"html-2506.13786\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13786\" href=\"/format/2506.13786\" id=\"oth-2506.13786\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Enhancing Bagging Ensemble Regression with Data Integration for Time Series-Based Diabetes Prediction\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ngo,+V+M\">Vuong M. Ngo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vinh,+T+Q\">Tran Quang Vinh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kearney,+P\">Patricia Kearney</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roantree,+M\">Mark Roantree</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          17th International Conference on Computational Collective Intelligence, LNAI, Springer, 11 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Diabetes is a chronic metabolic disease characterized by elevated blood glucose levels, leading to complications like heart disease, kidney failure, and nerve damage. Accurate state-level predictions are vital for effective healthcare planning and targeted interventions, but in many cases, data for necessary analyses are incomplete. This study begins with a data engineering process to integrate diabetes-related datasets from 2011 to 2021 to create a comprehensive feature set. We then introduce an enhanced bagging ensemble regression model (EBMBag+) for time series forecasting to predict diabetes prevalence across U.S. cities. Several baseline models, including SVMReg, BDTree, LSBoost, NN, LSTM, and ERMBag, were evaluated for comparison with our EBMBag+ algorithm. The experimental results demonstrate that EBMBag+ achieved the best performance, with an MAE of 0.41, RMSE of 0.53, MAPE of 4.01, and an R2 of 0.9.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item55\">[55]</a>\n",
       "<a href=\"/abs/2506.13787\" id=\"2506.13787\" title=\"Abstract\">\n",
       "        arXiv:2506.13787\n",
       "      </a>\n",
       "          (cross-list from cs.IR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13787\" href=\"/pdf/2506.13787\" id=\"pdf-2506.13787\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13787\" href=\"/format/2506.13787\" id=\"oth-2506.13787\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Analysis of Anonymous User Interaction Relationships and Prediction of Advertising Feedback Based on Graph Neural Network\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+Y\">Yanjun Dai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+H\">Haoyang Feng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+Y\">Yuan Gao</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          While online advertising is highly dependent on implicit interaction networks of anonymous users for engagement inference, and for the selection and optimization of delivery strategies, existing graph models seldom can capture the multi-scale temporal, semantic and higher-order dependency features of these interaction networks, thus it's hard to describe the complicated patterns of the anonymous behavior. In this paper, we propose Decoupled Temporal-Hierarchical Graph Neural Network (DTH-GNN), which achieves three main contributions. Above all, we introduce temporal edge decomposition, which divides each interaction into three types of channels: short-term burst, diurnal cycle and long-range memory, and conducts feature extraction using the convolution kernel of parallel dilated residuals; Furthermore, our model builds a hierarchical heterogeneous aggregation, where user-user, user-advertisement, advertisement-advertisement subgraphs are combined through the meta-path conditional Transformer encoder, where the noise structure is dynamically tamped down via the synergy of cross-channel self-attention and gating relationship selector. Thirdly, the contrast regularity of feedback perception is formulated, the consistency of various time slices is maximized, the entropy of control exposure information with dual-view target is maximized, the global prototype of dual-momentum queue distillation is presented, and the strategy gradient layer with light weight is combined with delaying transformation signal to fine-tune the node representation for benefit-oriented. The AUC of DTH-GNN improved by 8.2% and the logarithmic loss improved by 5.7% in comparison with the best baseline model.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item56\">[56]</a>\n",
       "<a href=\"/abs/2506.13796\" id=\"2506.13796\" title=\"Abstract\">\n",
       "        arXiv:2506.13796\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13796\" href=\"/pdf/2506.13796\" id=\"pdf-2506.13796\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13796\" href=\"https://arxiv.org/html/2506.13796v1\" id=\"html-2506.13796\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13796\" href=\"/format/2506.13796\" id=\"oth-2506.13796\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ClimateChat: Designing Data and Methods for Instruction Tuning LLMs to Answer Climate Change Queries\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Z\">Zhou Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xiao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liao,+Y\">Yuanhong Liao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+M\">Ming Lin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bai,+Y\">Yuqi Bai</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ICLR 2025 camera ready, 13 pages, 4 figures, 4 tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          As the issue of global climate change becomes increasingly severe, the demand for research in climate science continues to grow. Natural language processing technologies, represented by Large Language Models (LLMs), have been widely applied to climate change-specific research, providing essential information support for decision-makers and the public. Some studies have improved model performance on relevant tasks by constructing climate change-related instruction data and instruction-tuning LLMs. However, current research remains inadequate in efficiently producing large volumes of high-precision instruction data for climate change, which limits further development of climate change LLMs. This study introduces an automated method for constructing instruction data. The method generates instructions using facts and background knowledge from documents and enhances the diversity of the instruction data through web scraping and the collection of seed instructions. Using this method, we constructed a climate change instruction dataset, named ClimateChat-Corpus, which was used to fine-tune open-source LLMs, resulting in an LLM named ClimateChat. Evaluation results show that ClimateChat significantly improves performance on climate change question-and-answer tasks. Additionally, we evaluated the impact of different base models and instruction data on LLM performance and demonstrated its capability to adapt to a wide range of climate change scientific discovery tasks, emphasizing the importance of selecting an appropriate base model for instruction tuning. This research provides valuable references and empirical support for constructing climate change instruction data and training climate change-specific LLMs.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item57\">[57]</a>\n",
       "<a href=\"/abs/2506.13798\" id=\"2506.13798\" title=\"Abstract\">\n",
       "        arXiv:2506.13798\n",
       "      </a>\n",
       "          (cross-list from cs.CY)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13798\" href=\"/pdf/2506.13798\" id=\"pdf-2506.13798\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13798\" href=\"/format/2506.13798\" id=\"oth-2506.13798\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Contemporary AI foundation models increase biological weapons risk\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Brent,+R\">Roger Brent</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=McKelvey,+T+G\">T. Greg McKelvey Jr</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          58 pages, 10 figures, 4 tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The rapid advancement of artificial intelligence has raised concerns about its potential to facilitate biological weapons development. We argue existing safety assessments of contemporary foundation AI models underestimate this risk, largely due to flawed assumptions and inadequate evaluation methods. First, assessments mistakenly assume biological weapons development requires tacit knowledge, or skills gained through hands-on experience that cannot be easily verbalized. Second, they rely on imperfect benchmarks that overlook how AI can uplift both nonexperts and already-skilled individuals. To challenge the tacit knowledge assumption, we examine cases where individuals without formal expertise, including a 2011 Norwegian ultranationalist who synthesized explosives, successfully carried out complex technical tasks. We also review efforts to document pathogen construction processes, highlighting how such tasks can be conveyed in text. We identify \"elements of success\" for biological weapons development that large language models can describe in words, including steps such as acquiring materials and performing technical procedures. Applying this framework, we find that advanced AI models Llama 3.1 405B, ChatGPT-4o, and Claude 3.5 Sonnet can accurately guide users through the recovery of live poliovirus from commercially obtained synthetic DNA, challenging recent claims that current models pose minimal biosecurity risk. We advocate for improved benchmarks, while acknowledging the window for meaningful implementation may have already closed.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item58\">[58]</a>\n",
       "<a href=\"/abs/2506.13800\" id=\"2506.13800\" title=\"Abstract\">\n",
       "        arXiv:2506.13800\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13800\" href=\"/pdf/2506.13800\" id=\"pdf-2506.13800\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13800\" href=\"https://arxiv.org/html/2506.13800v1\" id=\"html-2506.13800\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13800\" href=\"/format/2506.13800\" id=\"oth-2506.13800\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Enhancing Clinical Decision Support and EHR Insights through LLMs and the Model Context Protocol: An Open-Source MCP-FHIR Framework\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ehtesham,+A\">Abul Ehtesham</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+A\">Aditi Singh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar,+S\">Saket Kumar</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Enhancing clinical decision support (CDS), reducing documentation burdens, and improving patient health literacy remain persistent challenges in digital health. This paper presents an open-source, agent-based framework that integrates Large Language Models (LLMs) with HL7 FHIR data via the Model Context Protocol (MCP) for dynamic extraction and reasoning over electronic health records (EHRs). Built on the established MCP-FHIR implementation, the framework enables declarative access to diverse FHIR resources through JSON-based configurations, supporting real-time summarization, interpretation, and personalized communication across multiple user personas, including clinicians, caregivers, and patients. To ensure privacy and reproducibility, the framework is evaluated using synthetic EHR data from the SMART Health IT sandbox (<a class=\"link-external link-https\" href=\"https://r4.smarthealthit.org/\" rel=\"external noopener nofollow\">this https URL</a>), which conforms to the FHIR R4 standard. Unlike traditional approaches that rely on hardcoded retrieval and static workflows, the proposed method delivers scalable, explainable, and interoperable AI-powered EHR applications. The agentic architecture further supports multiple FHIR formats, laying a robust foundation for advancing personalized digital health solutions.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item59\">[59]</a>\n",
       "<a href=\"/abs/2506.13804\" id=\"2506.13804\" title=\"Abstract\">\n",
       "        arXiv:2506.13804\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13804\" href=\"/pdf/2506.13804\" id=\"pdf-2506.13804\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13804\" href=\"/format/2506.13804\" id=\"oth-2506.13804\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Instruction and Solution Probabilities as Heuristics for Inductive Programming\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=McDaid,+E\">Edward McDaid</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=McDaid,+S\">Sarah McDaid</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 10 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Instruction subsets (ISs) are heuristics that can shrink the size of the inductive programming (IP) search space by tens of orders of magnitude. Here, we extend the IS approach by introducing instruction and solution probabilities as additional heuristics. Instruction probability reflects the expectation of an instruction occurring in a solution, based on the frequency of instruction occurrence in a large code sample. The solution probability for a partial or complete program is simply the product of all constituent instruction probabilities, including duplicates. We treat the minimum solution probabilities observed in code sample program units of different sizes as solution probability thresholds. These thresholds are used to prune the search space as partial solutions are constructed, thereby eliminating any branches containing unlikely combinations of instructions. The new approach has been evaluated using a large sample of human code. We tested two formulations of instruction probability: one based on instruction occurrence across the entire code sample and another that measured the distribution separately for each IS. Our results show that both variants produce substantial further reductions in the IP search space size of up to tens of orders of magnitude, depending on solution size. In combination with IS, reductions of over 100 orders of magnitude can be achieved. We also carried out cross-validation testing to show that the heuristics should work effectively with unseen code. The approach is described and the results and some ideas for future work are discussed.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item60\">[60]</a>\n",
       "<a href=\"/abs/2506.13805\" id=\"2506.13805\" title=\"Abstract\">\n",
       "        arXiv:2506.13805\n",
       "      </a>\n",
       "          (cross-list from cs.CY)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13805\" href=\"/pdf/2506.13805\" id=\"pdf-2506.13805\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13805\" href=\"https://arxiv.org/html/2506.13805v1\" id=\"html-2506.13805\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13805\" href=\"/format/2506.13805\" id=\"oth-2506.13805\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mingole,+B\">Bonam Mingole</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Majumdar,+A\">Aditya Majumdar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Choudhury,+F+A\">Firdaus Ahmed Choudhury</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kraschnewski,+J+L\">Jennifer L. Kraschnewski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sundar,+S+S\">Shyam S. Sundar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yadav,+A\">Amulya Yadav</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The proliferation of Large Language Models (LLMs) in high-stakes applications such as medical (self-)diagnosis and preliminary triage raises significant ethical and practical concerns about the effectiveness, appropriateness, and possible harmfulness of the use of these technologies for health-related concerns and queries. Some prior work has considered the effectiveness of LLMs in answering expert-written health queries/prompts, questions from medical examination banks, or queries based on pre-existing clinical cases. Unfortunately, these existing studies completely ignore an in-the-wild evaluation of the effectiveness of LLMs in answering everyday health concerns and queries typically asked by general users, which corresponds to the more prevalent use case for LLMs. To address this research gap, this paper presents the findings from a university-level competition that leveraged a novel, crowdsourced approach for evaluating the effectiveness of LLMs in answering everyday health queries. Over the course of a week, a total of 34 participants prompted four publicly accessible LLMs with 212 real (or imagined) health concerns, and the LLM generated responses were evaluated by a team of nine board-certified physicians. At a high level, our findings indicate that on average, 76% of the 212 LLM responses were deemed to be accurate by physicians. Further, with the help of medical professionals, we investigated whether RAG versions of these LLMs (powered with a comprehensive medical knowledge base) can improve the quality of responses generated by LLMs. Finally, we also derive qualitative insights to explain our quantitative findings by conducting interviews with seven medical professionals who were shown all the prompts in our competition. This paper aims to provide a more grounded understanding of how LLMs perform in real-world everyday health communication.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item61\">[61]</a>\n",
       "<a href=\"/abs/2506.13807\" id=\"2506.13807\" title=\"Abstract\">\n",
       "        arXiv:2506.13807\n",
       "      </a>\n",
       "          (cross-list from eess.IV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13807\" href=\"/pdf/2506.13807\" id=\"pdf-2506.13807\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13807\" href=\"https://arxiv.org/html/2506.13807v1\" id=\"html-2506.13807\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13807\" href=\"/format/2506.13807\" id=\"oth-2506.13807\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          BraTS orchestrator : Democratizing and Disseminating state-of-the-art brain tumor image analysis\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Kofler,+F\">Florian Kofler</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Rosier,+M\">Marcel Rosier</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Astaraki,+M\">Mehdi Astaraki</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Baid,+U\">Ujjwal Baid</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=M%C3%B6ller,+H\">Hendrik Möller</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Buchner,+J+A\">Josef A. Buchner</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Steinbauer,+F\">Felix Steinbauer</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Oswald,+E\">Eva Oswald</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=de+la+Rosa,+E\">Ezequiel de la Rosa</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Ezhov,+I\">Ivan Ezhov</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=von+See,+C\">Constantin von See</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Kirschke,+J\">Jan Kirschke</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Schmick,+A\">Anton Schmick</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Pati,+S\">Sarthak Pati</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Linardos,+A\">Akis Linardos</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Pitarch,+C\">Carla Pitarch</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Adap,+S\">Sanyukta Adap</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Rudie,+J\">Jeffrey Rudie</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=de+Verdier,+M+C\">Maria Correia de Verdier</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Saluja,+R\">Rachit Saluja</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Calabrese,+E\">Evan Calabrese</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=LaBella,+D\">Dominic LaBella</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Aboian,+M\">Mariam Aboian</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Moawad,+A+W\">Ahmed W. Moawad</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Maleki,+N\">Nazanin Maleki</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Anazodo,+U\">Udunna Anazodo</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Adewole,+M\">Maruf Adewole</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Linguraru,+M+G\">Marius George Linguraru</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Kazerooni,+A+F\">Anahita Fathi Kazerooni</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Jiang,+Z\">Zhifan Jiang</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Conte,+G+M\">Gian Marco Conte</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Li,+H\">Hongwei Li</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Iglesias,+J+E\">Juan Eugenio Iglesias</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Bakas,+S\">Spyridon Bakas</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Wiestler,+B\">Benedikt Wiestler</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Piraud,+M\">Marie Piraud</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Menze,+B\">Bjoern Menze</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          27p, 2figs, 3tabs\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The Brain Tumor Segmentation (BraTS) cluster of challenges has significantly advanced brain tumor image analysis by providing large, curated datasets and addressing clinically relevant tasks. However, despite its success and popularity, algorithms and models developed through BraTS have seen limited adoption in both scientific and clinical communities. To accelerate their dissemination, we introduce BraTS orchestrator, an open-source Python package that provides seamless access to state-of-the-art segmentation and synthesis algorithms for diverse brain tumors from the BraTS challenge ecosystem. Available on GitHub (<a class=\"link-external link-https\" href=\"https://github.com/BrainLesion/BraTS\" rel=\"external noopener nofollow\">this https URL</a>), the package features intuitive tutorials designed for users with minimal programming experience, enabling both researchers and clinicians to easily deploy winning BraTS algorithms for inference. By abstracting the complexities of modern deep learning, BraTS orchestrator democratizes access to the specialized knowledge developed within the BraTS community, making these advances readily available to broader neuro-radiology and neuro-oncology audiences.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item62\">[62]</a>\n",
       "<a href=\"/abs/2506.13809\" id=\"2506.13809\" title=\"Abstract\">\n",
       "        arXiv:2506.13809\n",
       "      </a>\n",
       "          (cross-list from q-bio.PE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13809\" href=\"/pdf/2506.13809\" id=\"pdf-2506.13809\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13809\" href=\"https://arxiv.org/html/2506.13809v1\" id=\"html-2506.13809\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13809\" href=\"/format/2506.13809\" id=\"oth-2506.13809\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Analysis and Optimization of Probabilities of Beneficial Mutation and Crossover Recombination in a Hamming Space\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Belavkin,+R+V\">Roman V. Belavkin</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          42 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Populations and Evolution (q-bio.PE)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Inspired by Fisher's geometric approach to study beneficial mutations, we analyse probabilities of beneficial mutation and crossover recombination of strings in a general Hamming space with arbitrary finite alphabet. Mutations and recombinations that reduce the distance to an optimum are considered as beneficial. Geometric and combinatorial analysis is used to derive closed-form expressions for transition probabilities between spheres around an optimum giving a complete description of Markov evolution of distances from an optimum over multiple generations. This paves the way for optimization of parameters of mutation and recombination operators. Here we derive optimality conditions for mutation and recombination radii maximizing the probabilities of mutation and crossover into the optimum. The analysis highlights important differences between these evolutionary operators. While mutation can potentially reach any part of the search space, the probability of beneficial mutation decreases with distance to an optimum, and the optimal mutation radius or rate should also decrease resulting in a slow-down of evolution near the optimum. Crossover recombination, on the other hand, acts in a subspace of the search space defined by the current population of strings. However, probabilities of beneficial and deleterious crossover are balanced, and their characteristics, such as variance, are translation invariant in a Hamming space, suggesting that recombination may complement mutation and boost the rate of evolution near the optimum.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item63\">[63]</a>\n",
       "<a href=\"/abs/2506.13811\" id=\"2506.13811\" title=\"Abstract\">\n",
       "        arXiv:2506.13811\n",
       "      </a>\n",
       "          (cross-list from cs.MA)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13811\" href=\"/pdf/2506.13811\" id=\"pdf-2506.13811\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13811\" href=\"/format/2506.13811\" id=\"oth-2506.13811\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Youwai,+S\">Sompote Youwai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Phim,+D\">David Phim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Murcia,+V+G\">Vianne Gayl Murcia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Onas,+R+C\">Rianne Clair Onas</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This study investigates router-based multi-agent systems for automating foundation design calculations through intelligent task classification and expert selection. Three approaches were evaluated: single-agent processing, multi-agent designer-checker architecture, and router-based expert selection. Performance assessment utilized baseline models including DeepSeek R1, ChatGPT 4 Turbo, Grok 3, and Gemini 2.5 Pro across shallow foundation and pile design scenarios. The router-based configuration achieved performance scores of 95.00% for shallow foundations and 90.63% for pile design, representing improvements of 8.75 and 3.13 percentage points over standalone Grok 3 performance respectively. The system outperformed conventional agentic workflows by 10.0 to 43.75 percentage points. Grok 3 demonstrated superior standalone performance without external computational tools, indicating advances in direct LLM mathematical reasoning for engineering applications. The dual-tier classification framework successfully distinguished foundation types, enabling appropriate analytical approaches. Results establish router-based multi-agent systems as optimal for foundation design automation while maintaining professional documentation standards. Given safety-critical requirements in civil engineering, continued human oversight remains essential, positioning these systems as advanced computational assistance tools rather than autonomous design replacements in professional practice.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item64\">[64]</a>\n",
       "<a href=\"/abs/2506.13817\" id=\"2506.13817\" title=\"Abstract\">\n",
       "        arXiv:2506.13817\n",
       "      </a>\n",
       "          (cross-list from q-bio.GN)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13817\" href=\"/pdf/2506.13817\" id=\"pdf-2506.13817\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13817\" href=\"https://arxiv.org/html/2506.13817v1\" id=\"html-2506.13817\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13817\" href=\"/format/2506.13817\" id=\"oth-2506.13817\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Dajani,+S+A+A\">Saleem A. Al Dajani</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sanchez,+A\">Abel Sanchez</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Williams,+J+R\">John R. Williams</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          4 pages, 5 figures, Accepted by ICML 2025 FM4LS <a class=\"link-external link-https\" href=\"https://openreview.net/forum?id=zNjXOZxEYB\" rel=\"external noopener nofollow\">this https URL</a> . Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences (FM4LS)}, July 2025\n",
       "        </div>\n",
       "<div class=\"list-journal-ref\"><span class=\"descriptor\">Journal-ref:</span>\n",
       "          International Conference on Machine Learning (ICML). Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences (FM4LS), July 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE); Quantitative Methods (q-bio.QM)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Generative AI foundation models offer transformative potential for processing structured biological data, particularly in single-cell RNA sequencing, where datasets are rapidly scaling toward billions of cells. We propose the use of agentic foundation models with real-time web search to automate the labeling of experimental data, achieving up to 82.5% accuracy. This addresses a key bottleneck in supervised learning for structured omics data by increasing annotation throughput without manual curation and human error. Our approach enables the development of virtual cell foundation models capable of downstream tasks such as cell-typing and perturbation prediction. As data volume grows, these models may surpass human performance in labeling, paving the way for reliable inference in large-scale perturbation screens. This application demonstrates domain-specific innovation in health monitoring and diagnostics, aligned with efforts like the Human Cell Atlas and Human Tumor Atlas Network.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item65\">[65]</a>\n",
       "<a href=\"/abs/2506.13820\" id=\"2506.13820\" title=\"Abstract\">\n",
       "        arXiv:2506.13820\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13820\" href=\"/pdf/2506.13820\" id=\"pdf-2506.13820\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13820\" href=\"https://arxiv.org/html/2506.13820v1\" id=\"html-2506.13820\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13820\" href=\"/format/2506.13820\" id=\"oth-2506.13820\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Structured Program Synthesis using LLMs: Results and Insights from the IPARC Challenge\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Surana,+S\">Shraddha Surana</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ashwin\">Ashwin Srinivasan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bain,+M\">Michael Bain</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The IPARC Challenge, inspired by ARC, provides controlled program synthesis tasks over synthetic images to evaluate automatic program construction, focusing on sequence, selection, and iteration. This set of 600 tasks has resisted automated solutions. This paper presents a structured inductive programming approach with LLMs that successfully solves tasks across all IPARC categories. The controlled nature of IPARC reveals insights into LLM-based code generation, including the importance of prior structuring, LLMs' ability to aid structuring (requiring human refinement), the need to freeze correct code, the efficiency of code reuse, and how LLM-generated code can spark human creativity. These findings suggest valuable mechanisms for human-LLM collaboration in tackling complex program synthesis.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item66\">[66]</a>\n",
       "<a href=\"/abs/2506.13824\" id=\"2506.13824\" title=\"Abstract\">\n",
       "        arXiv:2506.13824\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13824\" href=\"/pdf/2506.13824\" id=\"pdf-2506.13824\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13824\" href=\"https://arxiv.org/html/2506.13824v1\" id=\"html-2506.13824\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13824\" href=\"/format/2506.13824\" id=\"oth-2506.13824\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+J\">Jinyang Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+X\">Xiachong Feng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Q\">Qiguang Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+H\">Hanjie Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+Z\">Zihui Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bai,+J\">Jiesong Bai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+J\">Jingxuan Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+M\">Min Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qin,+L\">Libo Qin</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ACL 2025 Findings\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Code debugging is a crucial task in software engineering, which attracts increasing attention. While remarkable success has been made in the era of large language models (LLMs), current research still focuses on the simple no-library or single-library setting, ignoring the complex multi-library scenario in real-world applications. To address this limitation, we make the first attempt to introduce MLDebugging (Multi-Library Debugging), a comprehensive benchmark designed to assess debugging challenges within multi-library Python code. Specifically, MLDebugging encompasses 126 distinct Python libraries, covering a wide range of multi-library code issues, categorized into seven distinct types. Furthermore, we conduct a thorough evaluation of MLDebugging using both mainstream open-source and closed-source LLMs and highlight that current LLMs still struggle to correctly perform code debugging across multi-library scenarios. We hope this work can uncover the potential of LLMs in multi-library debugging scenario and offer insights for future research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item67\">[67]</a>\n",
       "<a href=\"/abs/2506.13827\" id=\"2506.13827\" title=\"Abstract\">\n",
       "        arXiv:2506.13827\n",
       "      </a>\n",
       "          (cross-list from cs.GR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13827\" href=\"/pdf/2506.13827\" id=\"pdf-2506.13827\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13827\" href=\"https://arxiv.org/html/2506.13827v1\" id=\"html-2506.13827\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13827\" href=\"/format/2506.13827\" id=\"oth-2506.13827\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zhuoying Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Z\">Zhu Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+Y\">Yuxin Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yang Liu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Instruction-based image editing, which aims to modify the image faithfully according to the instruction while preserving irrelevant content unchanged, has made significant progress. However, there still lacks a comprehensive metric for assessing the editing quality. Existing metrics either require high human evaluation costs, which hinder large-scale evaluation, or are adapted from other tasks and lose task-specific concerns, failing to comprehensively evaluate both instruction-based modification and preservation of irrelevant regions, resulting in biased evaluation. To tackle this, we introduce a new metric called Balancing Preservation and Modification (BPM), tailored for instruction-based image editing by explicitly disentangling the image into editing-relevant and irrelevant regions for specific consideration. We first identify and locate editing-relevant regions, followed by a two-tier process to assess editing quality: Region-Aware Judge evaluates whether the position and size of the edited region align with the instruction, and Semantic-Aware Judge further assesses the instruction content compliance within editing-relevant regions as well as content preservation within irrelevant regions, yielding comprehensive and interpretable quality assessment. Moreover, the editing-relevant region localization in BPM can be integrated into image editing approaches to improve editing quality, demonstrating its broad applicability. We verify the effectiveness of the BPM metric on comprehensive instruction-editing data, and the results show the highest alignment with human evaluation compared to existing metrics, indicating its efficacy. Code is available at: <a class=\"link-external link-https\" href=\"https://joyli-x.github.io/BPM/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item68\">[68]</a>\n",
       "<a href=\"/abs/2506.13831\" id=\"2506.13831\" title=\"Abstract\">\n",
       "        arXiv:2506.13831\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13831\" href=\"/pdf/2506.13831\" id=\"pdf-2506.13831\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13831\" href=\"https://arxiv.org/html/2506.13831v1\" id=\"html-2506.13831\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13831\" href=\"/format/2506.13831\" id=\"oth-2506.13831\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Quantifying Structure in CLIP Embeddings: A Statistical Framework for Concept Interpretation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+J\">Jitian Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Chenghui Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sala,+F\">Frederic Sala</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rohe,+K\">Karl Rohe</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Concept-based approaches, which aim to identify human-understandable concepts within a model's internal representations, are a promising method for interpreting embeddings from deep neural network models, such as CLIP. While these approaches help explain model behavior, current methods lack statistical rigor, making it challenging to validate identified concepts and compare different techniques. To address this challenge, we introduce a hypothesis testing framework that quantifies rotation-sensitive structures within the CLIP embedding space. Once such structures are identified, we propose a post-hoc concept decomposition method. Unlike existing approaches, it offers theoretical guarantees that discovered concepts represent robust, reproducible patterns (rather than method-specific artifacts) and outperforms other techniques in terms of reconstruction error. Empirically, we demonstrate that our concept-based decomposition algorithm effectively balances reconstruction accuracy with concept interpretability and helps mitigate spurious cues in data. Applied to a popular spurious correlation dataset, our method yields a 22.6% increase in worst-group accuracy after removing spurious background concepts.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item69\">[69]</a>\n",
       "<a href=\"/abs/2506.13832\" id=\"2506.13832\" title=\"Abstract\">\n",
       "        arXiv:2506.13832\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13832\" href=\"/pdf/2506.13832\" id=\"pdf-2506.13832\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13832\" href=\"https://arxiv.org/html/2506.13832v1\" id=\"html-2506.13832\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13832\" href=\"/format/2506.13832\" id=\"oth-2506.13832\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          FrontendBench: A Benchmark for Evaluating LLMs on Front-End Development via Automatic Evaluation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+H\">Hongda Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y\">Yiwen Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+B\">Bing Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ding,+J\">Jingzhe Ding</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Siyao Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+T\">Tong Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+D\">Dandan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yanan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zhaojian Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Language Models (LLMs) have made significant strides in front-end code generation. However, existing benchmarks exhibit several critical limitations: many tasks are overly simplistic, test cases often lack rigor, and end-to-end validation is absent. These issues hinder the accurate assessment of model performance. To address these challenges, we present FrontendBench, a benchmark co-developed by humans and LLMs. FrontendBench categorizes tasks based on code functionality and incorporates interactive test scenarios, enabling a more comprehensive and practical evaluation of front-end code generation capabilities. The benchmark comprises 148 meticulously crafted prompt-test case pairs spanning five levels of web components, from basic UI elements to complex interactive features. Each task reflects realistic front-end development challenges. Furthermore, we introduce an automatic evaluation framework that executes generated code within a sandbox environment and assesses outcomes using predefined test scripts. This framework achieves a 90.54% agreement rate with expert human evaluations, demonstrating high reliability. We benchmark several state-of-the-art LLMs on FrontendBench and observe substantial performance disparities in handling real-world front-end tasks. These results highlight FrontendBench as a reliable and scalable benchmark, supporting consistent multimodal evaluation and providing a robust foundation for future research in front-end code generation. Our data and code will be released soon.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item70\">[70]</a>\n",
       "<a href=\"/abs/2506.13833\" id=\"2506.13833\" title=\"Abstract\">\n",
       "        arXiv:2506.13833\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13833\" href=\"/pdf/2506.13833\" id=\"pdf-2506.13833\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13833\" href=\"https://arxiv.org/html/2506.13833v1\" id=\"html-2506.13833\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13833\" href=\"/format/2506.13833\" id=\"oth-2506.13833\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Survey on World Models Grounded in Acoustic Physical Information\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+X\">Xiaoliang Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chang,+L\">Le Chang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+X\">Xin Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+Y\">Yunhe Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tu,+X\">Xianling Tu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          28 pages,11 equations\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Audio and Speech Processing (eess.AS); Applied Physics (physics.app-ph)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This survey provides a comprehensive overview of the emerging field of world models grounded in the foundation of acoustic physical information. It examines the theoretical underpinnings, essential methodological frameworks, and recent technological advancements in leveraging acoustic signals for high-fidelity environmental perception, causal physical reasoning, and predictive simulation of dynamic events. The survey explains how acoustic signals, as direct carriers of mechanical wave energy from physical events, encode rich, latent information about material properties, internal geometric structures, and complex interaction dynamics. Specifically, this survey establishes the theoretical foundation by explaining how fundamental physical laws govern the encoding of physical information within acoustic signals. It then reviews the core methodological pillars, including Physics-Informed Neural Networks (PINNs), generative models, and self-supervised multimodal learning frameworks. Furthermore, the survey details the significant applications of acoustic world models in robotics, autonomous driving, healthcare, and finance. Finally, it systematically outlines the important technical and ethical challenges while proposing a concrete roadmap for future research directions toward robust, causal, uncertainty-aware, and responsible acoustic intelligence. These elements collectively point to a research pathway towards embodied active acoustic intelligence, empowering AI systems to construct an internal \"intuitive physics\" engine through sound.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item71\">[71]</a>\n",
       "<a href=\"/abs/2506.13834\" id=\"2506.13834\" title=\"Abstract\">\n",
       "        arXiv:2506.13834\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13834\" href=\"/pdf/2506.13834\" id=\"pdf-2506.13834\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13834\" href=\"https://arxiv.org/html/2506.13834v1\" id=\"html-2506.13834\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13834\" href=\"/format/2506.13834\" id=\"oth-2506.13834\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Evolvable Conditional Diffusion\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wei,+Z\">Zhao Wei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ooi,+C+C\">Chin Chun Ooi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gupta,+A\">Abhishek Gupta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wong,+J+C\">Jian Cheng Wong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chiu,+P\">Pao-Hsiung Chiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toh,+S+X+W\">Sheares Xue Wen Toh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ong,+Y\">Yew-Soon Ong</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This paper presents an evolvable conditional diffusion method such that black-box, non-differentiable multi-physics models, as are common in domains like computational fluid dynamics and electromagnetics, can be effectively used for guiding the generative process to facilitate autonomous scientific discovery. We formulate the guidance as an optimization problem where one optimizes for a desired fitness function through updates to the descriptive statistic for the denoising distribution, and derive an evolution-guided approach from first principles through the lens of probabilistic evolution. Interestingly, the final derived update algorithm is analogous to the update as per common gradient-based guided diffusion models, but without ever having to compute any derivatives. We validate our proposed evolvable diffusion algorithm in two AI for Science scenarios: the automated design of fluidic topology and meta-surface. Results demonstrate that this method effectively generates designs that better satisfy specific optimization objectives without reliance on differentiable proxies, providing an effective means of guidance-based diffusion that can capitalize on the wealth of black-box, non-differentiable multi-physics numerical models common across Science.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item72\">[72]</a>\n",
       "<a href=\"/abs/2506.13836\" id=\"2506.13836\" title=\"Abstract\">\n",
       "        arXiv:2506.13836\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13836\" href=\"/pdf/2506.13836\" id=\"pdf-2506.13836\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13836\" href=\"https://arxiv.org/html/2506.13836v1\" id=\"html-2506.13836\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13836\" href=\"/format/2506.13836\" id=\"oth-2506.13836\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen,+D+V+A\">Dang Viet Anh Nguyen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Azevedo,+C+L\">Carlos Lima Azevedo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toledo,+T\">Tomer Toledo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rodrigues,+F\">Filipe Rodrigues</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          35 pages, 5 figures, 3 tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a promising approach for improving urban mobility. However, its robustness under real-world disruptions such as traffic incidents remains largely underexplored. In this study, we introduce T-REX, an open-source, SUMO-based simulation framework for training and evaluating RL-TSC methods under dynamic, incident scenarios. T-REX models realistic network-level performance considering drivers' probabilistic rerouting, speed adaptation, and contextual lane-changing, enabling the simulation of congestion propagation under incidents. To assess robustness, we propose a suite of metrics that extend beyond conventional traffic efficiency measures. Through extensive experiments across synthetic and real-world networks, we showcase T-REX for the evaluation of several state-of-the-art RL-TSC methods under multiple real-world deployment paradigms. Our findings show that while independent value-based and decentralized pressure-based methods offer fast convergence and generalization in stable traffic conditions and homogeneous networks, their performance degrades sharply under incident-driven distribution shifts. In contrast, hierarchical coordination methods tend to offer more stable and adaptable performance in large-scale, irregular networks, benefiting from their structured decision-making architecture. However, this comes with the trade-off of slower convergence and higher training complexity. These findings highlight the need for robustness-aware design and evaluation in RL-TSC research. T-REX contributes to this effort by providing an open, standardized and reproducible platform for benchmarking RL methods under dynamic and disruptive traffic scenarios.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item73\">[73]</a>\n",
       "<a href=\"/abs/2506.13838\" id=\"2506.13838\" title=\"Abstract\">\n",
       "        arXiv:2506.13838\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13838\" href=\"/pdf/2506.13838\" id=\"pdf-2506.13838\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13838\" href=\"https://arxiv.org/html/2506.13838v1\" id=\"html-2506.13838\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13838\" href=\"/format/2506.13838\" id=\"oth-2506.13838\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Poenaru-Olaru,+L\">Lorena Poenaru-Olaru</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sallou,+J\">June Sallou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cruz,+L\">Luis Cruz</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rellermeyer,+J\">Jan Rellermeyer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=van+Deursen,+A\">Arie van Deursen</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          12 pages. Accepted at ICT4Sustainability 2025 conference\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The reliability of machine learning (ML) software systems is heavily influenced by changes in data over time. For that reason, ML systems require regular maintenance, typically based on model retraining. However, retraining requires significant computational demand, which makes it energy-intensive and raises concerns about its environmental impact. To understand which retraining techniques should be considered when designing sustainable ML applications, in this work, we study the energy consumption of common retraining techniques. Since the accuracy of ML systems is also essential, we compare retraining techniques in terms of both energy efficiency and accuracy. We showcase that retraining with only the most recent data, compared to all available data, reduces energy consumption by up to 25\\%, being a sustainable alternative to the status quo. Furthermore, our findings show that retraining a model only when there is evidence that updates are necessary, rather than on a fixed schedule, can reduce energy consumption by up to 40\\%, provided a reliable data change detector is in place. Our findings pave the way for better recommendations for ML practitioners, guiding them toward more energy-efficient retraining techniques when designing sustainable ML software systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item74\">[74]</a>\n",
       "<a href=\"/abs/2506.13845\" id=\"2506.13845\" title=\"Abstract\">\n",
       "        arXiv:2506.13845\n",
       "      </a>\n",
       "          (cross-list from cs.CY)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13845\" href=\"/pdf/2506.13845\" id=\"pdf-2506.13845\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13845\" href=\"https://arxiv.org/html/2506.13845v1\" id=\"html-2506.13845\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13845\" href=\"/format/2506.13845\" id=\"oth-2506.13845\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Students' Reliance on AI in Higher Education: Identifying Contributing Factors\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pitts,+G\">Griffin Pitts</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rani,+N\">Neha Rani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mildort,+W\">Weedguet Mildort</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cook,+E\">Eva-Marie Cook</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The increasing availability and use of artificial intelligence (AI) tools in educational settings has raised concerns about students' overreliance on these technologies. Overreliance occurs when individuals accept incorrect AI-generated recommendations, often without critical evaluation, leading to flawed problem solutions and undermining learning outcomes. This study investigates potential factors contributing to patterns of AI reliance among undergraduate students, examining not only overreliance but also appropriate reliance (correctly accepting helpful and rejecting harmful recommendations) and underreliance (incorrectly rejecting helpful recommendations). Our approach combined pre- and post-surveys with a controlled experimental task where participants solved programming problems with an AI assistant that provided both accurate and deliberately incorrect suggestions, allowing direct observation of students' reliance patterns when faced with varying AI reliability. We find that appropriate reliance is significantly related to students' programming self-efficacy, programming literacy, and need for cognition, while showing negative correlations with post-task trust and satisfaction. Overreliance showed significant correlations with post-task trust and satisfaction with the AI assistant. Underreliance was negatively correlated with programming literacy, programming self-efficacy, and need for cognition. Overall, the findings provide insights for developing targeted interventions that promote appropriate reliance on AI tools, with implications for the integration of AI in curriculum and educational technologies.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item75\">[75]</a>\n",
       "<a href=\"/abs/2506.13846\" id=\"2506.13846\" title=\"Abstract\">\n",
       "        arXiv:2506.13846\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13846\" href=\"/pdf/2506.13846\" id=\"pdf-2506.13846\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13846\" href=\"https://arxiv.org/html/2506.13846v1\" id=\"html-2506.13846\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13846\" href=\"/format/2506.13846\" id=\"oth-2506.13846\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Fake it till You Make it: Reward Modeling as Discriminative Prediction\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+R\">Runtao Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan,+J\">Jiahao Zhan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Y\">Yingqing He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wei,+C\">Chen Wei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuille,+A\">Alan Yuille</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Q\">Qifeng Chen</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          An effective reward model plays a pivotal role in reinforcement learning for post-training enhancement of visual generative models. However, current approaches of reward modeling suffer from implementation complexity due to their reliance on extensive human-annotated preference data or meticulously engineered quality dimensions that are often incomplete and engineering-intensive. Inspired by adversarial training in generative adversarial networks (GANs), this paper proposes GAN-RM, an efficient reward modeling framework that eliminates manual preference annotation and explicit quality dimension engineering. Our method trains the reward model through discrimination between a small set of representative, unpaired target samples(denoted as Preference Proxy Data) and model-generated ordinary outputs, requiring only a few hundred target samples. Comprehensive experiments demonstrate our GAN-RM's effectiveness across multiple key applications including test-time scaling implemented as Best-of-N sample filtering, post-training approaches like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item76\">[76]</a>\n",
       "<a href=\"/abs/2506.13862\" id=\"2506.13862\" title=\"Abstract\">\n",
       "        arXiv:2506.13862\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13862\" href=\"/pdf/2506.13862\" id=\"pdf-2506.13862\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13862\" href=\"https://arxiv.org/html/2506.13862v1\" id=\"html-2506.13862\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13862\" href=\"/format/2506.13862\" id=\"oth-2506.13862\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          StaQ it! Growing neural networks for Policy Mirror Descent\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shilova,+A\">Alena Shilova</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Davey,+A\">Alex Davey</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Driss,+B\">Brahim Driss</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Akrour,+R\">Riad Akrour</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          44 pages, 12 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In Reinforcement Learning (RL), regularization has emerged as a popular tool both in theory and practice, typically based either on an entropy bonus or a Kullback-Leibler divergence that constrains successive policies. In practice, these approaches have been shown to improve exploration, robustness and stability, giving rise to popular Deep RL algorithms such as SAC and TRPO. Policy Mirror Descent (PMD) is a theoretical framework that solves this general regularized policy optimization problem, however the closed-form solution involves the sum of all past Q-functions, which is intractable in practice. We propose and analyze PMD-like algorithms that only keep the last $M$ Q-functions in memory, and show that for finite and large enough $M$, a convergent algorithm can be derived, introducing no error in the policy update, unlike prior deep RL PMD implementations. StaQ, the resulting algorithm, enjoys strong theoretical guarantees and is competitive with deep RL baselines, while exhibiting less performance oscillation, paving the way for fully stable deep RL algorithms and providing a testbed for experimentation with Policy Mirror Descent.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item77\">[77]</a>\n",
       "<a href=\"/abs/2506.13886\" id=\"2506.13886\" title=\"Abstract\">\n",
       "        arXiv:2506.13886\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13886\" href=\"/pdf/2506.13886\" id=\"pdf-2506.13886\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13886\" href=\"https://arxiv.org/html/2506.13886v1\" id=\"html-2506.13886\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13886\" href=\"/format/2506.13886\" id=\"oth-2506.13886\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharya,+A+R\">Antara Raaghavi Bhattacharya</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Papadimitriou,+I\">Isabel Papadimitriou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Davidson,+K\">Kathryn Davidson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarez-Melis,+D\">David Alvarez-Melis</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Across languages, numeral systems vary widely in how they construct and combine numbers. While humans consistently learn to navigate this diversity, large language models (LLMs) struggle with linguistic-mathematical puzzles involving cross-linguistic numeral systems, which humans can learn to solve successfully. We investigate why this task is difficult for LLMs through a series of experiments that untangle the linguistic and mathematical aspects of numbers in language. Our experiments establish that models cannot consistently solve such problems unless the mathematical operations in the problems are explicitly marked using known symbols ($+$, $\\times$, etc, as in \"twenty + three\"). In further ablation studies, we probe how individual parameters of numeral construction and combination affect performance. While humans use their linguistic understanding of numbers to make inferences about the implicit compositional structure of numerals, LLMs seem to lack this notion of implicit numeral structure. We conclude that the ability to flexibly infer compositional rules from implicit patterns in human-scale data remains an open challenge for current reasoning models.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item78\">[78]</a>\n",
       "<a href=\"/abs/2506.13892\" id=\"2506.13892\" title=\"Abstract\">\n",
       "        arXiv:2506.13892\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13892\" href=\"/pdf/2506.13892\" id=\"pdf-2506.13892\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13892\" href=\"https://arxiv.org/html/2506.13892v1\" id=\"html-2506.13892\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13892\" href=\"/format/2506.13892\" id=\"oth-2506.13892\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Scaling Algorithm Distillation for Continuous Control with Mamba\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Beaussant,+S\">Samuel Beaussant</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mounsif,+M\">Mehdi Mounsif</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Algorithm Distillation (AD) was recently proposed as a new approach to perform In-Context Reinforcement Learning (ICRL) by modeling across-episodic training histories autoregressively with a causal transformer model. However, due to practical limitations induced by the attention mechanism, experiments were bottlenecked by the transformer's quadratic complexity and limited to simple discrete environments with short time horizons. In this work, we propose leveraging the recently proposed Selective Structured State Space Sequence (S6) models, which achieved state-of-the-art (SOTA) performance on long-range sequence modeling while scaling linearly in sequence length. Through four complex and continuous Meta Reinforcement Learning environments, we demonstrate the overall superiority of Mamba, a model built with S6 layers, over a transformer model for AD. Additionally, we show that scaling AD to very long contexts can improve ICRL performance and make it competitive even with a SOTA online meta RL baseline.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item79\">[79]</a>\n",
       "<a href=\"/abs/2506.13900\" id=\"2506.13900\" title=\"Abstract\">\n",
       "        arXiv:2506.13900\n",
       "      </a>\n",
       "          (cross-list from stat.ML)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13900\" href=\"/pdf/2506.13900\" id=\"pdf-2506.13900\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13900\" href=\"https://arxiv.org/html/2506.13900v1\" id=\"html-2506.13900\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13900\" href=\"/format/2506.13900\" id=\"oth-2506.13900\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Beyond Shapley Values: Cooperative Games for the Interpretation of Machine Learning Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Idrissi,+M+I\">Marouane Il Idrissi</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Machado,+A+F\">Agathe Fernandes Machado</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Charpentier,+A\">Arthur Charpentier</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Cooperative game theory has become a cornerstone of post-hoc interpretability in machine learning, largely through the use of Shapley values. Yet, despite their widespread adoption, Shapley-based methods often rest on axiomatic justifications whose relevance to feature attribution remains debatable. In this paper, we revisit cooperative game theory from an interpretability perspective and argue for a broader and more principled use of its tools. We highlight two general families of efficient allocations, the Weber and Harsanyi sets, that extend beyond Shapley values and offer richer interpretative flexibility. We present an accessible overview of these allocation schemes, clarify the distinction between value functions and aggregation rules, and introduce a three-step blueprint for constructing reliable and theoretically-grounded feature attributions. Our goal is to move beyond fixed axioms and provide the XAI community with a coherent framework to design attribution methods that are both meaningful and robust to shifting methodological trends.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item80\">[80]</a>\n",
       "<a href=\"/abs/2506.13901\" id=\"2506.13901\" title=\"Abstract\">\n",
       "        arXiv:2506.13901\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13901\" href=\"/pdf/2506.13901\" id=\"pdf-2506.13901\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13901\" href=\"https://arxiv.org/html/2506.13901v1\" id=\"html-2506.13901\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13901\" href=\"/format/2506.13901\" id=\"oth-2506.13901\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Borah,+A\">Abhilekh Borah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+C\">Chhavi Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Khanna,+D\">Danush Khanna</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bhatt,+U\">Utkarsh Bhatt</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+G\">Gurpreet Singh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abdullah,+H+M\">Hasnat Md Abdullah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ravi,+R+K\">Raghav Kaushik Ravi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jain,+V\">Vinija Jain</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Patel,+J\">Jyoti Patel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+S\">Shubham Singh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+V\">Vasu Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vats,+A\">Arpita Vats</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Raja,+R\">Rahul Raja</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chadha,+A\">Aman Chadha</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Das,+A\">Amitava Das</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Alignment is no longer a luxury, it is a necessity. As large language models (LLMs) enter high-stakes domains like education, healthcare, governance, and law, their behavior must reliably reflect human-aligned values and safety constraints. Yet current evaluations rely heavily on behavioral proxies such as refusal rates, G-Eval scores, and toxicity classifiers, all of which have critical blind spots. Aligned models are often vulnerable to jailbreaking, stochasticity of generation, and alignment faking.\n",
       "<br/>To address this issue, we introduce the Alignment Quality Index (AQI). This novel geometric and prompt-invariant metric empirically assesses LLM alignment by analyzing the separation of safe and unsafe activations in latent space. By combining measures such as the Davies-Bouldin Score (DBS), Dunn Index (DI), Xie-Beni Index (XBI), and Calinski-Harabasz Index (CHI) across various formulations, AQI captures clustering quality to detect hidden misalignments and jailbreak risks, even when outputs appear compliant. AQI also serves as an early warning signal for alignment faking, offering a robust, decoding invariant tool for behavior agnostic safety auditing.\n",
       "<br/>Additionally, we propose the LITMUS dataset to facilitate robust evaluation under these challenging conditions. Empirical tests on LITMUS across different models trained under DPO, GRPO, and RLHF conditions demonstrate AQI's correlation with external judges and ability to reveal vulnerabilities missed by refusal metrics. We make our implementation publicly available to foster future research in this area.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item81\">[81]</a>\n",
       "<a href=\"/abs/2506.13903\" id=\"2506.13903\" title=\"Abstract\">\n",
       "        arXiv:2506.13903\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13903\" href=\"/pdf/2506.13903\" id=\"pdf-2506.13903\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13903\" href=\"https://arxiv.org/html/2506.13903v1\" id=\"html-2506.13903\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13903\" href=\"/format/2506.13903\" id=\"oth-2506.13903\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Enhancing interpretability of rule-based classifiers through feature graphs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sirocchi,+C\">Christel Sirocchi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Verda,+D\">Damiano Verda</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In domains where transparency and trustworthiness are crucial, such as healthcare, rule-based systems are widely used and often preferred over black-box models for decision support systems due to their inherent interpretability. However, as rule-based models grow complex, discerning crucial features, understanding their interactions, and comparing feature contributions across different rule sets becomes challenging. To address this, we propose a comprehensive framework for estimating feature contributions in rule-based systems, introducing a graph-based feature visualisation strategy, a novel feature importance metric agnostic to rule-based predictors, and a distance metric for comparing rule sets based on feature contributions. By experimenting on two clinical datasets and four rule-based methods (decision trees, logic learning machines, association rules, and neural networks with rule extraction), we showcase our method's capability to uncover novel insights on the combined predictive value of clinical features, both at the dataset and class-specific levels. These insights can aid in identifying new risk factors, signature genes, and potential biomarkers, and determining the subset of patient information that should be prioritised to enhance diagnostic accuracy. Comparative analysis of the proposed feature importance score with state-of-the-art methods on 15 public benchmarks demonstrates competitive performance and superior robustness. The method implementation is available on GitHub: <a class=\"link-external link-https\" href=\"https://github.com/ChristelSirocchi/rule-graph\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item82\">[82]</a>\n",
       "<a href=\"/abs/2506.13904\" id=\"2506.13904\" title=\"Abstract\">\n",
       "        arXiv:2506.13904\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13904\" href=\"/pdf/2506.13904\" id=\"pdf-2506.13904\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13904\" href=\"/format/2506.13904\" id=\"oth-2506.13904\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Systematic Review of User-Centred Evaluation of Explainable AI in Healthcare\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Donoso-Guzm%C3%A1n,+I\">Ivania Donoso-Guzmán</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kacaf%C3%ADrkov%C3%A1,+K+S\">Kristýna Sirka Kacafírková</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Szymanski,+M\">Maxwell Szymanski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jacobs,+A\">An Jacobs</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parra,+D\">Denis Parra</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Verbert,+K\">Katrien Verbert</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite promising developments in Explainable Artificial Intelligence, the practical value of XAI methods remains under-explored and insufficiently validated in real-world settings. Robust and context-aware evaluation is essential, not only to produce understandable explanations but also to ensure their trustworthiness and usability for intended users, but tends to be overlooked because of no clear guidelines on how to design an evaluation with users.\n",
       "<br/>This study addresses this gap with two main goals: (1) to develop a framework of well-defined, atomic properties that characterise the user experience of XAI in healthcare; and (2) to provide clear, context-sensitive guidelines for defining evaluation strategies based on system characteristics.\n",
       "<br/>We conducted a systematic review of 82 user studies, sourced from five databases, all situated within healthcare settings and focused on evaluating AI-generated explanations. The analysis was guided by a predefined coding scheme informed by an existing evaluation framework, complemented by inductive codes developed iteratively.\n",
       "<br/>The review yields three key contributions: (1) a synthesis of current evaluation practices, highlighting a growing focus on human-centred approaches in healthcare XAI; (2) insights into the interrelations among explanation properties; and (3) an updated framework and a set of actionable guidelines to support interdisciplinary teams in designing and implementing effective evaluation strategies for XAI systems tailored to specific application contexts.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item83\">[83]</a>\n",
       "<a href=\"/abs/2506.13909\" id=\"2506.13909\" title=\"Abstract\">\n",
       "        arXiv:2506.13909\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13909\" href=\"/pdf/2506.13909\" id=\"pdf-2506.13909\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13909\" href=\"https://arxiv.org/html/2506.13909v1\" id=\"html-2506.13909\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13909\" href=\"/format/2506.13909\" id=\"oth-2506.13909\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tu,+X\">Xinyuan Tu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+H\">Haocheng Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chengxu,+T\">Tao Chengxu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Z\">Zuyi Chen</a> (Friedrich-Alexander-Universität Erlangen, Germany)</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Few-shot learning (FSL) has shown promise in vision but remains largely unexplored for \\emph{industrial} time-series data, where annotating every new defect is prohibitively expensive. We present a systematic FSL study on screw-fastening process monitoring, using a 2\\,300-sample multivariate torque dataset that covers 16 uni- and multi-factorial defect types. Beyond benchmarking, we introduce a \\textbf{label-aware episodic sampler} that collapses multi-label sequences into multiple single-label tasks, keeping the output dimensionality fixed while preserving combinatorial label information.\n",
       "<br/>Two FSL paradigms are investigated: the metric-based \\emph{Prototypical Network} and the gradient-based \\emph{Model-Agnostic Meta-Learning} (MAML), each paired with three backbones: 1D CNN, InceptionTime and the 341 M-parameter transformer \\emph{Moment}. On 10-shot, 3-way evaluation, the InceptionTime + Prototypical Network combination achieves a \\textbf{0.944 weighted F1} in the multi-class regime and \\textbf{0.935} in the multi-label regime, outperforming finetuned Moment by up to 5.3\\% while requiring two orders of magnitude fewer parameters and training time. Across all backbones, metric learning consistently surpasses MAML, and our label-aware sampling yields an additional 1.7\\% F1 over traditional class-based sampling.\n",
       "<br/>These findings challenge the assumption that large foundation models are always superior: when data are scarce, lightweight CNN architectures augmented with simple metric learning not only converge faster but also generalize better. We release code, data splits and pre-trained weights to foster reproducible research and to catalyze the adoption of FSL in high-value manufacturing inspection.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item84\">[84]</a>\n",
       "<a href=\"/abs/2506.13910\" id=\"2506.13910\" title=\"Abstract\">\n",
       "        arXiv:2506.13910\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13910\" href=\"/pdf/2506.13910\" id=\"pdf-2506.13910\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13910\" href=\"/format/2506.13910\" id=\"oth-2506.13910\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dutta,+A\">Aritra Dutta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Boral,+P\">Pushpita Boral</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Suseela,+G\">G Suseela</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The increasing global crime rate, coupled with substantial human and property losses, highlights the limitations of traditional surveillance methods in promptly detecting diverse and unexpected acts of violence. Addressing this pressing need for automatic violence detection, we leverage Machine Learning to detect and categorize violent events in video streams. This paper introduces a comprehensive framework for violence detection and classification, employing Supervised Learning for both binary and multi-class violence classification. The detection model relies on 3D Convolutional Neural Networks, while the classification model utilizes the separable convolutional 3D model for feature extraction and bidirectional LSTM for temporal processing. Training is conducted on a diverse customized datasets with frame-level annotations, incorporating videos from surveillance cameras, human recordings, hockey fight, sohas and wvd dataset across various platforms. Additionally, a camera module integrated with raspberry pi is used to capture live video feed, which is sent to the ML model for processing. Thus, demonstrating improved performance in terms of computational resource efficiency and accuracy.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item85\">[85]</a>\n",
       "<a href=\"/abs/2506.13911\" id=\"2506.13911\" title=\"Abstract\">\n",
       "        arXiv:2506.13911\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13911\" href=\"/pdf/2506.13911\" id=\"pdf-2506.13911\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13911\" href=\"/format/2506.13911\" id=\"oth-2506.13911\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Soeteman,+A\">Arie Soeteman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cate,+B+t\">Balder ten Cate</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Submitted to NeurIPS 2025, 28 pages, 5 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an expressive extension of graph neural networks (GNNs) with hierarchical node individualization, inspired by the Individualization-Refinement paradigm for graph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy of increasingly expressive models that, in the limit, can distinguish graphs up to isomorphism. We provide a logical characterization of HEGNN node classifiers, with and without subgraph restrictions, using graded hybrid logic. This characterization enables us to relate the separating power of HEGNNs to that of higher-order GNNs, GNNs enriched with local homomorphism count features, and color refinement algorithms based on Individualization-Refinement. Our experimental results confirm the practical feasibility of HEGNNs and show benefits in comparison with traditional GNN architectures, both with and without local homomorphism count features.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item86\">[86]</a>\n",
       "<a href=\"/abs/2506.13923\" id=\"2506.13923\" title=\"Abstract\">\n",
       "        arXiv:2506.13923\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13923\" href=\"/pdf/2506.13923\" id=\"pdf-2506.13923\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13923\" href=\"https://arxiv.org/html/2506.13923v1\" id=\"html-2506.13923\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13923\" href=\"/format/2506.13923\" id=\"oth-2506.13923\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nath,+V\">Vaskar Nath</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lau,+E\">Elaine Lau</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gunjal,+A\">Anisha Gunjal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+M\">Manasi Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Baharte,+N\">Nikhil Baharte</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hendryx,+S\">Sean Hendryx</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance through two main means: (1) by compressing pass@$k$ into pass@1 and (2) via \"capability gain\" in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B on &gt;500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $\\text{Guide}$ - a new class of online training algorithms. $\\text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the \"off-policy\" trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $\\text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$\\%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $\\text{Guide}$'s components and theoretically analyze Guide's learning efficiency.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item87\">[87]</a>\n",
       "<a href=\"/abs/2506.13925\" id=\"2506.13925\" title=\"Abstract\">\n",
       "        arXiv:2506.13925\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13925\" href=\"/pdf/2506.13925\" id=\"pdf-2506.13925\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13925\" href=\"https://arxiv.org/html/2506.13925v1\" id=\"html-2506.13925\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13925\" href=\"/format/2506.13925\" id=\"oth-2506.13925\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nadeem,+N\">Numair Nadeem</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Anwar,+S\">Saeed Anwar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Asad,+M+H\">Muhammad Hamza Asad</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bais,+A\">Abdul Bais</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item88\">[88]</a>\n",
       "<a href=\"/abs/2506.13932\" id=\"2506.13932\" title=\"Abstract\">\n",
       "        arXiv:2506.13932\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13932\" href=\"/pdf/2506.13932\" id=\"pdf-2506.13932\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13932\" href=\"https://arxiv.org/html/2506.13932v1\" id=\"html-2506.13932\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13932\" href=\"/format/2506.13932\" id=\"oth-2506.13932\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          How Does LLM Reasoning Work for Code? A Survey and a Call to Action\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ceka,+I\">Ira Ceka</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pujar,+S\">Saurabh Pujar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Manotas,+I\">Irene Manotas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+G\">Gail Kaiser</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ray,+B\">Baishakhi Ray</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ramji,+S\">Shyam Ramji</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The rise of large language models (LLMs) has led to dramatic improvements across a wide range of natural language tasks. These advancements have extended into the domain of code, facilitating complex tasks such as code generation, translation, summarization, and repair. However, their utility for real-world deployment in-the-wild has only recently been studied, particularly on software engineering (SWE) tasks such as GitHub issue resolution. In this study, we examine the code reasoning techniques that underlie the ability to perform such tasks, and examine the paradigms used to drive their performance. Our contributions in this paper are: (1) the first dedicated survey on code reasoning for code tasks, highlighting overarching strategies, hybrid and agentic approaches; (2) a taxonomy of various techniques used to drive code reasoning; (3) a comprehensive overview of performance on common benchmarks and a showcase of new, under-explored benchmarks with high potential in SWE; (4) an exploration on how core properties of code can be used to explain different reasoning techniques; and (5) gaps and potentially under-explored areas for future research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item89\">[89]</a>\n",
       "<a href=\"/abs/2506.13956\" id=\"2506.13956\" title=\"Abstract\">\n",
       "        arXiv:2506.13956\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13956\" href=\"/pdf/2506.13956\" id=\"pdf-2506.13956\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13956\" href=\"https://arxiv.org/html/2506.13956v1\" id=\"html-2506.13956\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13956\" href=\"/format/2506.13956\" id=\"oth-2506.13956\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tsai,+S\">Shang-Chi Tsai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kawano,+S\">Seiya Kawano</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Contreras,+A+G\">Angel Garcia Contreras</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yoshino,+K\">Koichiro Yoshino</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Y\">Yun-Nung Chen</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          IWSDS 2024 Best Paper Award\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          When designing robots to assist in everyday human activities, it is crucial to enhance user requests with visual cues from their surroundings for improved intent understanding. This process is defined as a multimodal classification task. However, gathering a large-scale dataset encompassing both visual and linguistic elements for model training is challenging and time-consuming. To address this issue, our paper introduces a novel framework focusing on data augmentation in robotic assistance scenarios, encompassing both dialogues and related environmental imagery. This approach involves leveraging a sophisticated large language model to simulate potential conversations and environmental contexts, followed by the use of a stable diffusion model to create images depicting these environments. The additionally generated data serves to refine the latest multimodal models, enabling them to more accurately determine appropriate actions in response to user interactions with the limited target data. Our experimental results, based on a dataset collected from real-world scenarios, demonstrate that our methodology significantly enhances the robot's action selection capabilities, achieving the state-of-the-art performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item90\">[90]</a>\n",
       "<a href=\"/abs/2506.13958\" id=\"2506.13958\" title=\"Abstract\">\n",
       "        arXiv:2506.13958\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13958\" href=\"/pdf/2506.13958\" id=\"pdf-2506.13958\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13958\" href=\"https://arxiv.org/html/2506.13958v1\" id=\"html-2506.13958\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13958\" href=\"/format/2506.13958\" id=\"oth-2506.13958\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guiducci,+L\">Leonardo Guiducci</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rizzo,+A\">Antonio Rizzo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dimitri,+G+M\">Giovanna Maria Dimitri</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Elastic Decision Transformers (EDTs) have proved to be particularly successful in offline reinforcement learning, offering a flexible framework that unifies sequence modeling with decision-making under uncertainty. Recent research has shown that incorporating intrinsic motivation mechanisms into EDTs improves performance across exploration tasks, yet the representational mechanisms underlying these improvements remain unexplored. In this paper, we introduce a systematic post-hoc explainability framework to analyze how intrinsic motivation shapes learned embeddings in EDTs. Through statistical analysis of embedding properties (including covariance structure, vector magnitudes, and orthogonality), we reveal that different intrinsic motivation variants create fundamentally different representational structures. Our analysis demonstrates environment-specific correlation patterns between embedding metrics and performance that explain why intrinsic motivation improves policy learning. These findings show that intrinsic motivation operates beyond simple exploration bonuses, acting as a representational prior that shapes embedding geometry in biologically plausible ways, creating environment-specific organizational structures that facilitate better decision-making.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item91\">[91]</a>\n",
       "<a href=\"/abs/2506.13961\" id=\"2506.13961\" title=\"Abstract\">\n",
       "        arXiv:2506.13961\n",
       "      </a>\n",
       "          (cross-list from eess.SY)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13961\" href=\"/pdf/2506.13961\" id=\"pdf-2506.13961\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13961\" href=\"https://arxiv.org/html/2506.13961v1\" id=\"html-2506.13961\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13961\" href=\"/format/2506.13961\" id=\"oth-2506.13961\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Safe Domains of Attraction for Discrete-Time Nonlinear Systems: Characterization and Verifiable Neural Network Estimation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Serry,+M\">Mohamed Serry</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Li,+H\">Haoyu Li</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Zhou,+R\">Ruikun Zhou</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Zhang,+H\">Huan Zhang</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Liu,+J\">Jun Liu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Analysis of nonlinear autonomous systems typically involves estimating domains of attraction, which have been a topic of extensive research interest for decades. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where existing methods are conservative or limited to low-dimensional systems. The estimation becomes even more challenging when accounting for state constraints. In this work, we propose a framework to accurately estimate safe (state-constrained) domains of attraction for discrete-time autonomous nonlinear systems. In establishing this framework, we first derive a new Zubov equation, whose solution corresponds to the exact safe domain of attraction. The solution to the aforementioned Zubov equation is shown to be unique and continuous over the whole state space. We then present a physics-informed approach to approximating the solution of the Zubov equation using neural networks. To obtain certifiable estimates of the domain of attraction from the neural network approximate solutions, we propose a verification framework that can be implemented using standard verification tools (e.g., $\\alpha,\\!\\beta$-CROWN and dReal). To illustrate its effectiveness, we demonstrate our approach through numerical examples concerning nonlinear systems with state constraints.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item92\">[92]</a>\n",
       "<a href=\"/abs/2506.13970\" id=\"2506.13970\" title=\"Abstract\">\n",
       "        arXiv:2506.13970\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13970\" href=\"/pdf/2506.13970\" id=\"pdf-2506.13970\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13970\" href=\"/format/2506.13970\" id=\"oth-2506.13970\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Making deep neural networks work for medical audio: representation, compression and domain adaptation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Onu,+C+C\">Charles C Onu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          PhD Thesis\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This thesis addresses the technical challenges of applying machine learning to understand and interpret medical audio signals. The sounds of our lungs, heart, and voice convey vital information about our health. Yet, in contemporary medicine, these sounds are primarily analyzed through auditory interpretation by experts using devices like stethoscopes. Automated analysis offers the potential to standardize the processing of medical sounds, enable screening in low-resource settings where physicians are scarce, and detect subtle patterns that may elude human perception, thereby facilitating early diagnosis and treatment.\n",
       "<br/>Focusing on the analysis of infant cry sounds to predict medical conditions, this thesis contributes on four key fronts. First, in low-data settings, we demonstrate that large databases of adult speech can be harnessed through neural transfer learning to develop more accurate and robust models for infant cry analysis. Second, in cost-effective modeling, we introduce an end-to-end model compression approach for recurrent networks using tensor decomposition. Our method requires no post-hoc processing, achieves compression rates of several hundred-fold, and delivers accurate, portable models suitable for resource-constrained devices. Third, we propose novel domain adaptation techniques tailored for audio models and adapt existing methods from computer vision. These approaches address dataset bias and enhance generalization across domains while maintaining strong performance on the original data. Finally, to advance research in this domain, we release a unique, open-source dataset of infant cry sounds, developed in collaboration with clinicians worldwide.\n",
       "<br/>This work lays the foundation for recognizing the infant cry as a vital sign and highlights the transformative potential of AI-driven audio monitoring in shaping the future of accessible and affordable healthcare.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item93\">[93]</a>\n",
       "<a href=\"/abs/2506.13981\" id=\"2506.13981\" title=\"Abstract\">\n",
       "        arXiv:2506.13981\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13981\" href=\"/pdf/2506.13981\" id=\"pdf-2506.13981\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13981\" href=\"https://arxiv.org/html/2506.13981v1\" id=\"html-2506.13981\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13981\" href=\"/format/2506.13981\" id=\"oth-2506.13981\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bui,+T+D\">Thanh Dan Bui</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          High-frequency stock price prediction is challenging due to non-stationarity, noise, and volatility. To tackle these issues, we propose the Hybrid Attentive Ensemble Learning Transformer (HAELT), a deep learning framework combining a ResNet-based noise-mitigation module, temporal self-attention for dynamic focus on relevant history, and a hybrid LSTM-Transformer core that captures both local and long-range dependencies. These components are adaptively ensembled based on recent performance. Evaluated on hourly Apple Inc. (AAPL) data from Jan 2024 to May 2025, HAELT achieves the highest F1-Score on the test set, effectively identifying both upward and downward price movements. This demonstrates HAELT's potential for robust, practical financial forecasting and algorithmic trading.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item94\">[94]</a>\n",
       "<a href=\"/abs/2506.13984\" id=\"2506.13984\" title=\"Abstract\">\n",
       "        arXiv:2506.13984\n",
       "      </a>\n",
       "          (cross-list from stat.ML)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13984\" href=\"/pdf/2506.13984\" id=\"pdf-2506.13984\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13984\" href=\"https://arxiv.org/html/2506.13984v1\" id=\"html-2506.13984\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13984\" href=\"/format/2506.13984\" id=\"oth-2506.13984\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Mirror Descent Using the Tempesta Generalized Multi-parametric Logarithms\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Cichocki,+A\">Andrzej Cichocki</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In this paper, we develop a wide class Mirror Descent (MD) algorithms, which play a key role in machine learning. For this purpose we formulated the constrained optimization problem, in which we exploits the Bregman divergence with the Tempesta multi-parametric deformation logarithm as a link function. This link function called also mirror function defines the mapping between the primal and dual spaces and is associated with a very-wide (in fact, theoretically infinite) class of generalized trace-form entropies. In order to derive novel MD updates, we estimate generalized exponential function, which closely approximates the inverse of the multi-parametric Tempesta generalized logarithm. The shape and properties of the Tempesta logarithm and its inverse-deformed exponential functions can be tuned by several hyperparameters. By learning these hyperparameters, we can adapt to distribution or geometry of training data, and we can adjust them to achieve desired properties of MD algorithms. The concept of applying multi-parametric logarithms allow us to generate a new wide and flexible family of MD and mirror-less MD updates.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item95\">[95]</a>\n",
       "<a href=\"/abs/2506.13989\" id=\"2506.13989\" title=\"Abstract\">\n",
       "        arXiv:2506.13989\n",
       "      </a>\n",
       "          (cross-list from cs.SI)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13989\" href=\"/pdf/2506.13989\" id=\"pdf-2506.13989\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13989\" href=\"/format/2506.13989\" id=\"oth-2506.13989\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AMLgentex: Mobilizing Data-Driven Research to Combat Money Laundering\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%96stman,+J\">Johan Östman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Callisen,+E\">Edvin Callisen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+A\">Anton Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ausmees,+K\">Kristiina Ausmees</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=G%C3%A5rdh,+E\">Emanuel Gårdh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zamac,+J\">Jovan Zamac</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Goldsteine,+J\">Jolanta Goldsteine</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wefer,+H\">Hugo Wefer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Whelan,+S\">Simon Whelan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Reimeg%C3%A5rd,+M\">Markus Reimegård</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          21 figures, 22 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Money laundering enables organized crime by allowing illicit funds to enter the legitimate economy. Although trillions of dollars are laundered each year, only a small fraction is ever uncovered. This stems from a range of factors, including deliberate evasion by launderers, the rarity of confirmed cases, and the limited visibility each financial institution has into the global transaction network. While several synthetic datasets are available, they fail to model the structural and behavioral complexity of real-world money laundering. In particular, they often overlook partial observability, sparse and uncertain labels, strategic behavior, temporal dynamics, class imbalance, and network-level dependencies. To address these limitations, we present AMLGentex, an open-source suite for generating realistic, configurable transaction data and benchmarking detection methods. It enables systematic evaluation of anti-money laundering (AML) systems in a controlled environment that captures key real-world challenges. We demonstrate how the framework can be used to rigorously evaluate methods under conditions that reflect the complexity of practical AML scenarios.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item96\">[96]</a>\n",
       "<a href=\"/abs/2506.13992\" id=\"2506.13992\" title=\"Abstract\">\n",
       "        arXiv:2506.13992\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13992\" href=\"/pdf/2506.13992\" id=\"pdf-2506.13992\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13992\" href=\"/format/2506.13992\" id=\"oth-2506.13992\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+A\">An Luo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xian,+X\">Xun Xian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+J\">Jin Du</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tian,+F\">Fangqiao Tian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+G\">Ganghua Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhong,+M\">Ming Zhong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+S\">Shengchun Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bi,+X\">Xuan Bi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z\">Zirui Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+J\">Jiawei Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jayanth\">Jayanth Srinivasa</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kundu,+A\">Ashish Kundu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fleming,+C\">Charles Fleming</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hong,+M\">Mingyi Hong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ding,+J\">Jie Ding</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Methodology (stat.ME)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) have advanced the automation of data science workflows. Yet it remains unclear whether they can critically leverage external domain knowledge as human data scientists do in practice. To answer this question, we introduce AssistedDS (Assisted Data Science), a benchmark designed to systematically evaluate how LLMs handle domain knowledge in tabular prediction tasks. AssistedDS features both synthetic datasets with explicitly known generative mechanisms and real-world Kaggle competitions, each accompanied by curated bundles of helpful and adversarial documents. These documents provide domain-specific insights into data cleaning, feature engineering, and model selection. We assess state-of-the-art LLMs on their ability to discern and apply beneficial versus harmful domain knowledge, evaluating submission validity, information recall, and predictive performance. Our results demonstrate three key findings: (1) LLMs frequently exhibit an uncritical adoption of provided information, significantly impairing their predictive performance when adversarial content is introduced, (2) helpful guidance is often insufficient to counteract the negative influence of adversarial information, and (3) in Kaggle datasets, LLMs often make errors in handling time-series data, applying consistent feature engineering across different folds, and interpreting categorical variables correctly. These findings highlight a substantial gap in current models' ability to critically evaluate and leverage expert knowledge, underscoring an essential research direction for developing more robust, knowledge-aware automated data science systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item97\">[97]</a>\n",
       "<a href=\"/abs/2506.14002\" id=\"2506.14002\" title=\"Abstract\">\n",
       "        arXiv:2506.14002\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14002\" href=\"/pdf/2506.14002\" id=\"pdf-2506.14002\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14002\" href=\"/format/2506.14002\" id=\"oth-2506.14002\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+S\">Siyu Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sheen,+H\">Heejune Sheen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong,+X\">Xuyuan Xiong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+T\">Tianhao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Z\">Zhuoran Yang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          136 pages, 21 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We study the challenge of achieving theoretically grounded feature recovery using Sparse Autoencoders (SAEs) for the interpretation of Large Language Models. Existing SAE training algorithms often lack rigorous mathematical guarantees and suffer from practical limitations such as hyperparameter sensitivity and instability. To address these issues, we first propose a novel statistical framework for the feature recovery problem, which includes a new notion of feature identifiability by modeling polysemantic features as sparse mixtures of underlying monosemantic concepts. Building on this framework, we introduce a new SAE training algorithm based on ``bias adaptation'', a technique that adaptively adjusts neural network bias parameters to ensure appropriate activation sparsity. We theoretically \\highlight{prove that this algorithm correctly recovers all monosemantic features} when input data is sampled from our proposed statistical model. Furthermore, we develop an improved empirical variant, Group Bias Adaptation (GBA), and \\highlight{demonstrate its superior performance against benchmark methods when applied to LLMs with up to 1.5 billion parameters}. This work represents a foundational step in demystifying SAE training by providing the first SAE algorithm with theoretical recovery guarantees, thereby advancing the development of more transparent and trustworthy AI systems through enhanced mechanistic interpretability.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item98\">[98]</a>\n",
       "<a href=\"/abs/2506.14020\" id=\"2506.14020\" title=\"Abstract\">\n",
       "        arXiv:2506.14020\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14020\" href=\"/pdf/2506.14020\" id=\"pdf-2506.14020\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14020\" href=\"https://arxiv.org/html/2506.14020v1\" id=\"html-2506.14020\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14020\" href=\"/format/2506.14020\" id=\"oth-2506.14020\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Bures-Wasserstein Flow Matching for Graph Generation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+K\">Keyue Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+J\">Jiahao Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dong,+X\">Xiaowen Dong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toni,+L\">Laura Toni</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Graph generation has emerged as a critical task in fields ranging from molecule design to drug discovery. Contemporary approaches, notably diffusion and flow-based models, have achieved solid graph generative performance through constructing a probability path that interpolates between a reference distribution and the data distribution. However, these methods typically model the evolution of individual nodes and edges independently and use linear interpolations to build the path assuming that the data lie in Euclidean space. We show that this is suboptimal given the intrinsic non-Euclidean structure and interconnected patterns of graphs, and it poses risks to the sampling convergence. To build a better probability path, we model the joint evolution of the nodes and edges by representing graphs as connected systems parameterized by Markov random fields (MRF). We then leverage the optimal transport displacement between MRF objects to design the probability path for graph generation. Based on this, we introduce BWFlow, a flow-matching framework for graph generation that respects the underlying geometry of graphs and provides smooth velocities in the probability path. The novel framework can be adapted to both continuous and discrete flow-matching algorithms. Experimental evaluations in plain graph generation and 2D/3D molecule generation validate the effectiveness of BWFlow in graph generation with competitive performance, stable training, and guaranteed sampling convergence.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item99\">[99]</a>\n",
       "<a href=\"/abs/2506.14035\" id=\"2506.14035\" title=\"Abstract\">\n",
       "        arXiv:2506.14035\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14035\" href=\"/pdf/2506.14035\" id=\"pdf-2506.14035\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14035\" href=\"https://arxiv.org/html/2506.14035v1\" id=\"html-2506.14035\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14035\" href=\"/format/2506.14035\" id=\"oth-2506.14035\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jain,+C\">Chelsi Jain</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yiran Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+Y\">Yifan Zeng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J\">Jiale Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+S+h\">S hengyu Dai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shao,+Z\">Zhenwen Shao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Q\">Qingyun Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Huazheng Wang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Document Visual Question Answering (DocVQA) is a practical yet challenging task, which is to ask questions based on documents while referring to multiple pages and different modalities of information, e.g, images and tables. To handle multi-modality, recent methods follow a similar Retrieval Augmented Generation (RAG) pipeline, but utilize Visual Language Models (VLMs) based embedding model to embed and retrieve relevant pages as images, and generate answers with VLMs that can accept an image as input. In this paper, we introduce SimpleDoc, a lightweight yet powerful retrieval - augmented framework for DocVQA. It boosts evidence page gathering by first retrieving candidates through embedding similarity and then filtering and re-ranking these candidates based on page summaries. A single VLM-based reasoner agent repeatedly invokes this dual-cue retriever, iteratively pulling fresh pages into a working memory until the question is confidently answered. SimpleDoc outperforms previous baselines by 3.2% on average on 4 DocVQA datasets with much fewer pages retrieved. Our code is available at <a class=\"link-external link-https\" href=\"https://github.com/ag2ai/SimpleDoc\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item100\">[100]</a>\n",
       "<a href=\"/abs/2506.14042\" id=\"2506.14042\" title=\"Abstract\">\n",
       "        arXiv:2506.14042\n",
       "      </a>\n",
       "          (cross-list from cs.LO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14042\" href=\"/pdf/2506.14042\" id=\"pdf-2506.14042\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14042\" href=\"https://arxiv.org/html/2506.14042v1\" id=\"html-2506.14042\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14042\" href=\"/format/2506.14042\" id=\"oth-2506.14042\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Asymptotically Smaller Encodings for Graph Problems and Scheduling\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Subercaseaux,+B\">Bernardo Subercaseaux</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We show how several graph problems (e.g., vertex-cover, independent-set, $k$-coloring) can be encoded into CNF using only $O(|V|^2 / \\lg |V|)$ many clauses, as opposed to the $\\Omega(|V|^2)$ constraints used by standard encodings. This somewhat surprising result is a simple consequence of a result of Erdős, Chung, and Spencer (1983) about biclique coverings of graphs, and opens theoretical avenues to understand the success of \"Bounded Variable Addition'' (Manthey, Heule, and Biere, 2012) as a preprocessing tool. Finally, we show a novel encoding for independent sets in some dense interval graphs using only $O(|V| \\lg |V|)$ clauses (the direct encoding uses $\\Omega(|V|^2)$), which we have successfully applied to a string-compression encoding posed by Bannai et al. (2022). As a direct byproduct, we obtain a reduction in the encoding size of a scheduling problem posed by Mayank and Modal (2020) from $O(NMT^2)$ to $O(NMT + M T^2 \\lg T)$, where $N$ is the number of tasks, $T$ the total timespan, and $M$ the number of machines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item101\">[101]</a>\n",
       "<a href=\"/abs/2506.14046\" id=\"2506.14046\" title=\"Abstract\">\n",
       "        arXiv:2506.14046\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14046\" href=\"/pdf/2506.14046\" id=\"pdf-2506.14046\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14046\" href=\"https://arxiv.org/html/2506.14046v1\" id=\"html-2506.14046\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14046\" href=\"/format/2506.14046\" id=\"oth-2506.14046\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kogan,+D\">David Kogan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schumacher,+M\">Max Schumacher</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen,+S\">Sam Nguyen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Suzuki,+M\">Masanori Suzuki</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Smith,+M\">Melissa Smith</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bellows,+C+S\">Chloe Sophia Bellows</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bernstein,+J\">Jared Bernstein</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          There is an unmet need to evaluate the language difficulty of short, conversational passages of text, particularly for training and filtering Large Language Models (LLMs). We introduce Ace-CEFR, a dataset of English conversational text passages expert-annotated with their corresponding level of text difficulty. We experiment with several models on Ace-CEFR, including Transformer-based models and LLMs. We show that models trained on Ace-CEFR can measure text difficulty more accurately than human experts and have latency appropriate to production environments. Finally, we release the Ace-CEFR dataset to the public for research and development.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item102\">[102]</a>\n",
       "<a href=\"/abs/2506.14054\" id=\"2506.14054\" title=\"Abstract\">\n",
       "        arXiv:2506.14054\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14054\" href=\"/pdf/2506.14054\" id=\"pdf-2506.14054\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14054\" href=\"https://arxiv.org/html/2506.14054v1\" id=\"html-2506.14054\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14054\" href=\"/format/2506.14054\" id=\"oth-2506.14054\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Scientifically-Interpretable Reasoning Network (ScIReN): Uncovering the Black-Box of Nature\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fan,+J\">Joshua Fan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+H\">Haodi Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tao,+F\">Feng Tao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nasim,+M\">Md Nasim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Grimson,+M\">Marc Grimson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+Y\">Yiqi Luo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gomes,+C+P\">Carla P. Gomes</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          28 pages, 9 figures, submitted to NeurIPS 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Neural networks are a powerful tool for learning patterns from data. However, they do not respect known scientific laws, nor can they reveal novel scientific insights due to their black-box nature. In contrast, scientific reasoning distills biological or physical principles from observations and controlled experiments, and quantitatively interprets them with process-based models made of mathematical equations. Yet, process-based models rely on numerous free parameters that must be set in an ad-hoc manner, and thus often fit observations poorly in cross-scale predictions. While prior work has embedded process-based models in conventional neural networks, discovering interpretable relationships between parameters in process-based models and input features is still a grand challenge for scientific discovery. We thus propose Scientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent framework that combines interpretable neural and process-based reasoning. An interpretable encoder predicts scientifically-meaningful latent parameters, which are then passed through a differentiable process-based decoder to predict labeled output variables. ScIReN also uses a novel hard-sigmoid constraint layer to restrict latent parameters to meaningful ranges defined by scientific prior knowledge, further enhancing its interpretability. While the embedded process-based model enforces established scientific knowledge, the encoder reveals new scientific mechanisms and relationships hidden in conventional black-box models. We apply ScIReN on two tasks: simulating the flow of organic carbon through soils, and modeling ecosystem respiration from plants. In both tasks, ScIReN outperforms black-box networks in predictive accuracy while providing substantial scientific interpretability -- it can infer latent scientific mechanisms and their relationships with input features.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item103\">[103]</a>\n",
       "<a href=\"/abs/2506.14086\" id=\"2506.14086\" title=\"Abstract\">\n",
       "        arXiv:2506.14086\n",
       "      </a>\n",
       "          (cross-list from cs.IR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14086\" href=\"/pdf/2506.14086\" id=\"pdf-2506.14086\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14086\" href=\"https://arxiv.org/html/2506.14086v1\" id=\"html-2506.14086\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14086\" href=\"/format/2506.14086\" id=\"oth-2506.14086\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Seetharaman,+R\">Rahul Seetharaman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dhole,+K+D\">Kaustubh D. Dhole</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal,+A\">Aman Bansal</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Language Models (LLMs) have demonstrated significant strides across various information retrieval tasks, particularly as rerankers, owing to their strong generalization and knowledge-transfer capabilities acquired from extensive pretraining. In parallel, the rise of LLM-based chat interfaces has raised user expectations, encouraging users to pose more complex queries that necessitate retrieval by ``reasoning'' over documents rather than through simple keyword matching or semantic similarity. While some recent efforts have exploited reasoning abilities of LLMs for reranking such queries, considerable potential for improvement remains. In that regards, we introduce InsertRank, an LLM-based reranker that leverages lexical signals like BM25 scores during reranking to further improve retrieval performance. InsertRank demonstrates improved retrieval effectiveness on -- BRIGHT, a reasoning benchmark spanning 12 diverse domains, and R2MED, a specialized medical reasoning retrieval benchmark spanning 8 different tasks. We conduct an exhaustive evaluation and several ablation studies and demonstrate that InsertRank consistently improves retrieval effectiveness across multiple families of LLMs, including GPT, Gemini, and Deepseek models. %In addition, we also conduct ablation studies on normalization by varying the scale of the BM25 scores, and positional bias by shuffling the order of the documents. With Deepseek-R1, InsertRank achieves a score of 37.5 on the BRIGHT benchmark. and 51.1 on the R2MED benchmark, surpassing previous methods.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item104\">[104]</a>\n",
       "<a href=\"/abs/2506.14096\" id=\"2506.14096\" title=\"Abstract\">\n",
       "        arXiv:2506.14096\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14096\" href=\"/pdf/2506.14096\" id=\"pdf-2506.14096\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14096\" href=\"https://arxiv.org/html/2506.14096v1\" id=\"html-2506.14096\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14096\" href=\"/format/2506.14096\" id=\"oth-2506.14096\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Akter,+S\">Sanjeda Akter</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shihab,+I+F\">Ibne Farabi Shihab</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+A\">Anuj Sharma</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The integration of Large Language Models (LLMs) with computer vision is profoundly transforming perception tasks like image segmentation. For intelligent transportation systems (ITS), where accurate scene understanding is critical for safety and efficiency, this new paradigm offers unprecedented capabilities. This survey systematically reviews the emerging field of LLM-augmented image segmentation, focusing on its applications, challenges, and future directions within ITS. We provide a taxonomy of current approaches based on their prompting mechanisms and core architectures, and we highlight how these innovations can enhance road scene understanding for autonomous driving, traffic monitoring, and infrastructure maintenance. Finally, we identify key challenges, including real-time performance and safety-critical reliability, and outline a perspective centered on explainable, human-centric AI as a prerequisite for the successful deployment of this technology in next-generation transportation systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item105\">[105]</a>\n",
       "<a href=\"/abs/2506.14098\" id=\"2506.14098\" title=\"Abstract\">\n",
       "        arXiv:2506.14098\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14098\" href=\"/pdf/2506.14098\" id=\"pdf-2506.14098\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14098\" href=\"https://arxiv.org/html/2506.14098v1\" id=\"html-2506.14098\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14098\" href=\"/format/2506.14098\" id=\"oth-2506.14098\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+Z\">Ziyuan Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jie Chen</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          A foundation model like GPT elicits many emergent abilities, owing to the pre-training with broad inclusion of data and the use of the powerful Transformer architecture. While foundation models in natural languages are prevalent, can we build similar models for graphs? This paper describes an approach toward a graph foundation model that is pre-trained with diverse graph datasets by adapting the Transformer backbone. A central challenge toward this end is how a sequence model encodes graphs of varying sizes and from different domains. We propose representing a node as multiple random walks, such that the Transformer can extract node representations from sequences, which in turn form edge and graph representations. We develop a novel context prediction loss for these random walks and theoretically analyze their expressive power in distinguishing neighborhoods and graphs. We also demonstrate the pre-training of our model and its adaptation to downstream tasks, showcasing its potential as a foundation for processing and reasoning with graph-structured data.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item106\">[106]</a>\n",
       "<a href=\"/abs/2506.14111\" id=\"2506.14111\" title=\"Abstract\">\n",
       "        arXiv:2506.14111\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14111\" href=\"/pdf/2506.14111\" id=\"pdf-2506.14111\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14111\" href=\"/format/2506.14111\" id=\"oth-2506.14111\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Essential-Web v1.0: 24T tokens of organized web data\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=AI,+E\">Essential AI</a>: <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hojel,+A\">Andrew Hojel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pust,+M\">Michael Pust</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Romanski,+T\">Tim Romanski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vanjani,+Y\">Yash Vanjani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kapila,+R\">Ritvik Kapila</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+M\">Mohit Parmar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chaluvaraju,+A\">Adarsh Chaluvaraju</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tripathy,+A\">Alok Tripathy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Thomas,+A\">Anil Thomas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tanwer,+A\">Ashish Tanwer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shah,+D+J\">Darsh J Shah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shah,+I\">Ishaan Shah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Stratos,+K\">Karl Stratos</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen,+K\">Khoi Nguyen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Smith,+K\">Kurt Smith</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Callahan,+M\">Michael Callahan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rushton,+P\">Peter Rushton</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Monk,+P\">Philip Monk</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mazarakis,+P\">Platon Mazarakis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jamal,+S\">Saad Jamal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Saurabh\">Saurabh Srivastava</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Singla,+S\">Somanshu Singla</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A\">Ashish Vaswani</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: <a class=\"link-external link-https\" href=\"https://huggingface.co/datasets/EssentialAI/essential-web-v1.0\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item107\">[107]</a>\n",
       "<a href=\"/abs/2506.14113\" id=\"2506.14113\" title=\"Abstract\">\n",
       "        arXiv:2506.14113\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14113\" href=\"/pdf/2506.14113\" id=\"pdf-2506.14113\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14113\" href=\"https://arxiv.org/html/2506.14113v1\" id=\"html-2506.14113\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14113\" href=\"/format/2506.14113\" id=\"oth-2506.14113\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y\">Yitian Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+L\">Liheng Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Valkanas,+A\">Antonios Valkanas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Oreshkin,+B+N\">Boris N. Oreshkin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Coates,+M\">Mark Coates</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Koopman operator theory provides a framework for nonlinear dynamical system analysis and time-series forecasting by mapping dynamics to a space of real-valued measurement functions, enabling a linear operator representation. Despite the advantage of linearity, the operator is generally infinite-dimensional. Therefore, the objective is to learn measurement functions that yield a tractable finite-dimensional Koopman operator approximation. In this work, we establish a connection between Koopman operator approximation and linear Recurrent Neural Networks (RNNs), which have recently demonstrated remarkable success in sequence modeling. We show that by considering an extended state consisting of lagged observations, we can establish an equivalence between a structured Koopman operator and linear RNN updates. Building on this connection, we present SKOLR, which integrates a learnable spectral decomposition of the input signal with a multilayer perceptron (MLP) as the measurement functions and implements a structured Koopman operator via a highly parallel linear RNN stack. Numerical experiments on various forecasting benchmarks and dynamical systems show that this streamlined, Koopman-theory-based design delivers exceptional performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item108\">[108]</a>\n",
       "<a href=\"/abs/2506.14122\" id=\"2506.14122\" title=\"Abstract\">\n",
       "        arXiv:2506.14122\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14122\" href=\"/pdf/2506.14122\" id=\"pdf-2506.14122\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14122\" href=\"https://arxiv.org/html/2506.14122v1\" id=\"html-2506.14122\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14122\" href=\"/format/2506.14122\" id=\"oth-2506.14122\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+T\">Tianming Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+R\">Renbo Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Z\">Zhengyi Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+Y\">Yunjun Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cao,+B\">Bin Cao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fan,+J\">Jing Fan</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Temporal Betweenness Centrality (TBC) measures how often a node appears on optimal temporal paths, reflecting its importance in temporal networks. However, exact computation is highly expensive, and real-world TBC distributions are extremely imbalanced. The severe imbalance leads learning-based models to overfit to zero-centrality nodes, resulting in inaccurate TBC predictions and failure to identify truly central nodes. Existing graph neural network (GNN) methods either fail to handle such imbalance or ignore temporal dependencies altogether. To address these issues, we propose a scalable and inductive contrastive learning-based GNN (CLGNN) for accurate and efficient TBC prediction. CLGNN builds an instance graph to preserve path validity and temporal order, then encodes structural and temporal features using dual aggregation, i.e., mean and edge-to-node multi-head attention mechanisms, enhanced by temporal path count and time encodings. A stability-based clustering-guided contrastive module (KContrastNet) is introduced to separate high-, median-, and low-centrality nodes in representation space, mitigating class imbalance, while a regression module (ValueNet) estimates TBC values. CLGNN also supports multiple optimal path definitions to accommodate diverse temporal semantics. Extensive experiments demonstrate the effectiveness and efficiency of CLGNN across diverse benchmarks. CLGNN achieves up to a 663.7~$\\times$ speedup compared to state-of-the-art exact TBC computation methods. It outperforms leading static GNN baselines with up to 31.4~$\\times$ lower MAE and 16.7~$\\times$ higher Spearman correlation, and surpasses state-of-the-art temporal GNNs with up to 5.7~$\\times$ lower MAE and 3.9~$\\times$ higher Spearman correlation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item109\">[109]</a>\n",
       "<a href=\"/abs/2506.14126\" id=\"2506.14126\" title=\"Abstract\">\n",
       "        arXiv:2506.14126\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14126\" href=\"/pdf/2506.14126\" id=\"pdf-2506.14126\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14126\" href=\"https://arxiv.org/html/2506.14126v1\" id=\"html-2506.14126\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14126\" href=\"/format/2506.14126\" id=\"oth-2506.14126\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Less is More: Undertraining Experts Improves Model Upcycling\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Horoi,+S\">Stefan Horoi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf,+G\">Guy Wolf</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Belilovsky,+E\">Eugene Belilovsky</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dziugaite,+G+K\">Gintare Karolina Dziugaite</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Modern deep learning is increasingly characterized by the use of open-weight foundation models that can be fine-tuned on specialized datasets. This has led to a proliferation of expert models and adapters, often shared via platforms like HuggingFace and AdapterHub. To leverage these resources, numerous model upcycling methods have emerged, enabling the reuse of fine-tuned models in multi-task systems. A natural pipeline has thus formed to harness the benefits of transfer learning and amortize sunk training costs: models are pre-trained on general data, fine-tuned on specific tasks, and then upcycled into more general-purpose systems. A prevailing assumption is that improvements at one stage of this pipeline propagate downstream, leading to gains at subsequent steps. In this work, we challenge that assumption by examining how expert fine-tuning affects model upcycling. We show that long fine-tuning of experts that optimizes for their individual performance leads to degraded merging performance, both for fully fine-tuned and LoRA-adapted models, and to worse downstream results when LoRA adapters are upcycled into MoE layers. We trace this degradation to the memorization of a small set of difficult examples that dominate late fine-tuning steps and are subsequently forgotten during merging. Finally, we demonstrate that a task-dependent aggressive early stopping strategy can significantly improve upcycling performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item110\">[110]</a>\n",
       "<a href=\"/abs/2506.14130\" id=\"2506.14130\" title=\"Abstract\">\n",
       "        arXiv:2506.14130\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14130\" href=\"/pdf/2506.14130\" id=\"pdf-2506.14130\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14130\" href=\"https://arxiv.org/html/2506.14130v1\" id=\"html-2506.14130\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14130\" href=\"/format/2506.14130\" id=\"oth-2506.14130\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          KDMOS:Knowledge Distillation for Motion Segmentation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cao,+C\">Chunyu Cao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+J\">Jintao Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Z\">Zeyu Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan,+L\">Linfan Zhan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fan,+R\">Rui Fan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Z\">Zhijian He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+X\">Xiaoyu Tang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Motion Object Segmentation (MOS) is crucial for autonomous driving, as it enhances localization, path planning, map construction, scene flow estimation, and future state prediction. While existing methods achieve strong performance, balancing accuracy and real-time inference remains a challenge. To address this, we propose a logits-based knowledge distillation framework for MOS, aiming to improve accuracy while maintaining real-time efficiency. Specifically, we adopt a Bird's Eye View (BEV) projection-based model as the student and a non-projection model as the teacher. To handle the severe imbalance between moving and non-moving classes, we decouple them and apply tailored distillation strategies, allowing the teacher model to better learn key motion-related features. This approach significantly reduces false positives and false negatives. Additionally, we introduce dynamic upsampling, optimize the network architecture, and achieve a 7.69% reduction in parameter count, mitigating overfitting. Our method achieves a notable IoU of 78.8% on the hidden test set of the SemanticKITTI-MOS dataset and delivers competitive results on the Apollo dataset. The KDMOS implementation is available at <a class=\"link-external link-https\" href=\"https://github.com/SCNU-RISLAB/KDMOS\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item111\">[111]</a>\n",
       "<a href=\"/abs/2506.14138\" id=\"2506.14138\" title=\"Abstract\">\n",
       "        arXiv:2506.14138\n",
       "      </a>\n",
       "          (cross-list from cs.NE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14138\" href=\"/pdf/2506.14138\" id=\"pdf-2506.14138\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14138\" href=\"https://arxiv.org/html/2506.14138v1\" id=\"html-2506.14138\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14138\" href=\"/format/2506.14138\" id=\"oth-2506.14138\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gautam,+A\">Ashish Gautam</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Date,+P\">Prasanna Date</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kulkarni,+S\">Shruti Kulkarni</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Patton,+R\">Robert Patton</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Potok,+T\">Thomas Potok</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Neuromorphic computing, FPGA, STDP, Spiking Graph Neural Networks, Spiking Neural Networks, VHDL\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Spiking Neural Networks (SNNs) are computational models inspired by the structure and dynamics of biological neuronal networks. Their event-driven nature enables them to achieve high energy efficiency, particularly when deployed on neuromorphic hardware platforms. Unlike conventional Artificial Neural Networks (ANNs), which primarily rely on layered architectures, SNNs naturally support a wide range of connectivity patterns, from traditional layered structures to small-world graphs characterized by locally dense and globally sparse connections. In this work, we introduce NeuroCoreX, an FPGA-based emulator designed for the flexible co-design and testing of SNNs. NeuroCoreX supports all-to-all connectivity, providing the capability to implement diverse network topologies without architectural restrictions. It features a biologically motivated local learning mechanism based on Spike-Timing-Dependent Plasticity (STDP). The neuron model implemented within NeuroCoreX is the Leaky Integrate-and-Fire (LIF) model, with current-based synapses facilitating spike integration and transmission . A Universal Asynchronous Receiver-Transmitter (UART) interface is provided for programming and configuring the network parameters, including neuron, synapse, and learning rule settings. Users interact with the emulator through a simple Python-based interface, streamlining SNN deployment from model design to hardware execution. NeuroCoreX is released as an open-source framework, aiming to accelerate research and development in energy-efficient, biologically inspired computing.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item112\">[112]</a>\n",
       "<a href=\"/abs/2506.14144\" id=\"2506.14144\" title=\"Abstract\">\n",
       "        arXiv:2506.14144\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14144\" href=\"/pdf/2506.14144\" id=\"pdf-2506.14144\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14144\" href=\"/format/2506.14144\" id=\"oth-2506.14144\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bai,+J\">Juho Bai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shim,+I\">Inwook Shim</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Accurate prediction of pedestrian trajectories is essential for applications in robotics and surveillance systems. While existing approaches primarily focus on social interactions between pedestrians, they often overlook the rich environmental context that significantly shapes human movement patterns. In this paper, we propose SceneAware, a novel framework that explicitly incorporates scene understanding to enhance trajectory prediction accuracy. Our method leverages a Vision Transformer~(ViT) scene encoder to process environmental context from static scene images, while Multi-modal Large Language Models~(MLLMs) generate binary walkability masks that distinguish between accessible and restricted areas during training. We combine a Transformer-based trajectory encoder with the ViT-based scene encoder, capturing both temporal dynamics and spatial constraints. The framework integrates collision penalty mechanisms that discourage predicted trajectories from violating physical boundaries, ensuring physically plausible predictions. SceneAware is implemented in both deterministic and stochastic variants. Comprehensive experiments on the ETH/UCY benchmark datasets show that our approach outperforms state-of-the-art methods, with more than 50\\% improvement over previous models. Our analysis based on different trajectory categories shows that the model performs consistently well across various types of pedestrian movement. This highlights the importance of using explicit scene information and shows that our scene-aware approach is both effective and reliable in generating accurate and physically plausible predictions. Code is available at: <a class=\"link-external link-https\" href=\"https://github.com/juho127/SceneAware\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item113\">[113]</a>\n",
       "<a href=\"/abs/2506.14158\" id=\"2506.14158\" title=\"Abstract\">\n",
       "        arXiv:2506.14158\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14158\" href=\"/pdf/2506.14158\" id=\"pdf-2506.14158\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14158\" href=\"https://arxiv.org/html/2506.14158v1\" id=\"html-2506.14158\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14158\" href=\"/format/2506.14158\" id=\"oth-2506.14158\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+T\">Tao He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+G\">Guang Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Y\">Yu Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+T\">Tianshi Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+S\">Sicheng Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ding,+G\">Guiguang Ding</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+P\">Pengyang Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tian,+F\">Feng Tian</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) exhibit remarkable reasoning capabilities across diverse downstream tasks. However, their autoregressive nature leads to substantial inference latency, posing challenges for real-time applications. Speculative sampling mitigates this issue by introducing a drafting phase followed by a parallel validation phase, enabling faster token generation and verification. Existing approaches, however, overlook the inherent coherence in text generation, limiting their efficiency. To address this gap, we propose a Speculative Sampling with Syntactic and Semantic Coherence (S$^4$C) framework, which extends speculative sampling by leveraging multi-head drafting for rapid token generation and a continuous verification tree for efficient candidate validation and feature reuse. Experimental results demonstrate that S$^4$C surpasses baseline methods across mainstream tasks, offering enhanced efficiency, parallelism, and the ability to generate more valid tokens with fewer computational resources. On Spec-bench benchmarks, S$^4$C achieves an acceleration ratio of 2.26x-2.60x, outperforming state-of-the-art methods.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item114\">[114]</a>\n",
       "<a href=\"/abs/2506.14159\" id=\"2506.14159\" title=\"Abstract\">\n",
       "        arXiv:2506.14159\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14159\" href=\"/pdf/2506.14159\" id=\"pdf-2506.14159\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14159\" href=\"/format/2506.14159\" id=\"oth-2506.14159\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Talaei,+S\">Shayan Talaei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+M\">Meijin Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Grover,+K\">Kanu Grover</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hippler,+J+K\">James Kent Hippler</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+D\">Diyi Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Saberi,+A\">Amin Saberi</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N=28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item115\">[115]</a>\n",
       "<a href=\"/abs/2506.14168\" id=\"2506.14168\" title=\"Abstract\">\n",
       "        arXiv:2506.14168\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14168\" href=\"/pdf/2506.14168\" id=\"pdf-2506.14168\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14168\" href=\"https://arxiv.org/html/2506.14168v1\" id=\"html-2506.14168\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14168\" href=\"/format/2506.14168\" id=\"oth-2506.14168\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          VideoMAR: Autoregressive Video Generatio with Continuous Tokens\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H\">Hu Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gong,+B\">Biao Gong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+H\">Hangjie Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+D\">DanDan Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chai,+W\">Weilong Chai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jingdong Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+K\">Kecheng Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+F\">Feng Zhao</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Submitted to NeurIPS 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Masked-based autoregressive models have demonstrated promising image generation capability in continuous space. However, their potential for video generation remains under-explored. In this paper, we propose \\textbf{VideoMAR}, a concise and efficient decoder-only autoregressive image-to-video model with continuous tokens, composing temporal frame-by-frame and spatial masked generation. We first identify temporal causality and spatial bi-directionality as the first principle of video AR models, and propose the next-frame diffusion loss for the integration of mask and video generation. Besides, the huge cost and difficulty of long sequence autoregressive modeling is a basic but crucial issue. To this end, we propose the temporal short-to-long curriculum learning and spatial progressive resolution training, and employ progressive temperature strategy at inference time to mitigate the accumulation error. Furthermore, VideoMAR replicates several unique capacities of language models to video generation. It inherently bears high efficiency due to simultaneous temporal-wise KV cache and spatial-wise parallel generation, and presents the capacity of spatial and temporal extrapolation via 3D rotary embeddings. On the VBench-I2V benchmark, VideoMAR surpasses the previous state-of-the-art (Cosmos I2V) while requiring significantly fewer parameters ($9.3\\%$), training data ($0.5\\%$), and GPU resources ($0.2\\%$).\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item116\">[116]</a>\n",
       "<a href=\"/abs/2506.14170\" id=\"2506.14170\" title=\"Abstract\">\n",
       "        arXiv:2506.14170\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14170\" href=\"/pdf/2506.14170\" id=\"pdf-2506.14170\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14170\" href=\"/format/2506.14170\" id=\"oth-2506.14170\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A multi-stage augmented multimodal interaction network for fish feeding intensity quantification\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S\">Shulong Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+M\">Mingyuan Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+J\">Jiayin Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+X\">Xiao Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Haihua Wang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item117\">[117]</a>\n",
       "<a href=\"/abs/2506.14175\" id=\"2506.14175\" title=\"Abstract\">\n",
       "        arXiv:2506.14175\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14175\" href=\"/pdf/2506.14175\" id=\"pdf-2506.14175\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14175\" href=\"/format/2506.14175\" id=\"oth-2506.14175\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          GRAM: A Generative Foundation Reward Model for Reward Generalization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+C\">Chenglong Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gan,+Y\">Yang Gan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huo,+Y\">Yifu Huo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mu,+Y\">Yongyu Mu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Q\">Qiaozhi He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+M\">Murun Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+B\">Bei Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao,+T\">Tong Xiao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+C\">Chunliang Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+T\">Tongran Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+J\">Jingbo Zhu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by ICML 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item118\">[118]</a>\n",
       "<a href=\"/abs/2506.14177\" id=\"2506.14177\" title=\"Abstract\">\n",
       "        arXiv:2506.14177\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14177\" href=\"/pdf/2506.14177\" id=\"pdf-2506.14177\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14177\" href=\"https://arxiv.org/html/2506.14177v1\" id=\"html-2506.14177\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14177\" href=\"/format/2506.14177\" id=\"oth-2506.14177\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nguyen,+T\">Tuan Nguyen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tran,+H\">Huy-Dat Tran</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by Interspeech 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Code-switching (CS), common in multilingual settings, presents challenges for ASR due to scarce and costly transcribed data caused by linguistic complexity. This study investigates building CS-ASR using synthetic CS data. We propose a phrase-level mixing method to generate synthetic CS data that mimics natural patterns. Utilizing monolingual augmented with synthetic phrase-mixed CS data to fine-tune large pretrained ASR models (Whisper, MMS, SeamlessM4T). This paper focuses on three under-resourced Southeast Asian language pairs: Malay-English (BM-EN), Mandarin-Malay (ZH-BM), and Tamil-English (TA-EN), establishing a new comprehensive benchmark for CS-ASR to evaluate the performance of leading ASR models. Experimental results show that the proposed training strategy enhances ASR performance on monolingual and CS tests, with BM-EN showing highest gains, then TA-EN and ZH-BM. This finding offers a cost-effective approach for CS-ASR development, benefiting research and industry.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item119\">[119]</a>\n",
       "<a href=\"/abs/2506.14196\" id=\"2506.14196\" title=\"Abstract\">\n",
       "        arXiv:2506.14196\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14196\" href=\"/pdf/2506.14196\" id=\"pdf-2506.14196\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14196\" href=\"https://arxiv.org/html/2506.14196v1\" id=\"html-2506.14196\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14196\" href=\"/format/2506.14196\" id=\"oth-2506.14196\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+J+M\">Jiayue Melissa Shi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Keran Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yoo,+D+W\">Dong Whi Yoo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Karkar,+R\">Ravi Karkar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Saha,+K\">Koustuv Saha</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Alzheimer's Disease and Related Dementias (AD/ADRD) are progressive neurodegenerative conditions that impair memory, thought processes, and functioning. Family caregivers of individuals with AD/ADRD face significant mental health challenges due to long-term caregiving responsibilities. Yet, current support systems often overlook the evolving nature of their mental wellbeing needs. Our study examines caregivers' mental wellbeing concerns, focusing on the practices they adopt to manage the burden of caregiving and the technologies they use for support. Through semi-structured interviews with 25 family caregivers of individuals with AD/ADRD, we identified the key causes and effects of mental health challenges, and developed a temporal mapping of how caregivers' mental wellbeing evolves across three distinct stages of the caregiving journey. Additionally, our participants shared insights into improvements for existing mental health technologies, emphasizing the need for accessible, scalable, and personalized solutions that adapt to caregivers' changing needs over time. These findings offer a foundation for designing dynamic, stage-sensitive interventions that holistically support caregivers' mental wellbeing, benefiting both caregivers and care recipients.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item120\">[120]</a>\n",
       "<a href=\"/abs/2506.14202\" id=\"2506.14202\" title=\"Abstract\">\n",
       "        arXiv:2506.14202\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14202\" href=\"/pdf/2506.14202\" id=\"pdf-2506.14202\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14202\" href=\"https://arxiv.org/html/2506.14202v1\" id=\"html-2506.14202\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14202\" href=\"/format/2506.14202\" id=\"oth-2506.14202\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shing,+M\">Makoto Shing</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Akiba,+T\">Takuya Akiba</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          To appear at TTODLer-FM Workshop of the 42nd International Conference on Machine Learning\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Training large neural networks with end-to-end backpropagation creates significant memory bottlenecks, limiting accessibility to state-of-the-art AI research. We propose $\\textit{DiffusionBlocks}$, a novel training framework that interprets neural network blocks as performing denoising operations in a continuous-time diffusion process. By partitioning the network into independently trainable blocks and optimizing noise level assignments based on equal cumulative probability mass, our approach achieves significant memory efficiency while maintaining competitive performance compared to traditional backpropagation in generative tasks. Experiments on image generation and language modeling tasks demonstrate memory reduction proportional to the number of blocks while achieving superior performance. DiffusionBlocks provides a promising pathway for democratizing access to large-scale neural network training with limited computational resources.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item121\">[121]</a>\n",
       "<a href=\"/abs/2506.14209\" id=\"2506.14209\" title=\"Abstract\">\n",
       "        arXiv:2506.14209\n",
       "      </a>\n",
       "          (cross-list from eess.IV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14209\" href=\"/pdf/2506.14209\" id=\"pdf-2506.14209\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14209\" href=\"https://arxiv.org/html/2506.14209v1\" id=\"html-2506.14209\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14209\" href=\"/format/2506.14209\" id=\"oth-2506.14209\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Wang,+P\">Pengwei Wang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Advances in treatment technology now allow for the use of customizable 3D-printed hydrogel wound dressings for patients with osteoradionecrosis (ORN) of the jaw (ONJ). Meanwhile, deep learning has enabled precise segmentation of 3D medical images using tools like nnUNet.\n",
       "<br/>However, the scarcity of labeled data in ONJ imaging makes supervised training impractical. This study aims to develop an unsupervised training approach for automatically identifying anomalies in imaging scans.\n",
       "<br/>We propose a novel two-stage training pipeline. In the first stage, a VQ-GAN is trained to accurately reconstruct normal subjects. In the second stage, random cube masking and ONJ-specific masking are applied to train a new encoder capable of recovering the data.\n",
       "<br/>The proposed method achieves successful segmentation on both simulated and real patient data.\n",
       "<br/>This approach provides a fast initial segmentation solution, reducing the burden of manual labeling. Additionally, it has the potential to be directly used for 3D printing when combined with hand-tuned post-processing.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item122\">[122]</a>\n",
       "<a href=\"/abs/2506.14217\" id=\"2506.14217\" title=\"Abstract\">\n",
       "        arXiv:2506.14217\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14217\" href=\"/pdf/2506.14217\" id=\"pdf-2506.14217\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14217\" href=\"https://arxiv.org/html/2506.14217v1\" id=\"html-2506.14217\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14217\" href=\"/format/2506.14217\" id=\"oth-2506.14217\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mahato,+D+T\">Dipesh Tharu Mahato</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Poudel,+R\">Rohan Poudel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dhungana,+P\">Pramod Dhungana</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          12 pages, 6 tables, 6 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Deep neural networks often achieve high accuracy, but ensuring their reliability under adversarial and distributional shifts remains a pressing challenge. We propose TriGuard, a unified safety evaluation framework that combines (1) formal robustness verification, (2) attribution entropy to quantify saliency concentration, and (3) a novel Attribution Drift Score measuring explanation stability. TriGuard reveals critical mismatches between model accuracy and interpretability: verified models can still exhibit unstable reasoning, and attribution-based signals provide complementary safety insights beyond adversarial accuracy. Extensive experiments across three datasets and five architectures show how TriGuard uncovers subtle fragilities in neural reasoning. We further demonstrate that entropy-regularized training reduces explanation drift without sacrificing performance. TriGuard advances the frontier in robust, interpretable model evaluation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item123\">[123]</a>\n",
       "<a href=\"/abs/2506.14229\" id=\"2506.14229\" title=\"Abstract\">\n",
       "        arXiv:2506.14229\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14229\" href=\"/pdf/2506.14229\" id=\"pdf-2506.14229\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14229\" href=\"https://arxiv.org/html/2506.14229v1\" id=\"html-2506.14229\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14229\" href=\"/format/2506.14229\" id=\"oth-2506.14229\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Changbai Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+H\">Haodong Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+H\">Hanlin Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+J\">Juan Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+T\">Tongfei Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+S\">Shuo Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shao,+S\">Shuwei Shao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dong,+W\">Wenhao Dong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+B\">Baochang Zhang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          3D Gaussian Splatting (3DGS) has made significant strides in real-time 3D scene reconstruction, but faces memory scalability issues in high-resolution scenarios. To address this, we propose Hierarchical Gaussian Splatting (HRGS), a memory-efficient framework with hierarchical block-level optimization. First, we generate a global, coarse Gaussian representation from low-resolution data. Then, we partition the scene into multiple blocks, refining each block with high-resolution data. The partitioning involves two steps: Gaussian partitioning, where irregular scenes are normalized into a bounded cubic space with a uniform grid for task distribution, and training data partitioning, where only relevant observations are retained for each block. By guiding block refinement with the coarse Gaussian prior, we ensure seamless Gaussian fusion across adjacent blocks. To reduce computational demands, we introduce Importance-Driven Gaussian Pruning (IDGP), which computes importance scores for each Gaussian and removes those with minimal contribution, speeding up convergence and reducing memory usage. Additionally, we incorporate normal priors from a pretrained model to enhance surface reconstruction quality. Our method enables high-quality, high-resolution 3D scene reconstruction even under memory constraints. Extensive experiments on three benchmarks show that HRGS achieves state-of-the-art performance in high-resolution novel view synthesis (NVS) and surface reconstruction tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item124\">[124]</a>\n",
       "<a href=\"/abs/2506.14234\" id=\"2506.14234\" title=\"Abstract\">\n",
       "        arXiv:2506.14234\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14234\" href=\"/pdf/2506.14234\" id=\"pdf-2506.14234\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14234\" href=\"/format/2506.14234\" id=\"oth-2506.14234\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hosain,+M+T\">Md Tanzib Hosain</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman,+S\">Salman Rahman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Morol,+M+K\">Md Kishor Morol</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parvez,+M+R\">Md Rizwan Parvez</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation - treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solvers - such as Olympiad or programming contest teams - leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition. We introduce Xolver, a training-free multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative interactions, agent-driven evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch - marking a transition from isolated inference toward experience-aware language agents. Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses advanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24 (94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) - highlighting holistic experience learning as a key step toward generalist agents capable of expert-level reasoning. Code and data are available at <a class=\"link-external link-https\" href=\"https://kagnlp.github.io/xolver.github.io/\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item125\">[125]</a>\n",
       "<a href=\"/abs/2506.14248\" id=\"2506.14248\" title=\"Abstract\">\n",
       "        arXiv:2506.14248\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14248\" href=\"/pdf/2506.14248\" id=\"pdf-2506.14248\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14248\" href=\"/format/2506.14248\" id=\"oth-2506.14248\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Re-Initialization Token Learning for Tool-Augmented Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Chenghao Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+L\">Liu Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+B\">Baosheng Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu,+J\">Jiayan Qiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhan,+Y\">Yibing Zhan</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models have demonstrated exceptional performance, yet struggle with complex tasks such as numerical reasoning, plan generation. Integrating external tools, such as calculators and databases, into large language models (LLMs) is crucial for enhancing problem-solving capabilities. Current methods assign a unique token to each tool, enabling LLMs to call tools through token prediction-similar to word generation. However, this approach fails to account for the relationship between tool and word tokens, limiting adaptability within pre-trained LLMs. To address this issue, we propose a novel token learning method that aligns tool tokens with the existing word embedding space from the perspective of initialization, thereby enhancing model performance. We begin by constructing prior token embeddings for each tool based on the tool's name or description, which are used to initialize and regularize the learnable tool token embeddings. This ensures the learned embeddings are well-aligned with the word token space, improving tool call accuracy. We evaluate the method on tasks such as numerical reasoning, knowledge-based question answering, and embodied plan generation using GSM8K-XL, FuncQA, KAMEL, and VirtualHome datasets. The results demonstrate clear improvements over recent baselines, including CoT, REACT, ICL, and ToolkenGPT, indicating that our approach effectively augments LLMs with tools through relevant tokens across diverse domains.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item126\">[126]</a>\n",
       "<a href=\"/abs/2506.14262\" id=\"2506.14262\" title=\"Abstract\">\n",
       "        arXiv:2506.14262\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14262\" href=\"/pdf/2506.14262\" id=\"pdf-2506.14262\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14262\" href=\"https://arxiv.org/html/2506.14262v1\" id=\"html-2506.14262\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14262\" href=\"/format/2506.14262\" id=\"oth-2506.14262\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Knowledge Adaptation as Posterior Correction\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Khan,+M+E\">Mohammad Emtiyaz Khan</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Adaptation is the holy grail of intelligence, but even the best AI models (like GPT) lack the adaptivity of toddlers. So the question remains: how can machines adapt quickly? Despite a lot of progress on model adaptation to facilitate continual and federated learning, as well as model merging, editing, unlearning, etc., little is known about the mechanisms by which machines can naturally learn to adapt in a similar way as humans and animals. Here, we show that all such adaptation methods can be seen as different ways of `correcting' the approximate posteriors. More accurate posteriors lead to smaller corrections, which in turn imply quicker adaptation. The result is obtained by using a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023) where interference created during adaptation is characterized by the natural-gradient mismatch over the past data. We present many examples to demonstrate the use of posterior-correction as a natural mechanism for the machines to learn to adapt quickly.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item127\">[127]</a>\n",
       "<a href=\"/abs/2506.14280\" id=\"2506.14280\" title=\"Abstract\">\n",
       "        arXiv:2506.14280\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14280\" href=\"/pdf/2506.14280\" id=\"pdf-2506.14280\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14280\" href=\"https://arxiv.org/html/2506.14280v1\" id=\"html-2506.14280\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14280\" href=\"/format/2506.14280\" id=\"oth-2506.14280\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Improving LoRA with Variational Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cong,+B\">Bai Cong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Daheim,+N\">Nico Daheim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+Y\">Yuesong Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yokota,+R\">Rio Yokota</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Khan,+M+E\">Mohammad Emtiyaz Khan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=M%C3%B6llenhoff,+T\">Thomas Möllenhoff</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          16 pages, 4 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Bayesian methods have recently been used to improve LoRA finetuning and, although they improve calibration, their effect on other metrics (such as accuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian methods also increase computational overheads and require additional tricks for them to work well. Here, we fix these issues by using a recently proposed variational algorithm called IVON. We show that IVON is easy to implement and has similar costs to AdamW, and yet it can also drastically improve many metrics by using a simple posterior pruning technique. We present extensive results on billion-scale LLMs (Llama and Qwen series) going way beyond the scale of existing applications of IVON. For example, we finetune a Llama-3.2-3B model on a set of commonsense reasoning tasks and improve accuracy over AdamW by 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian methods like Laplace-LoRA and BLoB. Overall, our results show that variational learning with IVON can effectively improve LoRA finetuning.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item128\">[128]</a>\n",
       "<a href=\"/abs/2506.14287\" id=\"2506.14287\" title=\"Abstract\">\n",
       "        arXiv:2506.14287\n",
       "      </a>\n",
       "          (cross-list from cs.RO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14287\" href=\"/pdf/2506.14287\" id=\"pdf-2506.14287\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14287\" href=\"https://arxiv.org/html/2506.14287v1\" id=\"html-2506.14287\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14287\" href=\"/format/2506.14287\" id=\"oth-2506.14287\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Steering Robots with Inference-Time Interactions\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yanwei Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          MIT Robotics PhD Thesis\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Imitation learning has driven the development of generalist policies capable of autonomously solving multiple tasks. However, when a pretrained policy makes errors during deployment, there are limited mechanisms for users to correct its behavior. While collecting additional data for finetuning can address such issues, doing so for each downstream use case is inefficient at deployment. My research proposes an alternative: keeping pretrained policies frozen as a fixed skill repertoire while allowing user interactions to guide behavior generation toward user preferences at inference time. By making pretrained policies steerable, users can help correct policy errors when the model struggles to generalize-without needing to finetune the policy. Specifically, I propose (1) inference-time steering, which leverages user interactions to switch between discrete skills, and (2) task and motion imitation, which enables user interactions to edit continuous motions while satisfying task constraints defined by discrete symbolic plans. These frameworks correct misaligned policy predictions without requiring additional training, maximizing the utility of pretrained models while achieving inference-time user objectives.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item129\">[129]</a>\n",
       "<a href=\"/abs/2506.14294\" id=\"2506.14294\" title=\"Abstract\">\n",
       "        arXiv:2506.14294\n",
       "      </a>\n",
       "          (cross-list from cs.RO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14294\" href=\"/pdf/2506.14294\" id=\"pdf-2506.14294\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14294\" href=\"https://arxiv.org/html/2506.14294v1\" id=\"html-2506.14294\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14294\" href=\"/format/2506.14294\" id=\"oth-2506.14294\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Uncertainty-Driven Radar-Inertial Fusion for Instantaneous 3D Ego-Velocity Estimation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rai,+P+K\">Prashant Kumar Rai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kowsari,+E\">Elham Kowsari</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Strokina,+N\">Nataliya Strokina</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ghabcheloo,+R\">Reza Ghabcheloo</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This paper has been accepted for presentation at the 28th International Conference on Information Fusion (Fusion 2025)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present a method for estimating ego-velocity in autonomous navigation by integrating high-resolution imaging radar with an inertial measurement unit. The proposed approach addresses the limitations of traditional radar-based ego-motion estimation techniques by employing a neural network to process complex-valued raw radar data and estimate instantaneous linear ego-velocity along with its associated uncertainty. This uncertainty-aware velocity estimate is then integrated with inertial measurement unit data using an Extended Kalman Filter. The filter leverages the network-predicted uncertainty to refine the inertial sensor's noise and bias parameters, improving the overall robustness and accuracy of the ego-motion estimation. We evaluated the proposed method on the publicly available ColoRadar dataset. Our approach achieves significantly lower error compared to the closest publicly available method and also outperforms both instantaneous and scan matching-based techniques.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item130\">[130]</a>\n",
       "<a href=\"/abs/2506.14303\" id=\"2506.14303\" title=\"Abstract\">\n",
       "        arXiv:2506.14303\n",
       "      </a>\n",
       "          (cross-list from eess.IV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14303\" href=\"/pdf/2506.14303\" id=\"pdf-2506.14303\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14303\" href=\"https://arxiv.org/html/2506.14303v1\" id=\"html-2506.14303\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14303\" href=\"/format/2506.14303\" id=\"oth-2506.14303\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Nataraj,+N\">Niran Nataraj</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Sogabe,+M\">Maina Sogabe</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Kawashima,+K\">Kenji Kawashima</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          24 pages, 7figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Deep learning in medical imaging faces obstacles: limited data diversity, ethical issues, high acquisition costs, and the need for precise annotations. Bleeding detection and localization during surgery is especially challenging due to the scarcity of high-quality datasets that reflect real surgical scenarios. We propose orGAN, a GAN-based system for generating high-fidelity, annotated surgical images of bleeding. By leveraging small \"mimicking organ\" datasets, synthetic models that replicate tissue properties and bleeding, our approach reduces ethical concerns and data-collection costs. orGAN builds on StyleGAN with Relational Positional Learning to simulate bleeding events realistically and mark bleeding coordinates. A LaMa-based inpainting module then restores clean, pre-bleed visuals, enabling precise pixel-level annotations. In evaluations, a balanced dataset of orGAN and mimicking-organ images achieved 90% detection accuracy in surgical settings and up to 99% frame-level accuracy. While our development data lack diverse organ morphologies and contain intraoperative artifacts, orGAN markedly advances ethical, efficient, and cost-effective creation of realistic annotated bleeding datasets, supporting broader integration of AI in surgical practice.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item131\">[131]</a>\n",
       "<a href=\"/abs/2506.14329\" id=\"2506.14329\" title=\"Abstract\">\n",
       "        arXiv:2506.14329\n",
       "      </a>\n",
       "          (cross-list from stat.ML)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14329\" href=\"/pdf/2506.14329\" id=\"pdf-2506.14329\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14329\" href=\"https://arxiv.org/html/2506.14329v1\" id=\"html-2506.14329\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14329\" href=\"/format/2506.14329\" id=\"oth-2506.14329\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adjustment for Confounding using Pre-Trained Representations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Schulte,+R\">Rickmer Schulte</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=R%C3%BCgamer,+D\">David Rügamer</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Nagler,+T\">Thomas Nagler</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at ICML 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computation (stat.CO); Methodology (stat.ME)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          There is growing interest in extending average treatment effect (ATE) estimation to incorporate non-tabular data, such as images and text, which may act as sources of confounding. Neglecting these effects risks biased results and flawed scientific conclusions. However, incorporating non-tabular data necessitates sophisticated feature extractors, often in combination with ideas of transfer learning. In this work, we investigate how latent features from pre-trained neural networks can be leveraged to adjust for sources of confounding. We formalize conditions under which these latent features enable valid adjustment and statistical inference in ATE estimation, demonstrating results along the example of double machine learning. We discuss critical challenges inherent to latent feature learning and downstream parameter estimation arising from the high dimensionality and non-identifiability of representations. Common structural assumptions for obtaining fast convergence rates with additive or sparse linear models are shown to be unrealistic for latent features. We argue, however, that neural networks are largely insensitive to these issues. In particular, we show that neural networks can achieve fast convergence rates by adapting to intrinsic notions of sparsity and dimension of the learning problem.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item132\">[132]</a>\n",
       "<a href=\"/abs/2506.14337\" id=\"2506.14337\" title=\"Abstract\">\n",
       "        arXiv:2506.14337\n",
       "      </a>\n",
       "          (cross-list from cs.CR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14337\" href=\"/pdf/2506.14337\" id=\"pdf-2506.14337\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14337\" href=\"https://arxiv.org/html/2506.14337v1\" id=\"html-2506.14337\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14337\" href=\"/format/2506.14337\" id=\"oth-2506.14337\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LLM-Powered Intent-Based Categorization of Phishing Emails\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Eilertsen,+E\">Even Eilertsen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mavroeidis,+V\">Vasileios Mavroeidis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Grov,+G\">Gudmund Grov</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Phishing attacks remain a significant threat to modern cybersecurity, as they successfully deceive both humans and the defense mechanisms intended to protect them. Traditional detection systems primarily focus on email metadata that users cannot see in their inboxes. Additionally, these systems struggle with phishing emails, which experienced users can often identify empirically by the text alone. This paper investigates the practical potential of Large Language Models (LLMs) to detect these emails by focusing on their intent. In addition to the binary classification of phishing emails, the paper introduces an intent-type taxonomy, which is operationalized by the LLMs to classify emails into distinct categories and, therefore, generate actionable threat information. To facilitate our work, we have curated publicly available datasets into a custom dataset containing a mix of legitimate and phishing emails. Our results demonstrate that existing LLMs are capable of detecting and categorizing phishing emails, underscoring their potential in this domain.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item133\">[133]</a>\n",
       "<a href=\"/abs/2506.14356\" id=\"2506.14356\" title=\"Abstract\">\n",
       "        arXiv:2506.14356\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14356\" href=\"/pdf/2506.14356\" id=\"pdf-2506.14356\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14356\" href=\"https://arxiv.org/html/2506.14356v1\" id=\"html-2506.14356\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14356\" href=\"/format/2506.14356\" id=\"oth-2506.14356\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xiaoqi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chau,+L\">Lap-Pui Chau</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Egocentric video-language understanding demands both high efficiency and accurate spatial-temporal modeling. Existing approaches face three key challenges: 1) Excessive pre-training cost arising from multi-stage pre-training pipelines, 2) Ineffective spatial-temporal encoding due to manually split 3D rotary positional embeddings that hinder feature interactions, and 3) Imprecise learning objectives in soft-label multi-instance retrieval, which neglect negative pair correlations. In this paper, we introduce EVA02-AT, a suite of EVA02-based video-language foundation models tailored to egocentric video understanding tasks. EVA02-AT first efficiently transfers an image-based CLIP model into a unified video encoder via a single-stage pretraining. Second, instead of applying rotary positional embeddings to isolated dimensions, we introduce spatial-temporal rotary positional embeddings along with joint attention, which can effectively encode both spatial and temporal information on the entire hidden dimension. This joint encoding of spatial-temporal features enables the model to learn cross-axis relationships, which are crucial for accurately modeling motion and interaction in videos. Third, focusing on multi-instance video-language retrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and a novel training framework that advances all soft labels for both positive and negative pairs, providing a more precise learning objective. Extensive experiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot and fine-tuning settings demonstrate that EVA02-AT achieves state-of-the-art performance across diverse egocentric video-language tasks with fewer parameters. Models with our SMS loss also show significant performance gains on multi-instance retrieval benchmarks. Our code and models are publicly available at <a class=\"link-external link-https\" href=\"https://github.com/xqwang14/EVA02-AT\" rel=\"external noopener nofollow\">this https URL</a> .\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item134\">[134]</a>\n",
       "<a href=\"/abs/2506.14375\" id=\"2506.14375\" title=\"Abstract\">\n",
       "        arXiv:2506.14375\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14375\" href=\"/pdf/2506.14375\" id=\"pdf-2506.14375\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14375\" href=\"/format/2506.14375\" id=\"oth-2506.14375\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yousuf,+M+H\">Muhammad Hamza Yousuf</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+J\">Jason Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vahdati,+S\">Sahar Vahdati</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Theilen,+R\">Raphael Theilen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wittenstein,+J\">Jakob Wittenstein</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lehmann,+J\">Jens Lehmann</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          under review, PAIS track @ ECAI 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Invasive mechanical ventilation (MV) is a life-sustaining therapy for critically ill patients in the intensive care unit (ICU). However, optimizing its settings remains a complex and error-prone process due to patient-specific variability. While Offline Reinforcement Learning (RL) shows promise for MV control, current stateof-the-art (SOTA) methods struggle with the hybrid (continuous and discrete) nature of MV actions. Discretizing the action space limits available actions due to exponential growth in combinations and introduces distribution shifts that can compromise safety. In this paper, we propose optimizations that build upon prior work in action space reduction to address the challenges of discrete action spaces. We also adapt SOTA offline RL algorithms (IQL and EDAC) to operate directly on hybrid action spaces, thereby avoiding the pitfalls of discretization. Additionally, we introduce a clinically grounded reward function based on ventilator-free days and physiological targets, which provides a more meaningful optimization objective compared to traditional sparse mortality-based rewards. Our findings demonstrate that AI-assisted MV optimization may enhance patient safety and enable individualized lung support, representing a significant advancement toward intelligent, data-driven critical care solutions.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item135\">[135]</a>\n",
       "<a href=\"/abs/2506.14382\" id=\"2506.14382\" title=\"Abstract\">\n",
       "        arXiv:2506.14382\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14382\" href=\"/pdf/2506.14382\" id=\"pdf-2506.14382\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14382\" href=\"https://arxiv.org/html/2506.14382v1\" id=\"html-2506.14382\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14382\" href=\"/format/2506.14382\" id=\"oth-2506.14382\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          DepthSeg: Depth prompting in remote sensing semantic segmentation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+N\">Ning Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+S\">Shanxiong Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+M\">Mingting Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sui,+H\">Haigang Sui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+L\">Lieyun Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H\">Han Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hua,+L\">Li Hua</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+Q\">Qiming Zhou</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Remote sensing semantic segmentation is crucial for extracting detailed land surface information, enabling applications such as environmental monitoring, land use planning, and resource assessment. In recent years, advancements in artificial intelligence have spurred the development of automatic remote sensing semantic segmentation methods. However, the existing semantic segmentation methods focus on distinguishing spectral characteristics of different objects while ignoring the differences in the elevation of the different targets. This results in land cover misclassification in complex scenarios involving shadow occlusion and spectral confusion. In this paper, we introduce a depth prompting two-dimensional (2D) remote sensing semantic segmentation framework (DepthSeg). It automatically models depth/height information from 2D remote sensing images and integrates it into the semantic segmentation framework to mitigate the effects of spectral confusion and shadow occlusion. During the feature extraction phase of DepthSeg, we introduce a lightweight adapter to enable cost-effective fine-tuning of the large-parameter vision transformer encoder pre-trained by natural images. In the depth prompting phase, we propose a depth prompter to model depth/height features explicitly. In the semantic prediction phase, we introduce a semantic classification decoder that couples the depth prompts with high-dimensional land-cover features, enabling accurate extraction of land-cover types. Experiments on the LiuZhou dataset validate the advantages of the DepthSeg framework in land cover mapping tasks. Detailed ablation studies further highlight the significance of the depth prompts in remote sensing semantic segmentation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item136\">[136]</a>\n",
       "<a href=\"/abs/2506.14386\" id=\"2506.14386\" title=\"Abstract\">\n",
       "        arXiv:2506.14386\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14386\" href=\"/pdf/2506.14386\" id=\"pdf-2506.14386\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14386\" href=\"https://arxiv.org/html/2506.14386v1\" id=\"html-2506.14386\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14386\" href=\"/format/2506.14386\" id=\"oth-2506.14386\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ResNets Are Deeper Than You Think\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mehmeti-G%C3%B6pel,+C+H+A\">Christian H.X. Ali Mehmeti-Göpel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wand,+M\">Michael Wand</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          NeurIPS 2025 Submission\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Residual connections remain ubiquitous in modern neural network architectures nearly a decade after their introduction. Their widespread adoption is often credited to their dramatically improved trainability: residual networks train faster, more stably, and achieve higher accuracy than their feedforward counterparts. While numerous techniques, ranging from improved initialization to advanced learning rate schedules, have been proposed to close the performance gap between residual and feedforward networks, this gap has persisted. In this work, we propose an alternative explanation: residual networks do not merely reparameterize feedforward networks, but instead inhabit a different function space. We design a controlled post-training comparison to isolate generalization performance from trainability; we find that variable-depth architectures, similar to ResNets, consistently outperform fixed-depth networks, even when optimization is unlikely to make a difference. These results suggest that residual connections confer performance advantages beyond optimization, pointing instead to a deeper inductive bias aligned with the structure of natural data.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item137\">[137]</a>\n",
       "<a href=\"/abs/2506.14391\" id=\"2506.14391\" title=\"Abstract\">\n",
       "        arXiv:2506.14391\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14391\" href=\"/pdf/2506.14391\" id=\"pdf-2506.14391\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14391\" href=\"https://arxiv.org/html/2506.14391v1\" id=\"html-2506.14391\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14391\" href=\"/format/2506.14391\" id=\"oth-2506.14391\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+Y\">Yaqiao Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wen,+H\">Hongkai Wen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Min,+G\">Geyong Min</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+M\">Man Luo</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Efficient traffic signal control (TSC) is essential for mitigating urban congestion, yet existing reinforcement learning (RL) methods face challenges in scaling to large networks while maintaining global coordination. Centralized RL suffers from scalability issues, while decentralized approaches often lack unified objectives, resulting in limited network-level efficiency. In this paper, we propose HiLight, a hierarchical reinforcement learning framework with global adversarial guidance for large-scale TSC. HiLight consists of a high-level Meta-Policy, which partitions the traffic network into subregions and generates sub-goals using a Transformer-LSTM architecture, and a low-level Sub-Policy, which controls individual intersections with global awareness. To improve the alignment between global planning and local execution, we introduce an adversarial training mechanism, where the Meta-Policy generates challenging yet informative sub-goals, and the Sub-Policy learns to surpass these targets, leading to more effective coordination. We evaluate HiLight across both synthetic and real-world benchmarks, and additionally construct a large-scale Manhattan network with diverse traffic conditions, including peak transitions, adverse weather, and holiday surges. Experimental results show that HiLight exhibits significant advantages in large-scale scenarios and remains competitive across standard benchmarks of varying sizes.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item138\">[138]</a>\n",
       "<a href=\"/abs/2506.14399\" id=\"2506.14399\" title=\"Abstract\">\n",
       "        arXiv:2506.14399\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14399\" href=\"/pdf/2506.14399\" id=\"pdf-2506.14399\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14399\" href=\"https://arxiv.org/html/2506.14399v1\" id=\"html-2506.14399\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14399\" href=\"/format/2506.14399\" id=\"oth-2506.14399\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xia,+T\">Tian Xia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=De+Sousa+Ribeiro,+F\">Fabio De Sousa Ribeiro</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rasal,+R+R\">Rajat R Rasal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kori,+A\">Avinash Kori</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mehta,+R\">Raghav Mehta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Glocker,+B\">Ben Glocker</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item139\">[139]</a>\n",
       "<a href=\"/abs/2506.14404\" id=\"2506.14404\" title=\"Abstract\">\n",
       "        arXiv:2506.14404\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14404\" href=\"/pdf/2506.14404\" id=\"pdf-2506.14404\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14404\" href=\"https://arxiv.org/html/2506.14404v1\" id=\"html-2506.14404\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14404\" href=\"/format/2506.14404\" id=\"oth-2506.14404\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Causally Steered Diffusion for Automated Video Counterfactual Generation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Spyrou,+N\">Nikos Spyrou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vlontzos,+A\">Athanasios Vlontzos</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pegios,+P\">Paraskevas Pegios</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Melistas,+T\">Thomas Melistas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gkouti,+N\">Nefeli Gkouti</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Panagakis,+Y\">Yannis Panagakis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Papanastasiou,+G\">Giorgos Papanastasiou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tsaftaris,+S+A\">Sotirios A. Tsaftaris</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Adapting text-to-image (T2I) latent diffusion models for video editing has shown strong visual fidelity and controllability, but challenges remain in maintaining causal relationships in video content. Edits affecting causally dependent attributes risk generating unrealistic or misleading outcomes if these relationships are ignored. In this work, we propose a causally faithful framework for counterfactual video generation, guided by a vision-language model (VLM). Our method is agnostic to the underlying video editing system and does not require access to its internal mechanisms or finetuning. Instead, we guide the generation by optimizing text prompts based on an assumed causal graph, addressing the challenge of latent space control in LDMs. We evaluate our approach using standard video quality metrics and counterfactual-specific criteria, such as causal effectiveness and minimality. Our results demonstrate that causally faithful video counterfactuals can be effectively generated within the learned distribution of LDMs through prompt-based causal steering. With its compatibility with any black-box video editing system, our method holds significant potential for generating realistic \"what-if\" video scenarios in diverse areas such as healthcare and digital media.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item140\">[140]</a>\n",
       "<a href=\"/abs/2506.14407\" id=\"2506.14407\" title=\"Abstract\">\n",
       "        arXiv:2506.14407\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14407\" href=\"/pdf/2506.14407\" id=\"pdf-2506.14407\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14407\" href=\"https://arxiv.org/html/2506.14407v1\" id=\"html-2506.14407\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14407\" href=\"/format/2506.14407\" id=\"oth-2506.14407\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Taghavi,+Z+S\">Zeinab Sadat Taghavi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Modarressi,+A\">Ali Modarressi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+Y\">Yunpu Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%BCtze,+H\">Hinrich Schütze</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Retrieval systems are central to many NLP pipelines, but often rely on surface-level cues such as keyword overlap and lexical semantic similarity. To evaluate retrieval beyond these shallow signals, recent benchmarks introduce reasoning-heavy queries; however, they primarily shift the burden to query-side processing techniques -- like prompting or multi-hop retrieval -- that can help resolve complexity. In contrast, we present ImpliRet, a benchmark that shifts the reasoning challenge to document-side processing: The queries are simple, but relevance depends on facts stated implicitly in documents through temporal (e.g., resolving \"two days ago\"), arithmetic, and world knowledge relationships. We evaluate a range of sparse and dense retrievers, all of which struggle in this setting: the best nDCG@10 is only 15.07%. We also test whether long-context models can overcome this limitation. But even with a short context of only ten documents, including the positive document, GPT-4.1 scores only 35.06%, showing that document-side reasoning remains a challenge. Our codes are available at <a class=\"link-external link-http\" href=\"http://github.com/ZeinabTaghavi/IMPLIRET.Contribution\" rel=\"external noopener nofollow\">this http URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item141\">[141]</a>\n",
       "<a href=\"/abs/2506.14411\" id=\"2506.14411\" title=\"Abstract\">\n",
       "        arXiv:2506.14411\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14411\" href=\"/pdf/2506.14411\" id=\"pdf-2506.14411\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14411\" href=\"https://arxiv.org/html/2506.14411v1\" id=\"html-2506.14411\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14411\" href=\"/format/2506.14411\" id=\"oth-2506.14411\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adaptive Reinforcement Learning for Unobservable Random Delays\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wikman,+J\">John Wikman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Proutiere,+A\">Alexandre Proutiere</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Broman,+D\">David Broman</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In standard Reinforcement Learning (RL) settings, the interaction between the agent and the environment is typically modeled as a Markov Decision Process (MDP), which assumes that the agent observes the system state instantaneously, selects an action without delay, and executes it immediately. In real-world dynamic environments, such as cyber-physical systems, this assumption often breaks down due to delays in the interaction between the agent and the system. These delays can vary stochastically over time and are typically unobservable, meaning they are unknown when deciding on an action. Existing methods deal with this uncertainty conservatively by assuming a known fixed upper bound on the delay, even if the delay is often much lower. In this work, we introduce the interaction layer, a general framework that enables agents to adaptively and seamlessly handle unobservable and time-varying delays. Specifically, the agent generates a matrix of possible future actions to handle both unpredictable delays and lost action packets sent over networks. Building on this framework, we develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA), which dynamically adjusts to delay patterns. Our method significantly outperforms state-of-the-art approaches across a wide range of locomotion benchmark environments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item142\">[142]</a>\n",
       "<a href=\"/abs/2506.14412\" id=\"2506.14412\" title=\"Abstract\">\n",
       "        arXiv:2506.14412\n",
       "      </a>\n",
       "          (cross-list from cs.IR)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14412\" href=\"/pdf/2506.14412\" id=\"pdf-2506.14412\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14412\" href=\"https://arxiv.org/html/2506.14412v1\" id=\"html-2506.14412\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14412\" href=\"/format/2506.14412\" id=\"oth-2506.14412\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cofala,+T\">Tim Cofala</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Astappiev,+O\">Oleh Astappiev</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xion,+W\">William Xion</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Teklehaymanot,+H\">Hailay Teklehaymanot</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          4 pages, 5 figures. Report for SIGIR 2025 LiveRAG Challenge\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Retrieval-Augmented Generation (RAG) enriches Large Language Models (LLMs) by combining their internal, parametric knowledge with external, non-parametric sources, with the goal of improving factual correctness and minimizing hallucinations. The LiveRAG 2025 challenge explores RAG solutions to maximize accuracy on DataMorgana's QA pairs, which are composed of single-hop and multi-hop questions. The challenge provides access to sparse OpenSearch and dense Pinecone indices of the Fineweb 10BT dataset. It restricts model use to LLMs with up to 10B parameters and final answer generation with Falcon-3-10B. A judge-LLM assesses the submitted answers along with human evaluators. By exploring distinct retriever combinations and RAG solutions under the challenge conditions, our final solution emerged using InstructRAG in combination with a Pinecone retriever and a BGE reranker. Our solution achieved a correctness score of 1.13 and a faithfulness score of 0.55, placing fourth in the SIGIR 2025 LiveRAG Challenge.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item143\">[143]</a>\n",
       "<a href=\"/abs/2506.14418\" id=\"2506.14418\" title=\"Abstract\">\n",
       "        arXiv:2506.14418\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14418\" href=\"/pdf/2506.14418\" id=\"pdf-2506.14418\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14418\" href=\"https://arxiv.org/html/2506.14418v1\" id=\"html-2506.14418\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14418\" href=\"/format/2506.14418\" id=\"oth-2506.14418\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Compositional Attribute Imbalance in Vision Datasets\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jiayi Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+Y\">Yanbiao Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+A\">Andi Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+W\">Weidong Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+W\">Wei Dai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+B\">Bowei Liu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Visual attribute imbalance is a common yet underexplored issue in image classification, significantly impacting model performance and generalization. In this work, we first define the first-level and second-level attributes of images and then introduce a CLIP-based framework to construct a visual attribute dictionary, enabling automatic evaluation of image attributes. By systematically analyzing both single-attribute imbalance and compositional attribute imbalance, we reveal how the rarity of attributes affects model performance. To tackle these challenges, we propose adjusting the sampling probability of samples based on the rarity of their compositional attributes. This strategy is further integrated with various data augmentation techniques (such as CutMix, Fmix, and SaliencyMix) to enhance the model's ability to represent rare attributes. Extensive experiments on benchmark datasets demonstrate that our method effectively mitigates attribute imbalance, thereby improving the robustness and fairness of deep neural networks. Our research highlights the importance of modeling visual attribute distributions and provides a scalable solution for long-tail image classification tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item144\">[144]</a>\n",
       "<a href=\"/abs/2506.14425\" id=\"2506.14425\" title=\"Abstract\">\n",
       "        arXiv:2506.14425\n",
       "      </a>\n",
       "          (cross-list from cs.NE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14425\" href=\"/pdf/2506.14425\" id=\"pdf-2506.14425\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14425\" href=\"https://arxiv.org/html/2506.14425v1\" id=\"html-2506.14425\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14425\" href=\"/format/2506.14425\" id=\"oth-2506.14425\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Is Selection All You Need in Differential Evolution?\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kitamura,+T\">Tomofumi Kitamura</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fukunaga,+A\">Alex Fukunaga</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          39 pages, 7 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Differential Evolution (DE) is a widely used evolutionary algorithm for black-box optimization problems. However, in modern DE implementations, a major challenge lies in the limited population diversity caused by the fixed population size enforced by the generational replacement. Population size is a critical control parameter that significantly affects DE performance. Larger populations inherently contain a more diverse set of individuals, thereby facilitating broader exploration of the search space. Conversely, when the maximum evaluation budgets is constrained, smaller populations focusing on a limited number of promising candidates may be more suitable. Many state-of-the-art DE variants incorporate an archive mechanism, in which a subset of discarded individuals is preserved in an archive during generation replacement and reused in mutation operations. However, maintaining what is essentially a secondary population via an archive introduces additional design considerations, such as policies for insertion, deletion, and appropriate sizing. To address these limitations, we propose a novel DE framework called Unbounded Differential Evolution (UDE), which adds all generated candidates to the population without discarding any individual based on fitness. Unlike conventional DE, which removes inferior individuals during generational replacement, UDE eliminates replacement altogether, along with the associated complexities of archive management and dynamic population sizing. UDE represents a fundamentally new approach to DE, relying solely on selection mechanisms and enabling a more straightforward yet powerful search algorithm.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item145\">[145]</a>\n",
       "<a href=\"/abs/2506.14434\" id=\"2506.14434\" title=\"Abstract\">\n",
       "        arXiv:2506.14434\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14434\" href=\"/pdf/2506.14434\" id=\"pdf-2506.14434\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14434\" href=\"https://arxiv.org/html/2506.14434v1\" id=\"html-2506.14434\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14434\" href=\"/format/2506.14434\" id=\"oth-2506.14434\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Unifying Streaming and Non-streaming Zipformer-based ASR\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+B\">Bidisha Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Durai,+K+P\">Karthik Pandia Durai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Venkatesan,+S\">Shankar Venkatesan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Prakash,+J+J\">Jeena J Prakash</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar,+S\">Shashi Kumar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chetlur,+M\">Malolan Chetlur</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Stolcke,+A\">Andreas Stolcke</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted in ACL2025 Industry track\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          There has been increasing interest in unifying streaming and non-streaming automatic speech recognition (ASR) models to reduce development, training, and deployment costs. We present a unified framework that trains a single end-to-end ASR model for both streaming and non-streaming applications, leveraging future context information. We propose to use dynamic right-context through the chunked attention masking in the training of zipformer-based ASR models. We demonstrate that using right-context is more effective in zipformer models compared to other conformer models due to its multi-scale nature. We analyze the effect of varying the number of right-context frames on accuracy and latency of the streaming ASR models. We use Librispeech and large in-house conversational datasets to train different versions of streaming and non-streaming models and evaluate them in a production grade server-client setup across diverse testsets of different domains. The proposed strategy reduces word error by relative 7.9\\% with a small degradation in user-perceived latency. By adding more right-context frames, we are able to achieve streaming performance close to that of non-streaming models. Our approach also allows flexible control of the latency-accuracy tradeoff according to customers requirements.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item146\">[146]</a>\n",
       "<a href=\"/abs/2506.14438\" id=\"2506.14438\" title=\"Abstract\">\n",
       "        arXiv:2506.14438\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14438\" href=\"/pdf/2506.14438\" id=\"pdf-2506.14438\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14438\" href=\"https://arxiv.org/html/2506.14438v1\" id=\"html-2506.14438\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14438\" href=\"/format/2506.14438\" id=\"oth-2506.14438\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          sHGCN: Simplified hyperbolic graph convolutional neural networks\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ar%C3%A9valo,+P\">Pol Arévalo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Molina,+A\">Alexis Molina</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ciudad,+%C3%81\">Álvaro Ciudad</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Hyperbolic geometry has emerged as a powerful tool for modeling complex, structured data, particularly where hierarchical or tree-like relationships are present. By enabling embeddings with lower distortion, hyperbolic neural networks offer promising alternatives to Euclidean-based models for capturing intricate data structures. Despite these advantages, they often face performance challenges, particularly in computational efficiency and tasks requiring high precision. In this work, we address these limitations by simplifying key operations within hyperbolic neural networks, achieving notable improvements in both runtime and performance. Our findings demonstrate that streamlined hyperbolic operations can lead to substantial gains in computational speed and predictive accuracy, making hyperbolic neural networks a more viable choice for a broader range of applications.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item147\">[147]</a>\n",
       "<a href=\"/abs/2506.14440\" id=\"2506.14440\" title=\"Abstract\">\n",
       "        arXiv:2506.14440\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14440\" href=\"/pdf/2506.14440\" id=\"pdf-2506.14440\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14440\" href=\"https://arxiv.org/html/2506.14440v1\" id=\"html-2506.14440\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14440\" href=\"/format/2506.14440\" id=\"oth-2506.14440\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Model compression using knowledge distillation with integrated gradients\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hernandez,+D+E\">David E. Hernandez</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chang,+J\">Jose Chang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nordling,+T+E+M\">Torbjörn E. M. Nordling</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          49 pages, 12 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Model compression is critical for deploying deep learning models on resource-constrained devices. We introduce a novel method enhancing knowledge distillation with integrated gradients (IG) as a data augmentation strategy. Our approach overlays IG maps onto input images during training, providing student models with deeper insights into teacher models' decision-making processes. Extensive evaluation on CIFAR-10 demonstrates that our IG-augmented knowledge distillation achieves 92.6% testing accuracy with a 4.1x compression factor-a significant 1.1 percentage point improvement ($p&lt;0.001$) over non-distilled models (91.5%). This compression reduces inference time from 140 ms to 13 ms. Our method precomputes IG maps before training, transforming substantial runtime costs into a one-time preprocessing step. Our comprehensive experiments include: (1) comparisons with attention transfer, revealing complementary benefits when combined with our approach; (2) Monte Carlo simulations confirming statistical robustness; (3) systematic evaluation of compression factor versus accuracy trade-offs across a wide range (2.2x-1122x); and (4) validation on an ImageNet subset aligned with CIFAR-10 classes, demonstrating generalisability beyond the initial dataset. These extensive ablation studies confirm that IG-based knowledge distillation consistently outperforms conventional approaches across varied architectures and compression ratios. Our results establish this framework as a viable compression technique for real-world deployment on edge devices while maintaining competitive accuracy.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item148\">[148]</a>\n",
       "<a href=\"/abs/2506.14451\" id=\"2506.14451\" title=\"Abstract\">\n",
       "        arXiv:2506.14451\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14451\" href=\"/pdf/2506.14451\" id=\"pdf-2506.14451\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14451\" href=\"https://arxiv.org/html/2506.14451v1\" id=\"html-2506.14451\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14451\" href=\"/format/2506.14451\" id=\"oth-2506.14451\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adapting Lightweight Vision Language Models for Radiological Visual Question Answering\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shourya,+A\">Aditya Shourya</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dumontier,+M\">Michel Dumontier</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+C\">Chang Sun</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advancements in vision-language systems have improved the accuracy of Radiological Visual Question Answering (VQA) Models. However, some challenges remain across each stage of model development: limited expert-labeled images hinders data procurement at scale; the intricate and nuanced patterns of radiological images make modeling inherently difficult; and the lack of evaluation evaluation efforts makes it difficult to identify cases where the model might be ill-conditioned. In this study, we fine-tune a lightweight 3B parameter vision-language model for Radiological VQA, demonstrating that small models, when appropriately tuned with curated data, can achieve robust performance across both open- and closed-ended questions. We propose a cost-effective training pipeline from synthetic question-answer pair generation to multi-stage fine-tuning on specialised radiological domain-targeted datasets (e.g., ROCO v2.0, MedPix v2.0). Our results show that despite operating at a fraction of the scale of state-of-the-art models such as LLaVA-Med, our model achieves promising performance given its small parameter size and the limited scale of training data. We introduce a lightweight saliency-based diagnostic tool that enables domain experts to inspect VQA model performance and identify ill-conditioned failure modes through saliency analysis.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item149\">[149]</a>\n",
       "<a href=\"/abs/2506.14456\" id=\"2506.14456\" title=\"Abstract\">\n",
       "        arXiv:2506.14456\n",
       "      </a>\n",
       "          (cross-list from quant-ph)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14456\" href=\"/pdf/2506.14456\" id=\"pdf-2506.14456\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14456\" href=\"https://arxiv.org/html/2506.14456v1\" id=\"html-2506.14456\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14456\" href=\"/format/2506.14456\" id=\"oth-2506.14456\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Hamiltonian Formalism for Comparing Quantum and Classical Intelligence\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/quant-ph?searchtype=author&amp;query=Perrier,+E\">Elija Perrier</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This is the version accepted at AGI 25 (camera ready length limit of 10 pages plus references and appendices). Further work detailing bounds and limitations is in preparation. Comments and criticisms welcome\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The prospect of AGI instantiated on quantum substrates motivates the development of mathematical frameworks that enable direct comparison of their operation in classical and quantum environments. To this end, we introduce a Hamiltonian formalism for describing classical and quantum AGI tasks as a means of contrasting their interaction with the environment. We propose a decomposition of AGI dynamics into Hamiltonian generators for core functions such as induction, reasoning, recursion, learning, measurement, and memory. This formalism aims to contribute to the development of a precise mathematical language for how quantum and classical agents differ via environmental interaction.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item150\">[150]</a>\n",
       "<a href=\"/abs/2506.14464\" id=\"2506.14464\" title=\"Abstract\">\n",
       "        arXiv:2506.14464\n",
       "      </a>\n",
       "          (cross-list from cs.NE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14464\" href=\"/pdf/2506.14464\" id=\"pdf-2506.14464\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14464\" href=\"https://arxiv.org/html/2506.14464v1\" id=\"html-2506.14464\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14464\" href=\"/format/2506.14464\" id=\"oth-2506.14464\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Baronig,+M\">Maximilian Baronig</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bahariasl,+Y\">Yeganeh Bahariasl</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=%C3%96zdenizci,+O\">Ozan Özdenizci</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Legenstein,+R\">Robert Legenstein</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recurrent spiking neural networks (RSNNs) can be implemented very efficiently in neuromorphic systems. Nevertheless, training of these models with powerful gradient-based learning algorithms is mostly performed on standard digital hardware using Backpropagation through time (BPTT). However, BPTT has substantial limitations. It does not permit online training and its memory consumption scales linearly with the number of computation steps. In contrast, learning methods using forward propagation of gradients operate in an online manner with a memory consumption independent of the number of time steps. These methods enable SNNs to learn from continuous, infinite-length input sequences. Yet, slow execution speed on conventional hardware as well as inferior performance has hindered their widespread application. In this work, we introduce HYbrid PRopagation (HYPR) that combines the efficiency of parallelization with approximate online forward learning. Our algorithm yields high-throughput online learning through parallelization, paired with constant, i.e., sequence length independent, memory demands. HYPR enables parallelization of parameter update computation over the sub sequences for RSNNs consisting of almost arbitrary non-linear spiking neuron models. We apply HYPR to networks of spiking neurons with oscillatory subthreshold dynamics. We find that this type of neuron model is particularly well trainable by HYPR, resulting in an unprecedentedly low task performance gap between approximate forward gradient learning and BPTT.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item151\">[151]</a>\n",
       "<a href=\"/abs/2506.14472\" id=\"2506.14472\" title=\"Abstract\">\n",
       "        arXiv:2506.14472\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14472\" href=\"/pdf/2506.14472\" id=\"pdf-2506.14472\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14472\" href=\"https://arxiv.org/html/2506.14472v1\" id=\"html-2506.14472\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14472\" href=\"/format/2506.14472\" id=\"oth-2506.14472\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bernier,+F\">Fabien Bernier</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cordy,+M\">Maxime Cordy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Traon,+Y+L\">Yves Le Traon</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ECML PKDD 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Accurate electrical consumption forecasting is crucial for efficient energy management and resource allocation. While traditional time series forecasting relies on historical patterns and temporal dependencies, incorporating external factors -- such as weather indicators -- has shown significant potential for improving prediction accuracy in complex real-world applications. However, the inclusion of these additional features often degrades the performance of global predictive models trained on entire populations, despite improving individual household-level models. To address this challenge, we found that a hypernetwork architecture can effectively leverage external factors to enhance the accuracy of global electrical consumption forecasting models, by specifically adjusting the model weights to each consumer.\n",
       "<br/>We collected a comprehensive dataset spanning two years, comprising consumption data from over 6000 luxembourgish households and corresponding external factors such as weather indicators, holidays, and major local events. By comparing various forecasting models, we demonstrate that a hypernetwork approach outperforms existing methods when associated to external factors, reducing forecasting errors and achieving the best accuracy while maintaining the benefits of a global model.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item152\">[152]</a>\n",
       "<a href=\"/abs/2506.14513\" id=\"2506.14513\" title=\"Abstract\">\n",
       "        arXiv:2506.14513\n",
       "      </a>\n",
       "          (cross-list from cs.RO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14513\" href=\"/pdf/2506.14513\" id=\"pdf-2506.14513\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14513\" href=\"https://arxiv.org/html/2506.14513v1\" id=\"html-2506.14513\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14513\" href=\"/format/2506.14513\" id=\"oth-2506.14513\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wasay,+F+A\">Farha Abdul Wasay</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rahman,+M+A\">Mohammed Abdul Rahman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ghouse,+H\">Hania Ghouse</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The convergence of robotics and virtual reality (VR) has enabled safer and more efficient workflows in high-risk laboratory settings, particularly virology labs. As biohazard complexity increases, minimizing direct human exposure while maintaining precision becomes essential. We propose GAMORA (Gesture Articulated Meta Operative Robotic Arm), a novel VR-guided robotic system that enables remote execution of hazardous tasks using natural hand gestures. Unlike existing scripted automation or traditional teleoperation, GAMORA integrates the Oculus Quest 2, NVIDIA Jetson Nano, and Robot Operating System (ROS) to provide real-time immersive control, digital twin simulation, and inverse kinematics-based articulation. The system supports VR-based training and simulation while executing precision tasks in physical environments via a 3D-printed robotic arm. Inverse kinematics ensure accurate manipulation for delicate operations such as specimen handling and pipetting. The pipeline includes Unity-based 3D environment construction, real-time motion planning, and hardware-in-the-loop testing. GAMORA achieved a mean positional discrepancy of 2.2 mm (improved from 4 mm), pipetting accuracy within 0.2 mL, and repeatability of 1.2 mm across 50 trials. Integrated object detection via YOLOv8 enhances spatial awareness, while energy-efficient operation (50% reduced power output) ensures sustainable deployment. The system's digital-physical feedback loop enables safe, precise, and repeatable automation of high-risk lab tasks. GAMORA offers a scalable, immersive solution for robotic control and biosafety in biomedical research environments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item153\">[153]</a>\n",
       "<a href=\"/abs/2506.14530\" id=\"2506.14530\" title=\"Abstract\">\n",
       "        arXiv:2506.14530\n",
       "      </a>\n",
       "          (cross-list from stat.ML)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14530\" href=\"/pdf/2506.14530\" id=\"pdf-2506.14530\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14530\" href=\"https://arxiv.org/html/2506.14530v1\" id=\"html-2506.14530\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14530\" href=\"/format/2506.14530\" id=\"oth-2506.14530\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Kratsios,+A\">Anastasis Kratsios</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Cheng,+T+S\">Tin Sum Cheng</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Lucchi,+A\">Aurelien Lucchi</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=de+Oc%C3%A1riz+Borde,+H+S\">Haitz Sáez de Ocáriz Borde</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Statistics Theory (math.ST)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Low-Rank Adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning (PEFT) technique for foundation models. Recent work has highlighted an inherent asymmetry in the initialization of LoRA's low-rank factors, which has been present since its inception and was presumably derived experimentally. This paper focuses on providing a comprehensive theoretical characterization of asymmetric LoRA with frozen random factors. First, while existing research provides upper-bound generalization guarantees based on averages over multiple experiments, the behaviour of a single fine-tuning run with specific random factors remains an open question. We address this by investigating the concentration of the typical LoRA generalization gap around its mean. Our main upper bound reveals a sample complexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{r}}{\\sqrt{N}}\\right)$ with high probability for rank $r$ LoRAs trained on $N$ samples. Additionally, we also determine the fundamental limits in terms of sample efficiency, establishing a matching lower bound of $\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)$. By more closely reflecting the practical scenario of a single fine-tuning run, our findings offer crucial insights into the reliability and practicality of asymmetric LoRA.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item154\">[154]</a>\n",
       "<a href=\"/abs/2506.14534\" id=\"2506.14534\" title=\"Abstract\">\n",
       "        arXiv:2506.14534\n",
       "      </a>\n",
       "          (cross-list from math.ST)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14534\" href=\"/pdf/2506.14534\" id=\"pdf-2506.14534\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14534\" href=\"https://arxiv.org/html/2506.14534v1\" id=\"html-2506.14534\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14534\" href=\"/format/2506.14534\" id=\"oth-2506.14534\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Complete Characterization for Adjustment in Summary Causal Graphs of Time Series\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/math?searchtype=author&amp;query=Yvernes,+C\">Clément Yvernes</a>, <a href=\"https://arxiv.org/search/math?searchtype=author&amp;query=Devijver,+E\">Emilie Devijver</a>, <a href=\"https://arxiv.org/search/math?searchtype=author&amp;query=Gaussier,+E\">Eric Gaussier</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at the 41st Conference on Uncertainty in Artificial Intelligence (UAI)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Statistics Theory (math.ST)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The identifiability problem for interventions aims at assessing whether the total causal effect can be written with a do-free formula, and thus be estimated from observational data only. We study this problem, considering multiple interventions, in the context of time series when only an abstraction of the true causal graph, in the form of a summary causal graph, is available. We propose in particular both necessary and sufficient conditions for the adjustment criterion, which we show is complete in this setting, and provide a pseudo-linear algorithm to decide whether the query is identifiable or not.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item155\">[155]</a>\n",
       "<a href=\"/abs/2506.14535\" id=\"2506.14535\" title=\"Abstract\">\n",
       "        arXiv:2506.14535\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14535\" href=\"/pdf/2506.14535\" id=\"pdf-2506.14535\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14535\" href=\"https://arxiv.org/html/2506.14535v1\" id=\"html-2506.14535\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14535\" href=\"/format/2506.14535\" id=\"oth-2506.14535\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Automatic Qiskit Code Refactoring Using Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Su%C3%A1rez,+J+M\">José Manuel Suárez</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bibb%C3%B3,+L+M\">Luis Mariano Bibbó</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bogado,+J\">Joaquin Bogado</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandez,+A\">Alejandro Fernandez</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Submitted for review to \"Taller Latinoamericano de Ingeniería de Software Cuántico\" (<a class=\"link-external link-https\" href=\"https://www.ripaisc.net/call-for-papers-tlisc-2025/\" rel=\"external noopener nofollow\">this https URL</a>)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          As quantum software frameworks evolve, developers face increasing challenges in maintaining compatibility with rapidly changing APIs. In this work, we present a novel methodology for refactoring Qiskit code using large language models (LLMs). We begin by extracting a taxonomy of migration scenarios from the different sources of official Qiskit documentation (such as release notes), capturing common patterns such as migration of functionality to different modules and deprecated usage. This taxonomy, along with the original Python source code, is provided as input to an LLM, which is then tasked with identifying instances of migration scenarios in the code and suggesting appropriate refactoring solutions. Our approach is designed to address the context length limitations of current LLMs by structuring the input and reasoning process in a targeted, efficient manner. The results demonstrate that LLMs, when guided by domain-specific migration knowledge, can effectively assist in automating Qiskit code migration. This work contributes both a set of proven prompts and taxonomy for Qiskit code migration from earlier versions to version 0.46 and a methodology to asses the capabilities of LLMs to assist in the migration of quantum code.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item156\">[156]</a>\n",
       "<a href=\"/abs/2506.14540\" id=\"2506.14540\" title=\"Abstract\">\n",
       "        arXiv:2506.14540\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14540\" href=\"/pdf/2506.14540\" id=\"pdf-2506.14540\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14540\" href=\"https://arxiv.org/html/2506.14540v1\" id=\"html-2506.14540\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14540\" href=\"/format/2506.14540\" id=\"oth-2506.14540\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Flores,+G+A\">Gerardo A. Flores</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Smith,+A+H\">Alyssa H. Smith</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fukuyama,+J+A\">Julia A. Fukuyama</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wilson,+A+C\">Ashia C. Wilson</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Machine learning-based decision support systems are increasingly deployed in clinical settings, where probabilistic scoring functions are used to inform and prioritize patient management decisions. However, widely used scoring rules, such as accuracy and AUC-ROC, fail to adequately reflect key clinical priorities, including calibration, robustness to distributional shifts, and sensitivity to asymmetric error costs. In this work, we propose a principled yet practical evaluation framework for selecting calibrated thresholded classifiers that explicitly accounts for the uncertainty in class prevalences and domain-specific cost asymmetries often found in clinical settings. Building on the theory of proper scoring rules, particularly the Schervish representation, we derive an adjusted variant of cross-entropy (log score) that averages cost-weighted performance over clinically relevant ranges of class balance. The resulting evaluation is simple to apply, sensitive to clinical deployment conditions, and designed to prioritize models that are both calibrated and robust to real-world variations.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item157\">[157]</a>\n",
       "<a href=\"/abs/2506.14562\" id=\"2506.14562\" title=\"Abstract\">\n",
       "        arXiv:2506.14562\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14562\" href=\"/pdf/2506.14562\" id=\"pdf-2506.14562\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14562\" href=\"https://arxiv.org/html/2506.14562v1\" id=\"html-2506.14562\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14562\" href=\"/format/2506.14562\" id=\"oth-2506.14562\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+D\">Di He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jaiswal,+A\">Ajay Jaiswal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tu,+S\">Songjun Tu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+L\">Li Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+G\">Ganzhao Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Shiwei Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+L\">Lu Yin</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Weight decay is a standard regularization technique for training large language models (LLMs). While it is common to assign a uniform decay rate to every layer, this approach overlooks the structural diversity of LLMs and the varying spectral properties across modules. In this paper, we introduce AlphaDecay, a simple yet effective method that adaptively assigns different weight decay strengths to each module of an LLM. Our approach is guided by Heavy-Tailed Self-Regularization (HT-SR) theory, which analyzes the empirical spectral density (ESD) of weight correlation matrices to quantify \"heavy-tailedness.\" Modules exhibiting more pronounced heavy-tailed ESDs, reflecting stronger feature learning, are assigned weaker decay, while modules with lighter-tailed spectra receive stronger decay. Our method leverages tailored weight decay assignments to balance the module-wise differences in spectral properties, leading to improved performance. Extensive pre-training tasks with various model sizes from 60M to 1B demonstrate that AlphaDecay achieves better perplexity and generalization than conventional uniform decay and other adaptive decay baselines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item158\">[158]</a>\n",
       "<a href=\"/abs/2506.14567\" id=\"2506.14567\" title=\"Abstract\">\n",
       "        arXiv:2506.14567\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14567\" href=\"/pdf/2506.14567\" id=\"pdf-2506.14567\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14567\" href=\"/format/2506.14567\" id=\"oth-2506.14567\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Moss,+E\">Emanuel Moss</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Watkins,+E\">Elizabeth Watkins</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Persaud,+C\">Christopher Persaud</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Karunaratne,+P\">Passant Karunaratne</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nafus,+D\">Dawn Nafus</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Generative AI tools have become more prevalent in engineering workflows, particularly through chatbots and code assistants. As the perceived accuracy of these tools improves, questions arise about whether and how those who work in high-precision domains might maintain vigilance for errors, and what other aspects of using such tools might trouble their work. This paper analyzes interviews with hardware and software engineers, and their collaborators, who work in integrated circuit design to identify the role accuracy plays in their use of generative AI tools and what other forms of trouble they face in using such tools. The paper inventories these forms of trouble, which are then mapped to elements of generative AI systems, to conclude that controlling the context of interactions between engineers and the generative AI tools is one of the largest challenges they face. The paper concludes with recommendations for mitigating this form of trouble by increasing the ability to control context interactively.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item159\">[159]</a>\n",
       "<a href=\"/abs/2506.14574\" id=\"2506.14574\" title=\"Abstract\">\n",
       "        arXiv:2506.14574\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14574\" href=\"/pdf/2506.14574\" id=\"pdf-2506.14574\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14574\" href=\"https://arxiv.org/html/2506.14574v1\" id=\"html-2506.14574\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14574\" href=\"/format/2506.14574\" id=\"oth-2506.14574\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+M\">Mingkang Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+X\">Xi Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Zhongdao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+B\">Bei Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+H\">Hengshuang Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jia,+J\">Jiaya Jia</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ICML 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advancements in reinforcement learning from human feedback have shown that utilizing fine-grained token-level reward models can substantially enhance the performance of Proximal Policy Optimization (PPO) in aligning large language models. However, it is challenging to leverage such token-level reward as guidance for Direct Preference Optimization (DPO), since DPO is formulated as a sequence-level bandit problem. To address this challenge, this work decomposes the sequence-level PPO into a sequence of token-level proximal policy optimization problems and then frames the problem of token-level PPO with token-level reward guidance, from which closed-form optimal token-level policy and the corresponding token-level reward can be derived. Using the obtained reward and Bradley-Terry model, this work establishes a framework of computable loss functions with token-level reward guidance for DPO, and proposes a practical reward guidance based on the induced DPO reward. This formulation enables different tokens to exhibit varying degrees of deviation from reference policy based on their respective rewards. Experiment results demonstrate that our method achieves substantial performance improvements over DPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on AlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at <a class=\"link-external link-https\" href=\"https://github.com/dvlab-research/TGDPO\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item160\">[160]</a>\n",
       "<a href=\"/abs/2506.14577\" id=\"2506.14577\" title=\"Abstract\">\n",
       "        arXiv:2506.14577\n",
       "      </a>\n",
       "          (cross-list from cs.LG)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14577\" href=\"/pdf/2506.14577\" id=\"pdf-2506.14577\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14577\" href=\"https://arxiv.org/html/2506.14577v1\" id=\"html-2506.14577\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14577\" href=\"/format/2506.14577\" id=\"oth-2506.14577\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Object-Centric Neuro-Argumentative Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jacob,+A+R\">Abdul Rahman Jacob</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kori,+A\">Avinash Kori</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=De+Angelis,+E\">Emanuele De Angelis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Glocker,+B\">Ben Glocker</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Proietti,+M\">Maurizio Proietti</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toni,+F\">Francesca Toni</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Proceedings of Machine Learning Research, 2025 19th Conference on Neurosymbolic Learning and Reasoning\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Over the last decade, as we rely more on deep learning technologies to make critical decisions, concerns regarding their safety, reliability and interpretability have emerged. We introduce a novel Neural Argumentative Learning (NAL) architecture that integrates Assumption-Based Argumentation (ABA) with deep learning for image analysis. Our architecture consists of neural and symbolic components. The former segments and encodes images into facts using object-centric learning, while the latter applies ABA learning to develop ABA frameworks enabling predictions with images. Experiments on synthetic data show that the NAL architecture can be competitive with a state-of-the-art alternative.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item161\">[161]</a>\n",
       "<a href=\"/abs/2506.14580\" id=\"2506.14580\" title=\"Abstract\">\n",
       "        arXiv:2506.14580\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14580\" href=\"/pdf/2506.14580\" id=\"pdf-2506.14580\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14580\" href=\"https://arxiv.org/html/2506.14580v1\" id=\"html-2506.14580\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14580\" href=\"/format/2506.14580\" id=\"oth-2506.14580\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          GenerationPrograms: Fine-grained Attribution with Executable Programs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wan,+D\">David Wan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hirsch,+E\">Eran Hirsch</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Stengel-Eskin,+E\">Elias Stengel-Eskin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dagan,+I\">Ido Dagan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bansal,+M\">Mohit Bansal</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          27 Pages. Code: <a class=\"link-external link-https\" href=\"https://github.com/meetdavidwan/generationprograms\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent large language models (LLMs) achieve impressive performance in source-conditioned text generation but often fail to correctly provide fine-grained attributions for their outputs, undermining verifiability and trust. Moreover, existing attribution methods do not explain how and why models leverage the provided source documents to generate their final responses, limiting interpretability. To overcome these challenges, we introduce a modular generation framework, GenerationPrograms, inspired by recent advancements in executable \"code agent\" architectures. Unlike conventional generation methods that simultaneously generate outputs and attributions or rely on post-hoc attribution, GenerationPrograms decomposes the process into two distinct stages: first, creating an executable program plan composed of modular text operations (such as paraphrasing, compression, and fusion) explicitly tailored to the query, and second, executing these operations following the program's specified instructions to produce the final response. Empirical evaluations demonstrate that GenerationPrograms significantly improves attribution quality at both the document level and sentence level across two long-form question-answering tasks and a multi-document summarization task. We further demonstrate that GenerationPrograms can effectively function as a post-hoc attribution method, outperforming traditional techniques in recovering accurate attributions. In addition, the interpretable programs generated by GenerationPrograms enable localized refinement through modular-level improvements that further enhance overall attribution quality.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item162\">[162]</a>\n",
       "<a href=\"/abs/2506.14583\" id=\"2506.14583\" title=\"Abstract\">\n",
       "        arXiv:2506.14583\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14583\" href=\"/pdf/2506.14583\" id=\"pdf-2506.14583\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14583\" href=\"https://arxiv.org/html/2506.14583v1\" id=\"html-2506.14583\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14583\" href=\"/format/2506.14583\" id=\"oth-2506.14583\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sahukara,+K\">Krishna Sahukara</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bettouche,+Z\">Zineddine Bettouche</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fischer,+A\">Andreas Fischer</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Document pages captured by smartphones or scanners often contain tables, yet manual extraction is slow and error-prone. We introduce an automated LaTeX-based pipeline that synthesizes realistic two-column pages with visually diverse table layouts and aligned ground-truth masks. The generated corpus augments the real-world Marmot benchmark and enables a systematic resolution study of TableNet. Training TableNet on our synthetic data achieves a pixel-wise XOR error of 4.04% on our synthetic test set with a 256x256 input resolution, and 4.33% with 1024x1024. The best performance on the Marmot benchmark is 9.18% (at 256x256), while cutting manual annotation effort through automation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item163\">[163]</a>\n",
       "<a href=\"/abs/2506.14596\" id=\"2506.14596\" title=\"Abstract\">\n",
       "        arXiv:2506.14596\n",
       "      </a>\n",
       "          (cross-list from cs.CV)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14596\" href=\"/pdf/2506.14596\" id=\"pdf-2506.14596\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14596\" href=\"/format/2506.14596\" id=\"oth-2506.14596\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+M\">Ming Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X\">Xu Zhang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Existing monocular 3D pose estimation methods primarily rely on joint positional features, while overlooking intrinsic directional and angular correlations within the skeleton. As a result, they often produce implausible poses under joint occlusions or rapid motion changes. To address these challenges, we propose the PoseGRAF framework. We first construct a dual graph convolutional structure that separately processes joint and bone graphs, effectively capturing their local dependencies. A Cross-Attention module is then introduced to model interdependencies between bone directions and joint features. Building upon this, a dynamic fusion module is designed to adaptively integrate both feature types by leveraging the relational dependencies between joints and bones. An improved Transformer encoder is further incorporated in a residual manner to generate the final output. Experimental results on the Human3.6M and MPI-INF-3DHP datasets show that our method exceeds state-of-the-art approaches. Additional evaluations on in-the-wild videos further validate its generalizability. The code is publicly available at <a class=\"link-external link-https\" href=\"https://github.com/iCityLab/PoseGRAF\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item164\">[164]</a>\n",
       "<a href=\"/abs/2506.14623\" id=\"2506.14623\" title=\"Abstract\">\n",
       "        arXiv:2506.14623\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14623\" href=\"/pdf/2506.14623\" id=\"pdf-2506.14623\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14623\" href=\"https://arxiv.org/html/2506.14623v1\" id=\"html-2506.14623\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14623\" href=\"/format/2506.14623\" id=\"oth-2506.14623\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Low-code to fight climate change: the Climaborough project\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Conrardy,+A\">Aaron Conrardy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sulejmani,+A\">Armen Sulejmani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guerlain,+C\">Cindy Guerlain</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pagani,+D\">Daniele Pagani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hick,+D\">David Hick</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Satta,+M\">Matteo Satta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cabot,+J\">Jordi Cabot</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This paper was presented in the Research Projects Track of the 19th International Conference on Research Challenges in Information Science (RCIS 2025)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The EU-funded Climaborough project supports European cities to achieve carbon neutrality by 2030. Eleven cities in nine countries will deploy in real conditions products and services fostering climate transition in their local environment. The Climaborough City Platform is being developed to monitor the cities' overall progress towards their climate goals by aggregating historic and real-time data and displaying the results in user-friendly dashboards that will be used by non-technical experts to evaluate the effectiveness of local experimental initiatives, identify those that yield significant impact, and assess the potential consequences of scaling them up to a broader level. In this paper, we explain how we have put in place a low-code/no-code strategy in Climaborough in response to the project's aim to quickly deploy climate dashboards. A low-code strategy is used to accelerate the development of the dashboards. The dashboards embed a no-code philosophy that enables all types of citizen profiles to configure and adapt the dashboard to their specific needs.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item165\">[165]</a>\n",
       "<a href=\"/abs/2506.14625\" id=\"2506.14625\" title=\"Abstract\">\n",
       "        arXiv:2506.14625\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14625\" href=\"/pdf/2506.14625\" id=\"pdf-2506.14625\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14625\" href=\"https://arxiv.org/html/2506.14625v1\" id=\"html-2506.14625\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14625\" href=\"/format/2506.14625\" id=\"oth-2506.14625\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+C\">Chenchen Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zheyu Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+S\">Shuo Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Prenkaj,+B\">Bardh Prenkaj</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kasneci,+G\">Gjergji Kasneci</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          18 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Language Models (LLMs) have shown impressive moral reasoning abilities. Yet they often diverge when confronted with complex, multi-factor moral dilemmas. To address these discrepancies, we propose a framework that synthesizes multiple LLMs' moral judgments into a collectively formulated moral judgment, realigning models that deviate significantly from this consensus. Our aggregation mechanism fuses continuous moral acceptability scores (beyond binary labels) into a collective probability, weighting contributions by model reliability. For misaligned models, a targeted embedding-optimization procedure fine-tunes token embeddings for moral philosophical theories, minimizing JS divergence to the consensus while preserving semantic integrity. Experiments on a large-scale social moral dilemma dataset show our approach builds robust consensus and improves individual model fidelity. These findings highlight the value of data-driven moral alignment across multiple models and its potential for safer, more consistent AI systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item166\">[166]</a>\n",
       "<a href=\"/abs/2506.14627\" id=\"2506.14627\" title=\"Abstract\">\n",
       "        arXiv:2506.14627\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14627\" href=\"/pdf/2506.14627\" id=\"pdf-2506.14627\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14627\" href=\"https://arxiv.org/html/2506.14627v1\" id=\"html-2506.14627\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14627\" href=\"/format/2506.14627\" id=\"oth-2506.14627\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ACM Survey Draft on Formalising Software Requirements with Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Beg,+A\">Arshad Beg</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=O'Donoghue,+D\">Diarmuid O'Donoghue</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Monahan,+R\">Rosemary Monahan</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          22 pages. 6 summary tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This draft is a working document, having a summary of nighty-four (94) papers with additional sections on Traceability of Software Requirements (Section 4), Formal Methods and Its Tools (Section 5), Unifying Theories of Programming (UTP) and Theory of Institutions (Section 6). Please refer to abstract of [7,8]. Key difference of this draft from our recently anticipated ones with similar titles, i.e. AACS 2025 [7] and SAIV 2025 [8] is:\n",
       "<br/>[7] is a two page submission to ADAPT Annual Conference, Ireland. Submitted on 18th of March, 2025, it went through the light-weight blind review and accepted for poster presentation. Conference was held on 15th of May, 2025.\n",
       "<br/>[8] is a nine page paper with additional nine pages of references and summary tables, submitted to Symposium on AI Verification (SAIV 2025) on 24th of April, 2025. It went through rigorous review process. The uploaded version on <a class=\"link-external link-http\" href=\"http://arXiv.org\" rel=\"external noopener nofollow\">arXiv.org</a> [8] is the improved one of the submission, after addressing the specific suggestions to improve the paper.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item167\">[167]</a>\n",
       "<a href=\"/abs/2506.14634\" id=\"2506.14634\" title=\"Abstract\">\n",
       "        arXiv:2506.14634\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14634\" href=\"/pdf/2506.14634\" id=\"pdf-2506.14634\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14634\" href=\"/format/2506.14634\" id=\"oth-2506.14634\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=von+der+Heyde,+L\">Leah von der Heyde</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Haensch,+A\">Anna-Carolina Haensch</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%C3%9F,+B\">Bernd Weiß</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Daikeler,+J\">Jessika Daikeler</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          to appear in Survey Research Methods\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item168\">[168]</a>\n",
       "<a href=\"/abs/2506.14640\" id=\"2506.14640\" title=\"Abstract\">\n",
       "        arXiv:2506.14640\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14640\" href=\"/pdf/2506.14640\" id=\"pdf-2506.14640\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14640\" href=\"https://arxiv.org/html/2506.14640v1\" id=\"html-2506.14640\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14640\" href=\"/format/2506.14640\" id=\"oth-2506.14640\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Navigating the growing field of research on AI for software testing -- the taxonomy for AI-augmented software testing and an ontology-driven literature survey\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schieferdecker,+I+K\">Ina K. Schieferdecker</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          15 pages, 7 figures, 1 table, 2 listings (will be presented at FMICS 2025)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In industry, software testing is the primary method to verify and validate the functionality, performance, security, usability, and so on, of software-based systems. Test automation has gained increasing attention in industry over the last decade, following decades of intense research into test automation and model-based testing. However, designing, developing, maintaining and evolving test automation is a considerable effort. Meanwhile, AI's breakthroughs in many engineering fields are opening up new perspectives for software testing, for both manual and automated testing. This paper reviews recent research on AI augmentation in software test automation, from no automation to full automation. It also discusses new forms of testing made possible by AI. Based on this, the newly developed taxonomy, ai4st, is presented and used to classify recent research and identify open research questions.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item169\">[169]</a>\n",
       "<a href=\"/abs/2506.14641\" id=\"2506.14641\" title=\"Abstract\">\n",
       "        arXiv:2506.14641\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14641\" href=\"/pdf/2506.14641\" id=\"pdf-2506.14641\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14641\" href=\"https://arxiv.org/html/2506.14641v1\" id=\"html-2506.14641\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14641\" href=\"/format/2506.14641\" id=\"oth-2506.14641\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+X\">Xiang Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pan,+C\">Chengyan Pan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+M\">Minjun Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+D\">Deyang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+F\">Fangchao Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X\">Xinyu Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X\">Xiao Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yong Liu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          19 pages,22 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \\texttt{Qwen2.5-Max} and \\texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item170\">[170]</a>\n",
       "<a href=\"/abs/2506.14648\" id=\"2506.14648\" title=\"Abstract\">\n",
       "        arXiv:2506.14648\n",
       "      </a>\n",
       "          (cross-list from cs.RO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14648\" href=\"/pdf/2506.14648\" id=\"pdf-2506.14648\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14648\" href=\"https://arxiv.org/html/2506.14648v1\" id=\"html-2506.14648\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14648\" href=\"/format/2506.14648\" id=\"oth-2506.14648\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ni,+H\">Hexian Ni</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+T\">Tao Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+H\">Haoyuan Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cai,+Y\">Yinghao Cai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+S\">Shuo Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          8 pages, 8 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Preference-based Reinforcement Learning (PbRL) methods provide a solution to avoid reward engineering by learning reward models based on human preferences. However, poor feedback- and sample- efficiency still remain the problems that hinder the application of PbRL. In this paper, we present a novel efficient query selection and preference-guided exploration method, called SENIOR, which could select the meaningful and easy-to-comparison behavior segment pairs to improve human feedback-efficiency and accelerate policy learning with the designed preference-guided intrinsic rewards. Our key idea is twofold: (1) We designed a Motion-Distinction-based Selection scheme (MDS). It selects segment pairs with apparent motion and different directions through kernel density estimation of states, which is more task-related and easy for human preference labeling; (2) We proposed a novel preference-guided exploration method (PGE). It encourages the exploration towards the states with high preference and low visits and continuously guides the agent achieving the valuable samples. The synergy between the two mechanisms could significantly accelerate the progress of reward and policy learning. Our experiments show that SENIOR outperforms other five existing methods in both human feedback-efficiency and policy convergence speed on six complex robot manipulation tasks from simulation and four real-worlds.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item171\">[171]</a>\n",
       "<a href=\"/abs/2506.14652\" id=\"2506.14652\" title=\"Abstract\">\n",
       "        arXiv:2506.14652\n",
       "      </a>\n",
       "          (cross-list from cs.CY)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14652\" href=\"/pdf/2506.14652\" id=\"pdf-2506.14652\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14652\" href=\"https://arxiv.org/html/2506.14652v1\" id=\"html-2506.14652\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14652\" href=\"/format/2506.14652\" id=\"oth-2506.14652\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Olteanu,+A\">Alexandra Olteanu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Blodgett,+S+L\">Su Lin Blodgett</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Balayn,+A\">Agathe Balayn</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+A\">Angelina Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Diaz,+F\">Fernando Diaz</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Calmon,+F+d+P\">Flavio du Pin Calmon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mitchell,+M\">Margaret Mitchell</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ekstrand,+M\">Michael Ekstrand</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Binns,+R\">Reuben Binns</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Barocas,+S\">Solon Barocas</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          20 pages, 1 figure, 1 table\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In AI research and practice, rigor remains largely understood in terms of methodological rigor -- such as whether mathematical, statistical, or computational methods are correctly applied. We argue that this narrow conception of rigor has contributed to the concerns raised by the responsible AI community, including overblown claims about AI capabilities. Our position is that a broader conception of what rigorous AI research and practice should entail is needed. We believe such a conception -- in addition to a more expansive understanding of (1) methodological rigor -- should include aspects related to (2) what background knowledge informs what to work on (epistemic rigor); (3) how disciplinary, community, or personal norms, standards, or beliefs influence the work (normative rigor); (4) how clearly articulated the theoretical constructs under use are (conceptual rigor); (5) what is reported and how (reporting rigor); and (6) how well-supported the inferences from existing evidence are (interpretative rigor). In doing so, we also aim to provide useful language and a framework for much-needed dialogue about the AI community's work by researchers, policymakers, journalists, and other stakeholders.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item172\">[172]</a>\n",
       "<a href=\"/abs/2506.14665\" id=\"2506.14665\" title=\"Abstract\">\n",
       "        arXiv:2506.14665\n",
       "      </a>\n",
       "          (cross-list from physics.chem-ph)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14665\" href=\"/pdf/2506.14665\" id=\"pdf-2506.14665\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14665\" href=\"/format/2506.14665\" id=\"oth-2506.14665\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Accurate and scalable exchange-correlation with deep learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Luise,+G\">Giulia Luise</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Huang,+C\">Chin-Wei Huang</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Vogels,+T\">Thijs Vogels</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Kooi,+D+P\">Derk P. Kooi</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Ehlert,+S\">Sebastian Ehlert</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Lanius,+S\">Stephanie Lanius</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Giesbertz,+K+J+H\">Klaas J. H. Giesbertz</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Karton,+A\">Amir Karton</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Gunceler,+D\">Deniz Gunceler</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Stanley,+M\">Megan Stanley</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Bruinsma,+W+P\">Wessel P. Bruinsma</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Huang,+L\">Lin Huang</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Wei,+X\">Xinran Wei</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Torres,+J+G\">José Garrido Torres</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Katbashev,+A\">Abylay Katbashev</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=M%C3%A1t%C3%A9,+B\">Bálint Máté</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Kaba,+S\">Sékou-Oumar Kaba</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Sordillo,+R\">Roberto Sordillo</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Chen,+Y\">Yingrong Chen</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Williams-Young,+D+B\">David B. Williams-Young</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Bishop,+C+M\">Christopher M. Bishop</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Hermann,+J\">Jan Hermann</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=van+den+Berg,+R\">Rianne van den Berg</a>, <a href=\"https://arxiv.org/search/physics?searchtype=author&amp;query=Gori-Giorgi,+P\">Paola Gori-Giorgi</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Main: 13 pages plus references, 11 figures and tables. Supplementary information: 19 pages, 12 figures and tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Density Functional Theory (DFT) is the most widely used electronic structure method for predicting the properties of molecules and materials. Although DFT is, in principle, an exact reformulation of the Schrödinger equation, practical applications rely on approximations to the unknown exchange-correlation (XC) functional. Most existing XC functionals are constructed using a limited set of increasingly complex, hand-crafted features that improve accuracy at the expense of computational efficiency. Yet, no current approximation achieves the accuracy and generality for predictive modeling of laboratory experiments at chemical accuracy -- typically defined as errors below 1 kcal/mol. In this work, we present Skala, a modern deep learning-based XC functional that bypasses expensive hand-designed features by learning representations directly from data. Skala achieves chemical accuracy for atomization energies of small molecules while retaining the computational efficiency typical of semi-local DFT. This performance is enabled by training on an unprecedented volume of high-accuracy reference data generated using computationally intensive wavefunction-based methods. Notably, Skala systematically improves with additional training data covering diverse chemistry. By incorporating a modest amount of additional high-accuracy data tailored to chemistry beyond atomization energies, Skala achieves accuracy competitive with the best-performing hybrid functionals across general main group chemistry, at the cost of semi-local DFT. As the training dataset continues to expand, Skala is poised to further enhance the predictive power of first-principles simulations.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item173\">[173]</a>\n",
       "<a href=\"/abs/2506.14670\" id=\"2506.14670\" title=\"Abstract\">\n",
       "        arXiv:2506.14670\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14670\" href=\"/pdf/2506.14670\" id=\"pdf-2506.14670\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14670\" href=\"https://arxiv.org/html/2506.14670v1\" id=\"html-2506.14670\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14670\" href=\"/format/2506.14670\" id=\"oth-2506.14670\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+J\">Jina Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jang,+L\">Leeje Jang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang,+Y\">Yao-Yi Chiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+G\">Guanyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pasco,+M\">Michelle Pasco</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Traditionally, neighborhood studies have employed interviews, surveys, and manual image annotation guided by detailed protocols to identify environmental characteristics, including physical disorder, decay, street safety, and sociocultural symbols, and to examine their impact on developmental and health outcomes. While these methods yield rich insights, they are time-consuming and require intensive expert intervention. Recent technological advances, including vision-language models (VLMs), have begun to automate parts of this process; however, existing efforts are often ad hoc and lack adaptability across research designs and geographic contexts. In this demo paper, we present StreetLens, a human-centered, researcher-configurable workflow that embeds relevant social science expertise in a VLM for scalable neighborhood environmental assessments. StreetLens mimics the process of trained human coders by grounding the analysis in questions derived from established interview protocols, retrieving relevant street view imagery (SVI), and generating a wide spectrum of semantic annotations from objective features (e.g., the number of cars) to subjective perceptions (e.g., the sense of disorder in an image). By enabling researchers to define the VLM's role through domain-informed prompting, StreetLens places domain knowledge at the core of the analysis process. It also supports the integration of prior survey data to enhance robustness and expand the range of characteristics assessed across diverse settings. We provide a Google Colab notebook to make StreetLens accessible and extensible for researchers working with public or custom SVI datasets. StreetLens represents a shift toward flexible, agentic AI systems that work closely with researchers to accelerate and scale neighborhood studies.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item174\">[174]</a>\n",
       "<a href=\"/abs/2506.14677\" id=\"2506.14677\" title=\"Abstract\">\n",
       "        arXiv:2506.14677\n",
       "      </a>\n",
       "          (cross-list from cs.HC)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14677\" href=\"/pdf/2506.14677\" id=\"pdf-2506.14677\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14677\" href=\"https://arxiv.org/html/2506.14677v1\" id=\"html-2506.14677\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14677\" href=\"/format/2506.14677\" id=\"oth-2506.14677\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yingchao Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This paper presents a human-centered, real-time, user-adaptive speech-to-sign language animation system that integrates Transformer-based motion generation with a transparent, user-editable JSON intermediate layer. The framework overcomes key limitations in prior sign language technologies by enabling direct user inspection and modification of sign segments, thus enhancing naturalness, expressiveness, and user agency. Leveraging a streaming Conformer encoder and autoregressive Transformer-MDN decoder, the system synchronizes spoken input into upper-body and facial motion for 3D avatar rendering. Edits and user ratings feed into a human-in-the-loop optimization loop for continuous improvement. Experiments with 20 deaf signers and 5 interpreters show that the editable interface and participatory feedback significantly improve comprehension, naturalness, usability, and trust, while lowering cognitive load. With sub-20 ms per-frame inference on standard hardware, the system is ready for real-time communication and education. This work illustrates how technical and participatory innovation together enable accessible, explainable, and user-adaptive AI for sign language technology.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item175\">[175]</a>\n",
       "<a href=\"/abs/2506.14683\" id=\"2506.14683\" title=\"Abstract\">\n",
       "        arXiv:2506.14683\n",
       "      </a>\n",
       "          (cross-list from cs.SE)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14683\" href=\"/pdf/2506.14683\" id=\"pdf-2506.14683\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14683\" href=\"https://arxiv.org/html/2506.14683v1\" id=\"html-2506.14683\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14683\" href=\"/format/2506.14683\" id=\"oth-2506.14683\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Unified Software Engineering agent as AI Software Engineer\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Applis,+L\">Leonhard Applis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y\">Yuntong Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+S\">Shanchao Liang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+N\">Nan Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+L\">Lin Tan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roychoudhury,+A\">Abhik Roychoudhury</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Leonhard Applis and Yuntong Zhang contributed equally to this work\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The growth of Large Language Model (LLM) technology has raised expectations for automated coding. However, software engineering is more than coding and is concerned with activities including maintenance and evolution of a project. In this context, the concept of LLM agents has gained traction, which utilize LLMs as reasoning engines to invoke external tools autonomously. But is an LLM agent the same as an AI software engineer? In this paper, we seek to understand this question by developing a Unified Software Engineering agent or USEagent. Unlike existing work which builds specialized agents for specific software tasks such as testing, debugging, and repair, our goal is to build a unified agent which can orchestrate and handle multiple capabilities. This gives the agent the promise of handling complex scenarios in software development such as fixing an incomplete patch, adding new features, or taking over code written by others. We envision USEagent as the first draft of a future AI Software Engineer which can be a team member in future software development teams involving both AI and humans. To evaluate the efficacy of USEagent, we build a Unified Software Engineering bench (USEbench) comprising of myriad tasks such as coding, testing, and patching. USEbench is a judicious mixture of tasks from existing benchmarks such as SWE-bench, SWT-bench, and REPOCOD. In an evaluation on USEbench consisting of 1,271 repository-level software engineering tasks, USEagent shows improved efficacy compared to existing general agents such as OpenHands CodeActAgent. There exist gaps in the capabilities of USEagent for certain coding tasks, which provides hints on further developing the AI Software Engineer of the future.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item176\">[176]</a>\n",
       "<a href=\"/abs/2506.14684\" id=\"2506.14684\" title=\"Abstract\">\n",
       "        arXiv:2506.14684\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14684\" href=\"/pdf/2506.14684\" id=\"pdf-2506.14684\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14684\" href=\"https://arxiv.org/html/2506.14684v1\" id=\"html-2506.14684\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14684\" href=\"/format/2506.14684\" id=\"oth-2506.14684\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Refining music sample identification with a self-supervised graph neural network\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bhattacharjee,+A\">Aditya Bhattacharjee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Higgs,+I+M\">Ivan Meresman Higgs</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sandler,+M\">Mark Sandler</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Benetos,+E\">Emmanouil Benetos</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at International Conference for Music Information Retrieval (ISMIR) 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under \"real world\" (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge.\n",
       "<br/>In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%.\n",
       "<br/>To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item177\">[177]</a>\n",
       "<a href=\"/abs/2506.14723\" id=\"2506.14723\" title=\"Abstract\">\n",
       "        arXiv:2506.14723\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14723\" href=\"/pdf/2506.14723\" id=\"pdf-2506.14723\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14723\" href=\"https://arxiv.org/html/2506.14723v1\" id=\"html-2506.14723\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14723\" href=\"/format/2506.14723\" id=\"oth-2506.14723\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adaptive Accompaniment with ReaLchords\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yusong Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cooijmans,+T\">Tim Cooijmans</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kastner,+K\">Kyle Kastner</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roberts,+A\">Adam Roberts</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Simon,+I\">Ian Simon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Scarlatos,+A\">Alexander Scarlatos</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Donahue,+C\">Chris Donahue</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tarakajian,+C\">Cassie Tarakajian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Omidshafiei,+S\">Shayegan Omidshafiei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Courville,+A\">Aaron Courville</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Castro,+P+S\">Pablo Samuel Castro</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jaques,+N\">Natasha Jaques</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+C+A\">Cheng-Zhi Anna Huang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by ICML 2024\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Jamming requires coordination, anticipation, and collaborative creativity between musicians. Current generative models of music produce expressive output but are not able to generate in an \\emph{online} manner, meaning simultaneously with other musicians (human or otherwise). We propose ReaLchords, an online generative model for improvising chord accompaniment to user melody. We start with an online model pretrained by maximum likelihood, and use reinforcement learning to finetune the model for online use. The finetuning objective leverages both a novel reward model that provides feedback on both harmonic and temporal coherency between melody and chord, and a divergence term that implements a novel type of distillation from a teacher model that can see the future melody. Through quantitative experiments and listening tests, we demonstrate that the resulting model adapts well to unfamiliar input and produce fitting accompaniment. ReaLchords opens the door to live jamming, as well as simultaneous co-creation in other modalities.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item178\">[178]</a>\n",
       "<a href=\"/abs/2506.14727\" id=\"2506.14727\" title=\"Abstract\">\n",
       "        arXiv:2506.14727\n",
       "      </a>\n",
       "          (cross-list from cs.RO)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14727\" href=\"/pdf/2506.14727\" id=\"pdf-2506.14727\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.14727\" href=\"/format/2506.14727\" id=\"oth-2506.14727\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+H\">Huihan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shah,+R\">Rutav Shah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Shuijing Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pittenger,+J\">Jack Pittenger</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Seo,+M\">Mingyo Seo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+Y\">Yuchen Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bisk,+Y\">Yonatan Bisk</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADn-Mart%C3%ADn,+R\">Roberto Martín-Martín</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+Y\">Yuke Zhu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Assistive teleoperation, where control is shared between a human and a robot, enables efficient and intuitive human-robot collaboration in diverse and unstructured environments. A central challenge in real-world assistive teleoperation is for the robot to infer a wide range of human intentions from user control inputs and to assist users with correct actions. Existing methods are either confined to simple, predefined scenarios or restricted to task-specific data distributions at training, limiting their support for real-world assistance. We introduce Casper, an assistive teleoperation system that leverages commonsense knowledge embedded in pre-trained visual language models (VLMs) for real-time intent inference and flexible skill execution. Casper incorporates an open-world perception module for a generalized understanding of novel objects and scenes, a VLM-powered intent inference mechanism that leverages commonsense reasoning to interpret snippets of teleoperated user input, and a skill library that expands the scope of prior assistive teleoperation systems to support diverse, long-horizon mobile manipulation tasks. Extensive empirical evaluation, including human studies and system ablations, demonstrates that Casper improves task performance, reduces human cognitive load, and achieves higher user satisfaction than direct teleoperation and assistive teleoperation baselines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item179\">[179]</a>\n",
       "<a href=\"/abs/2506.14731\" id=\"2506.14731\" title=\"Abstract\">\n",
       "        arXiv:2506.14731\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14731\" href=\"/pdf/2506.14731\" id=\"pdf-2506.14731\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14731\" href=\"https://arxiv.org/html/2506.14731v1\" id=\"html-2506.14731\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14731\" href=\"/format/2506.14731\" id=\"oth-2506.14731\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ring+Team\">Ring Team</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+B\">Bin Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+C\">Cai Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+D\">Deng Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+D\">Ding Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jin,+D\">Dingnan Jin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+F\">Feng Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+H\">Hao Dai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luan,+H\">Hongzhi Luan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+J\">Jia Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J\">Jiaming Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J\">Jiewei Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mei,+J\">Jun Mei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+J\">Jun Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+J\">Junbo Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong,+J\">Junwu Xiong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+K\">Kaihong Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+K\">Kuan Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+L\">Lei Liang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+L\">Liang Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+L\">Liangcheng Fu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+L\">Longfei Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+Q\">Qiang Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+Q\">Qing Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wan,+Q\">Quan Wan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+S\">Shaomian Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S\">Shuaicheng Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+T\">Tongkai Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ren,+W\">Wang Ren</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yan,+X\">Xiaodong Yan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wan,+X\">Xiaopei Wan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+X\">Xiaoyun Feng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+X\">Xin Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+X\">Xinxing Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kong,+X\">Xinyu Kong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+X\">Xuemin Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yingting Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yongkang Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Z\">Zhankai Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhenduo Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+Z\">Zhenglei Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+Z\">Zhenyu Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhiqiang Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Zihao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wen,+Z\">Zujie Wen</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Technical Report\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item180\">[180]</a>\n",
       "<a href=\"/abs/2506.14750\" id=\"2506.14750\" title=\"Abstract\">\n",
       "        arXiv:2506.14750\n",
       "      </a>\n",
       "          (cross-list from cs.SD)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14750\" href=\"/pdf/2506.14750\" id=\"pdf-2506.14750\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14750\" href=\"https://arxiv.org/html/2506.14750v1\" id=\"html-2506.14750\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14750\" href=\"/format/2506.14750\" id=\"oth-2506.14750\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Exploring Speaker Diarization with Mixture of Experts\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+G\">Gaobin Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+M\">Maokui He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Niu,+S\">Shutong Niu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+R\">Ruoyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+H\">Hang Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+J\">Jun Du</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In this paper, we propose a novel neural speaker diarization system using memory-aware multi-speaker embedding with sequence-to-sequence architecture (NSD-MS2S), which integrates a memory-aware multi-speaker embedding module with a sequence-to-sequence architecture. The system leverages a memory module to enhance speaker embeddings and employs a Seq2Seq framework to efficiently map acoustic features to speaker labels. Additionally, we explore the application of mixture of experts in speaker diarization, and introduce a Shared and Soft Mixture of Experts (SS-MoE) module to further mitigate model bias and enhance performance. Incorporating SS-MoE leads to the extended model NSD-MS2S-SSMoE. Experiments on multiple complex acoustic datasets, including CHiME-6, DiPCo, Mixer 6 and DIHARD-III evaluation sets, demonstrate meaningful improvements in robustness and generalization. The proposed methods achieve state-of-the-art results, showcasing their effectiveness in challenging real-world scenarios.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item181\">[181]</a>\n",
       "<a href=\"/abs/2506.14761\" id=\"2506.14761\" title=\"Abstract\">\n",
       "        arXiv:2506.14761\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14761\" href=\"/pdf/2506.14761\" id=\"pdf-2506.14761\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14761\" href=\"https://arxiv.org/html/2506.14761v1\" id=\"html-2506.14761\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14761\" href=\"/format/2506.14761\" id=\"oth-2506.14761\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          From Bytes to Ideas: Language Modeling with Autoregressive U-Nets\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Videau,+M\">Mathurin Videau</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Idrissi,+B+Y\">Badr Youbi Idrissi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Leite,+A\">Alessandro Leite</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schoenauer,+M\">Marc Schoenauer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Teytaud,+O\">Olivier Teytaud</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lopez-Paz,+D\">David Lopez-Paz</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Tokenization imposes a fixed granularity on the input text, freezing how a language model operates on data and how far in the future it predicts. Byte Pair Encoding (BPE) and similar schemes split text once, build a static vocabulary, and leave the model stuck with that choice. We relax this rigidity by introducing an autoregressive U-Net that learns to embed its own tokens as it trains. The network reads raw bytes, pools them into words, then pairs of words, then up to 4 words, giving it a multi-scale view of the sequence. At deeper stages, the model must predict further into the future -- anticipating the next few words rather than the next byte -- so deeper stages focus on broader semantic patterns while earlier stages handle fine details. When carefully tuning and controlling pretraining compute, shallow hierarchies tie strong BPE baselines, and deeper hierarchies have a promising trend. Because tokenization now lives inside the model, the same system can handle character-level tasks and carry knowledge across low-resource languages.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item182\">[182]</a>\n",
       "<a href=\"/abs/2506.14767\" id=\"2506.14767\" title=\"Abstract\">\n",
       "        arXiv:2506.14767\n",
       "      </a>\n",
       "          (cross-list from cs.CL)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.14767\" href=\"/pdf/2506.14767\" id=\"pdf-2506.14767\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.14767\" href=\"https://arxiv.org/html/2506.14767v1\" id=\"html-2506.14767\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.14767\" href=\"/format/2506.14767\" id=\"oth-2506.14767\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Variational Framework for Improving Naturalness in Generative Spoken Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+L\">Li-Wei Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Higuchi,+T\">Takuya Higuchi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Aldeneh,+Z\">Zakaria Aldeneh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abdelaziz,+A+H\">Ahmed Hussen Abdelaziz</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rudnicky,+A\">Alexander Rudnicky</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          International Conference on Machine Learning (ICML) 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The success of large language models in text processing has inspired their adaptation to speech modeling. However, since speech is continuous and complex, it is often discretized for autoregressive modeling. Speech tokens derived from self-supervised models (known as semantic tokens) typically focus on the linguistic aspects of speech but neglect prosodic information. As a result, models trained on these tokens can generate speech with reduced naturalness. Existing approaches try to fix this by adding pitch features to the semantic tokens. However, pitch alone cannot fully represent the range of paralinguistic attributes, and selecting the right features requires careful hand-engineering. To overcome this, we propose an end-to-end variational approach that automatically learns to encode these continuous speech attributes to enhance the semantic tokens. Our approach eliminates the need for manual extraction and selection of paralinguistic features. Moreover, it produces preferred speech continuations according to human raters. Code, samples and models are available at <a class=\"link-external link-https\" href=\"https://github.com/b04901014/vae-gslm\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "</dl>\n",
       "<dl id=\"articles\">\n",
       "<h3>Replacement submissions (showing 109 of 109 entries)</h3>\n",
       "<dt>\n",
       "<a name=\"item183\">[183]</a>\n",
       "<a href=\"/abs/2310.07637\" id=\"2310.07637\" title=\"Abstract\">\n",
       "        arXiv:2310.07637\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2310.07637\" href=\"/pdf/2310.07637\" id=\"pdf-2310.07637\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2310.07637\" href=\"https://arxiv.org/html/2310.07637v5\" id=\"html-2310.07637\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2310.07637\" href=\"/format/2310.07637\" id=\"oth-2310.07637\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          OpsEval: A Comprehensive IT Operations Benchmark Suite for Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yuhe Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pei,+C\">Changhua Pei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+L\">Longlong Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+B\">Bohan Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+M\">Mingze Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhirui Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+Y\">Yongqian Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S\">Shenglin Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Kun Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+H\">Haiming Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+J\">Jianhui Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xie,+G\">Gaogang Xie</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wen,+X\">Xidao Wen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nie,+X\">Xiaohui Nie</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+M\">Minghua Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pei,+D\">Dan Pei</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Information Technology (IT) Operations (Ops), particularly Artificial Intelligence for IT Operations (AIOps), is the guarantee for maintaining the orderly and stable operation of existing information systems. According to Gartner's prediction, the use of AI technology for automated IT operations has become a new trend. Large language models (LLMs) that have exhibited remarkable capabilities in NLP-related tasks, are showing great potential in the field of AIOps, such as in aspects of root cause analysis of failures, generation of operations and maintenance scripts, and summarizing of alert information. Nevertheless, the performance of current LLMs in Ops tasks is yet to be determined. In this paper, we present OpsEval, a comprehensive task-oriented Ops benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in various crucial scenarios at different ability levels. The benchmark includes 7184 multi-choice questions and 1736 question-answering (QA) formats in English and Chinese. By conducting a comprehensive performance evaluation of the current leading large language models, we show how various LLM techniques can affect the performance of Ops, and discussed findings related to various topics, including model quantification, QA evaluation, and hallucination issues. To ensure the credibility of our evaluation, we invite dozens of domain experts to manually review our questions. At the same time, we have open-sourced 20% of the test QA to assist current researchers in preliminary evaluations of their OpsLLM models. The remaining 80% of the data, which is not disclosed, is used to eliminate the issue of the test set leakage. Additionally, we have constructed an online leaderboard that is updated in real-time and will continue to be updated, ensuring that any newly emerging LLMs will be evaluated promptly. Both our dataset and leaderboard have been made public.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item184\">[184]</a>\n",
       "<a href=\"/abs/2403.17328\" id=\"2403.17328\" title=\"Abstract\">\n",
       "        arXiv:2403.17328\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2403.17328\" href=\"/pdf/2403.17328\" id=\"pdf-2403.17328\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2403.17328\" href=\"https://arxiv.org/html/2403.17328v3\" id=\"html-2403.17328\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2403.17328\" href=\"/format/2403.17328\" id=\"oth-2403.17328\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Learning Traffic Signal Control via Genetic Programming\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liao,+X\">Xiao-Cheng Liao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mei,+Y\">Yi Mei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+M\">Mengjie Zhang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The control of traffic signals is crucial for improving transportation efficiency. Recently, learning-based methods, especially Deep Reinforcement Learning (DRL), garnered substantial success in the quest for more efficient traffic signal control strategies. However, the design of rewards in DRL highly demands domain knowledge to converge to an effective policy, and the final policy also presents difficulties in terms of explainability. In this work, a new learning-based method for signal control in complex intersections is proposed. In our approach, we design a concept of phase urgency for each signal phase. During signal transitions, the traffic light control strategy selects the next phase to be activated based on the phase urgency. We then proposed to represent the urgency function as an explainable tree structure. The urgency function can calculate the phase urgency for a specific phase based on the current road conditions. Genetic programming is adopted to perform gradient-free optimization of the urgency function. We test our algorithm on multiple public traffic signal control datasets. The experimental results indicate that the tree-shaped urgency function evolved by genetic programming outperforms the baselines, including a state-of-the-art method in the transportation field and a well-known DRL-based method. Our code is available online.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item185\">[185]</a>\n",
       "<a href=\"/abs/2405.20653\" id=\"2405.20653\" title=\"Abstract\">\n",
       "        arXiv:2405.20653\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2405.20653\" href=\"/pdf/2405.20653\" id=\"pdf-2405.20653\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2405.20653\" href=\"/format/2405.20653\" id=\"oth-2405.20653\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Mind the Inconspicuous: Revealing the Hidden Weakness in Aligned LLMs' Refusal Boundaries\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+J\">Jiahao Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+H\">Haozheng Luo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+J+Y\">Jerry Yao-Chieh Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+W\">Wenbo Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+H\">Han Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+X\">Xinyu Xing</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          published at USENIX Security 25\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advances in Large Language Models (LLMs) have led to impressive alignment where models learn to distinguish harmful from harmless queries through supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). In this paper, we reveal a subtle yet impactful weakness in these aligned models. We find that simply appending multiple end of sequence (eos) tokens can cause a phenomenon we call context segmentation, which effectively shifts both harmful and benign inputs closer to the refusal boundary in the hidden space.\n",
       "<br/>Building on this observation, we propose a straightforward method to BOOST jailbreak attacks by appending eos tokens. Our systematic evaluation shows that this strategy significantly increases the attack success rate across 8 representative jailbreak techniques and 16 open-source LLMs, ranging from 2B to 72B parameters. Moreover, we develop a novel probing mechanism for commercial APIs and discover that major providers such as OpenAI, Anthropic, and Qwen do not filter eos tokens, making them similarly vulnerable. These findings highlight a hidden yet critical blind spot in existing alignment and content filtering approaches.\n",
       "<br/>We call for heightened attention to eos tokens' unintended influence on model behaviors, particularly in production systems. Our work not only calls for an input-filtering based defense, but also points to new defenses that make refusal boundaries more robust and generalizable, as well as fundamental alignment techniques that can defend against context segmentation attacks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item186\">[186]</a>\n",
       "<a href=\"/abs/2406.14986\" id=\"2406.14986\" title=\"Abstract\">\n",
       "        arXiv:2406.14986\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2406.14986\" href=\"/pdf/2406.14986\" id=\"pdf-2406.14986\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2406.14986\" href=\"https://arxiv.org/html/2406.14986v3\" id=\"html-2406.14986\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2406.14986\" href=\"/format/2406.14986\" id=\"oth-2406.14986\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mondal,+M\">Manuel Mondal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dolamic,+L\">Ljiljana Dolamic</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bovet,+G\">Gérôme Bovet</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cudr%C3%A9-Mauroux,+P\">Philippe Cudré-Mauroux</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Audiffren,+J\">Julien Audiffren</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Multiple Choice Questions (MCQ) have become a commonly used approach to assess the capabilities of Large Language Models (LLMs), due to their ease of manipulation and evaluation. The experimental appraisals of the LLMs' Stated Answer (their answer to MCQ) have pointed to their apparent ability to perform probabilistic reasoning or to grasp uncertainty. In this work, we investigate whether these aptitudes are measurable outside tailored prompting and MCQ by reformulating these issues as direct text-completion - the fundamental computational unit of LLMs. We introduce Revealed Belief, an evaluation framework that evaluates LLMs on tasks requiring reasoning under uncertainty, which complements MCQ scoring by analyzing text-completion probability distributions. Our findings suggest that while LLMs frequently state the correct answer, their Revealed Belief shows that they often allocate probability mass inconsistently, exhibit systematic biases, and often fail to update their beliefs appropriately when presented with new evidence, leading to strong potential impacts on downstream tasks. These results suggest that common evaluation methods may only provide a partial picture and that more research is needed to assess the extent and nature of their capabilities.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item187\">[187]</a>\n",
       "<a href=\"/abs/2407.05674\" id=\"2407.05674\" title=\"Abstract\">\n",
       "        arXiv:2407.05674\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2407.05674\" href=\"/pdf/2407.05674\" id=\"pdf-2407.05674\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2407.05674\" href=\"https://arxiv.org/html/2407.05674v3\" id=\"html-2407.05674\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2407.05674\" href=\"/format/2407.05674\" id=\"oth-2407.05674\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Controllable and Reliable Knowledge-Intensive Task-Oriented Conversational Agents with Declarative Genie Worksheets\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Joshi,+H\">Harshit Joshi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Shicheng Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">James Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Weigle,+R\">Robert Weigle</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lam,+M+S\">Monica S. Lam</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at ACL 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Language Models can carry out human-like conversations in diverse settings, responding to user requests for tasks and knowledge. However, existing conversational agents implemented with LLMs often struggle with hallucination, following instructions with conditional logic, and integrating knowledge from different sources. These shortcomings compromise the agents' effectiveness, rendering them unsuitable for deployment. To address these challenges, we introduce Genie, a programmable framework for creating knowledge-intensive task-oriented conversational agents. Genie can handle involved interactions and answer complex queries. Unlike LLMs, it delivers reliable, grounded responses through advanced dialogue state management and supports controllable agent policies via its declarative specification -- Genie Worksheet. This is achieved through an algorithmic runtime system that implements the developer-supplied policy, limiting LLMs to (1) parse user input using a succinct conversational history, and (2) generate responses according to supplied context. Agents built with Genie outperform SOTA methods on complex logic dialogue datasets. We conducted a user study with 62 participants on three real-life applications: restaurant reservations with Yelp, as well as ticket submission and course enrollment for university students. Genie agents with GPT-4 Turbo outperformed the GPT-4 Turbo agents with function calling, improving goal completion rates from 21.8% to 82.8% across three real-world tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item188\">[188]</a>\n",
       "<a href=\"/abs/2408.05682\" id=\"2408.05682\" title=\"Abstract\">\n",
       "        arXiv:2408.05682\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2408.05682\" href=\"/pdf/2408.05682\" id=\"pdf-2408.05682\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2408.05682\" href=\"https://arxiv.org/html/2408.05682v2\" id=\"html-2408.05682\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2408.05682\" href=\"/format/2408.05682\" id=\"oth-2408.05682\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Decoupling Generation and Evaluation for Parallel Greedy Best-First Search(extended version)\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shimoda,+T\">Takumi Shimoda</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fukunaga,+A\">Alex Fukunaga</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          In Proceedings of SoCS 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In order to understand and control the search behavior of parallel search, recent work has proposed a class of constrained parallel greedy best-first search algorithms which only expands states that satisfy some <a class=\"link-external link-http\" href=\"http://constraint.However\" rel=\"external noopener nofollow\">this http URL</a>, enforcing such constraints can be costly, as threads must be waiting idly until a state that satisfies the expansion constraint is available. We propose an improvement to constrained parallel search which decouples state generation and state evaluation and significantly improves state evaluation rate, resulting in better search performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item189\">[189]</a>\n",
       "<a href=\"/abs/2408.08852\" id=\"2408.08852\" title=\"Abstract\">\n",
       "        arXiv:2408.08852\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2408.08852\" href=\"/pdf/2408.08852\" id=\"pdf-2408.08852\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2408.08852\" href=\"https://arxiv.org/html/2408.08852v4\" id=\"html-2408.08852\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2408.08852\" href=\"/format/2408.08852\" id=\"oth-2408.08852\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Unified Framework for Next-Gen Urban Forecasting via LLM-driven Dependency Retrieval and GeoTransformer\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jia,+Y\">Yuhao Jia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Z\">Zile Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yi,+S\">Shengao Yi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+Y\">Yifei Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+X\">Xiao Huang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Urban forecasting has increasingly benefited from high-dimensional spatial data through two primary approaches: graph-based methods that rely on predefined spatial structures, and region-based methods that focus on learning expressive urban representations. Although these methods have laid a strong foundation, they either rely heavily on structured spatial data, struggle to adapt to task-specific dependencies, or fail to integrate holistic urban context. Moreover, no existing framework systematically integrates these two paradigms and overcomes their respective limitations. To address this gap, we propose a novel, unified framework for high-dimensional urban forecasting, composed of three key components: (1) the Urban Region Representation Module that organizes latent embeddings and semantic descriptions for each region, (2) the Task-aware Dependency Retrieval module that selects relevant context regions based on natural language prompts, and (3) the Prediction Module, exemplified by our proposed GeoTransformer architecture, which adopts a novel geospatial attention mechanism to incorporate spatial proximity and information entropy as priors. Our framework is modular, supports diverse representation methods and forecasting models, and can operate even with minimal input. Quantitative experiments and qualitative analysis across six urban forecasting tasks demonstrate strong task generalization and validate the framework's effectiveness.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item190\">[190]</a>\n",
       "<a href=\"/abs/2410.05243\" id=\"2410.05243\" title=\"Abstract\">\n",
       "        arXiv:2410.05243\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2410.05243\" href=\"/pdf/2410.05243\" id=\"pdf-2410.05243\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2410.05243\" href=\"https://arxiv.org/html/2410.05243v3\" id=\"html-2410.05243\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2410.05243\" href=\"/format/2410.05243\" id=\"oth-2410.05243\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gou,+B\">Boyu Gou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+R\">Ruohan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+B\">Boyuan Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xie,+Y\">Yanan Xie</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chang,+C\">Cheng Chang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shu,+Y\">Yiheng Shu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+H\">Huan Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Su,+Y\">Yu Su</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted to ICLR 2025 (Oral). Project Homepage: <a class=\"link-external link-https\" href=\"https://osu-nlp-group.github.io/UGround/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robustness of their grounding capability. Current GUI agents predominantly utilize text-based representations such as HTML or accessibility trees, which, despite their utility, often introduce noise, incompleteness, and increased computational overhead. In this paper, we advocate a human-like embodiment for GUI agents that perceive the environment entirely visually and directly perform pixel-level operations on the GUI. The key is visual grounding models that can accurately map diverse referring expressions of GUI elements to their coordinates on the GUI across different platforms. We show that a simple recipe, which includes web-based synthetic data and slight adaptation of the LLaVA architecture, is surprisingly effective for training such visual grounding models. We collect the largest dataset for GUI visual grounding so far, containing 10M GUI elements and their referring expressions over 1.3M screenshots, and use it to train UGround, a strong universal visual grounding model for GUI agents. Empirical results on six benchmarks spanning three categories (grounding, offline agent, and online agent) show that 1) UGround substantially outperforms existing visual grounding models for GUI agents, by up to 20% absolute, and 2) agents with UGround outperform state-of-the-art agents, despite the fact that existing agents use additional text-based input while ours only uses visual perception. These results provide strong support for the feasibility and promises of GUI agents that navigate the digital world as humans do.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item191\">[191]</a>\n",
       "<a href=\"/abs/2412.03123\" id=\"2412.03123\" title=\"Abstract\">\n",
       "        arXiv:2412.03123\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2412.03123\" href=\"/pdf/2412.03123\" id=\"pdf-2412.03123\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2412.03123\" href=\"https://arxiv.org/html/2412.03123v2\" id=\"html-2412.03123\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2412.03123\" href=\"/format/2412.03123\" id=\"oth-2412.03123\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Robust Multi-bit Text Watermark with LLM-based Paraphrasers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+X\">Xiaojun Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jia,+J\">Jinghan Jia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+Y\">Yuanshun Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yang Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H\">Hang Li</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by ICML 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          We propose an imperceptible multi-bit text watermark embedded by paraphrasing with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave differently so that their paraphrasing difference reflected in the text semantics can be identified by a trained decoder. To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level. Then we use a text classifier as the decoder to decode each bit of the watermark. Through extensive experiments, we show that our watermarks can achieve over 99.99\\% detection AUC with small (1.1B) text paraphrasers while keeping the semantic information of the original sentence. More importantly, our pipeline is robust under word substitution and sentence paraphrasing perturbations and generalizes well to out-of-distributional data. We also show the stealthiness of our watermark with LLM-based evaluation. We open-source the code: <a class=\"link-external link-https\" href=\"https://github.com/xiaojunxu/multi-bit-text-watermark\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item192\">[192]</a>\n",
       "<a href=\"/abs/2502.07709\" id=\"2502.07709\" title=\"Abstract\">\n",
       "        arXiv:2502.07709\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.07709\" href=\"/pdf/2502.07709\" id=\"pdf-2502.07709\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.07709\" href=\"https://arxiv.org/html/2502.07709v3\" id=\"html-2502.07709\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.07709\" href=\"/format/2502.07709\" id=\"oth-2502.07709\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gaven,+L\">Loris Gaven</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Carta,+T\">Thomas Carta</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Romac,+C\">Clément Romac</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Colas,+C\">Cédric Colas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lamprier,+S\">Sylvain Lamprier</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sigaud,+O\">Olivier Sigaud</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Oudeyer,+P\">Pierre-Yves Oudeyer</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Open-ended learning agents must efficiently prioritize goals in vast possibility spaces, focusing on those that maximize learning progress (LP). When such autotelic exploration is achieved by LLM agents trained with online RL in high-dimensional and evolving goal spaces, a key challenge for LP prediction is modeling one's own competence, a form of metacognitive monitoring. Traditional approaches either require extensive sampling or rely on brittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive framework that lets LLM agents learn to predict their competence and LP online. By capturing semantic relationships between goals, MAGELLAN enables sample-efficient LP estimation and dynamic adaptation to evolving goal spaces through generalization. In an interactive learning environment, we show that MAGELLAN improves LP prediction efficiency and goal prioritization, being the only method allowing the agent to fully master a large and evolving goal space. These results demonstrate how augmenting LLM agents with a metacognitive ability for LP predictions can effectively scale curriculum learning to open-ended goal spaces.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item193\">[193]</a>\n",
       "<a href=\"/abs/2502.11422\" id=\"2502.11422\" title=\"Abstract\">\n",
       "        arXiv:2502.11422\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.11422\" href=\"/pdf/2502.11422\" id=\"pdf-2502.11422\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.11422\" href=\"https://arxiv.org/html/2502.11422v2\" id=\"html-2502.11422\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.11422\" href=\"/format/2502.11422\" id=\"oth-2502.11422\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mu,+C\">Chaoxu Mu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X\">Xufeng Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Hui Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          17 pages, 8 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Heuristics have achieved great success in solving combinatorial optimization problems (COPs). However, heuristics designed by humans require too much domain knowledge and testing time. Given the fact that Large Language Models (LLMs) possess strong capabilities to understand and generate content, and a knowledge base that covers various domains, which offer a novel way to automatically optimize heuristics. Therefore, we propose Planning of Heuristics (PoH), an optimization method that integrates the self-reflection of LLMs with the Monte Carlo Tree Search (MCTS), a well-known planning algorithm. PoH iteratively refines generated heuristics by evaluating their performance and providing improvement suggestions. Our method enables to iteratively evaluate the generated heuristics (states) and improve them based on the improvement suggestions (actions) and evaluation results (rewards), by effectively simulating future states to search for paths with higher rewards. In this paper, we apply PoH to solve the Traveling Salesman Problem (TSP) and the Flow Shop Scheduling Problem (FSSP). The experimental results show that PoH outperforms other hand-crafted heuristics and Automatic Heuristic Design (AHD) by other LLMs-based methods, and achieves the significant improvements and the state-of-the-art performance of our proposed method in automating heuristic optimization with LLMs to solve COPs.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item194\">[194]</a>\n",
       "<a href=\"/abs/2503.04429\" id=\"2503.04429\" title=\"Abstract\">\n",
       "        arXiv:2503.04429\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.04429\" href=\"/pdf/2503.04429\" id=\"pdf-2503.04429\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2503.04429\" href=\"/format/2503.04429\" id=\"oth-2503.04429\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Activation Space Interventions Can Be Transferred Between Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Oozeer,+N\">Narmeen Oozeer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nathawani,+D\">Dhruv Nathawani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Prakash,+N\">Nirmalendu Prakash</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lan,+M\">Michael Lan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Harrasse,+A\">Abir Harrasse</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abdullah,+A\">Amirali Abdullah</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          75 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          The study of representation universality in AI models reveals growing convergence across domains, modalities, and architectures. However, the practical applications of representation universality remain largely unexplored. We bridge this gap by demonstrating that safety interventions can be transferred between models through learned mappings of their shared activation spaces. We demonstrate this approach on two well-established AI safety tasks: backdoor removal and refusal of harmful prompts, showing successful transfer of steering vectors that alter the models' outputs in a predictable way. Additionally, we propose a new task, \\textit{corrupted capabilities}, where models are fine-tuned to embed knowledge tied to a backdoor. This tests their ability to separate useful skills from backdoors, reflecting real-world challenges. Extensive experiments across Llama, Qwen and Gemma model families show that our method enables using smaller models to efficiently align larger ones. Furthermore, we demonstrate that autoencoder mappings between base and fine-tuned models can serve as reliable ``lightweight safety switches\", allowing dynamic toggling between model behaviors.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item195\">[195]</a>\n",
       "<a href=\"/abs/2503.08679\" id=\"2503.08679\" title=\"Abstract\">\n",
       "        arXiv:2503.08679\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.08679\" href=\"/pdf/2503.08679\" id=\"pdf-2503.08679\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.08679\" href=\"https://arxiv.org/html/2503.08679v4\" id=\"html-2503.08679\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.08679\" href=\"/format/2503.08679\" id=\"oth-2503.08679\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Chain-of-Thought Reasoning In The Wild Is Not Always Faithful\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Arcuschin,+I\">Iván Arcuschin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Janiak,+J\">Jett Janiak</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Krzyzanowski,+R\">Robert Krzyzanowski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rajamanoharan,+S\">Senthooran Rajamanoharan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nanda,+N\">Neel Nanda</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Conmy,+A\">Arthur Conmy</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted to the Reasoning and Planning for LLMs Workshop (ICLR 25), 10 main paper pages, 39 appendix pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art AI capabilities. However, recent studies have shown that CoT reasoning is not always faithful when models face an explicit bias in their prompts, i.e., the CoT can give an incorrect picture of how models arrive at conclusions. We go further and show that unfaithful CoT can also occur on realistic prompts with no artificial bias. We find that when separately presented with the questions \"Is X bigger than Y?\" and \"Is Y bigger than X?\", models sometimes produce superficially coherent arguments to justify systematically answering Yes to both questions or No to both questions, despite such responses being logically contradictory. We show preliminary evidence that this is due to models' implicit biases towards Yes or No, thus labeling this unfaithfulness as Implicit Post-Hoc Rationalization. Our results reveal that several production models exhibit surprisingly high rates of post-hoc rationalization in our settings: GPT-4o-mini (13%) and Haiku 3.5 (7%). While frontier models are more faithful, especially thinking ones, none are entirely faithful: Gemini 2.5 Flash (2.17%), ChatGPT-4o (0.49%), DeepSeek R1 (0.37%), Gemini 2.5 Pro (0.14%), and Sonnet 3.7 with thinking (0.04%). We also investigate Unfaithful Illogical Shortcuts, where models use subtly illogical reasoning to try to make a speculative answer to hard maths problems seem rigorously proven. Our findings raise challenges for strategies for detecting undesired behavior in LLMs via the chain of thought.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item196\">[196]</a>\n",
       "<a href=\"/abs/2503.12917\" id=\"2503.12917\" title=\"Abstract\">\n",
       "        arXiv:2503.12917\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.12917\" href=\"/pdf/2503.12917\" id=\"pdf-2503.12917\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.12917\" href=\"https://arxiv.org/html/2503.12917v2\" id=\"html-2503.12917\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.12917\" href=\"/format/2503.12917\" id=\"oth-2503.12917\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Verification Learning: Make Unsupervised Neuro-Symbolic System Feasible\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jia,+L\">Lin-Han Jia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+W\">Wen-Chao Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shao,+J\">Jie-Jing Shao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+L\">Lan-Zhe Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yu-Feng Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          The current Neuro-Symbolic (NeSy) Learning paradigm suffers from an over-reliance on labeled data, so if we completely disregard labels, it leads to less symbol information, a larger solution space, and more shortcuts-issues that current Nesy systems cannot resolve. This paper introduces a novel learning paradigm, Verification Learning (VL), which addresses this challenge by transforming the label-based reasoning process in Nesy into a label-free verification process. VL achieves excellent learning results solely by relying on unlabeled data and a function that verifies whether the current predictions conform to the rules. We formalize this problem as a Constraint Optimization Problem (COP) and propose a Dynamic Combinatorial Sorting (DCS) algorithm that accelerates the solution by reducing verification attempts, effectively lowering computational costs and introduce a prior alignment method to address potential shortcuts. Our theoretical analysis points out which tasks in Nesy systems can be completed without labels and explains why rules can replace infinite labels for some tasks, while for others the rules have no effect. We validate the proposed framework through several fully unsupervised tasks including addition, sort, match, and chess, each showing significant performance and efficiency improvements.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item197\">[197]</a>\n",
       "<a href=\"/abs/2503.14973\" id=\"2503.14973\" title=\"Abstract\">\n",
       "        arXiv:2503.14973\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.14973\" href=\"/pdf/2503.14973\" id=\"pdf-2503.14973\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.14973\" href=\"https://arxiv.org/html/2503.14973v2\" id=\"html-2503.14973\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.14973\" href=\"/format/2503.14973\" id=\"oth-2503.14973\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Behaviour Discovery and Attribution for Explainable Reinforcement Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rishav,+R\">Rishav Rishav</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nath,+S\">Somjit Nath</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Michalski,+V\">Vincent Michalski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kahou,+S+E\">Samira Ebrahimi Kahou</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Building trust in reinforcement learning (RL) agents requires understanding why they make certain decisions, especially in high-stakes applications like robotics, healthcare, and finance. Existing explainability methods often focus on single states or entire trajectories, either providing only local, step-wise insights or attributing decisions to coarse, episodelevel summaries. Both approaches miss the recurring strategies and temporally extended patterns that actually drive agent behavior across multiple decisions. We address this gap by proposing a fully offline, reward-free framework for behavior discovery and segmentation, enabling the attribution of actions to meaningful and interpretable behavior segments that capture recurring patterns appearing across multiple trajectories. Our method identifies coherent behavior clusters from state-action sequences and attributes individual actions to these clusters for fine-grained, behavior-centric explanations. Evaluations on four diverse offline RL environments show that our approach discovers meaningful behaviors and outperforms trajectory-level baselines in fidelity, human preference, and cluster coherence. Our code is publicly available.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item198\">[198]</a>\n",
       "<a href=\"/abs/2504.21370\" id=\"2504.21370\" title=\"Abstract\">\n",
       "        arXiv:2504.21370\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2504.21370\" href=\"/pdf/2504.21370\" id=\"pdf-2504.21370\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2504.21370\" href=\"/format/2504.21370\" id=\"oth-2504.21370\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yi,+J\">Jingyang Yi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J\">Jiazheng Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S\">Sida Li</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          updated project website\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent models such as OpenAI o1 and DeepSeek-R1 have demonstrated strong performance on reasoning-intensive tasks by generating extended Chain-of-Thought (CoT) traces. While longer reasoning helps with thorough exploration of solution paths for complex problems, it also often leads to inefficient and redundant outputs--a phenomenon commonly described as overthinking. In this paper, we propose ShorterBetter, a simple yet effective reinforcement learning method that enables reasoning models to learn their own optimal CoT lengths without manual supervision. We define the Sample Optimal Length (SOL) as the length of the shortest correct response among multiple generations, which serves as a dynamic reward signal to guide the model toward efficient reasoning. Applied to DeepSeek-Distill-Qwen-1.5B/7B as base models, ShorterBetter achieves 50%-80% reduction in output lengths in both in-domain and out-of-domain reasoning tasks while maintaining accuracy. Our reasoning trace analysis shows that ShorterBetter refines the structure of the reasoning traces by reducing unnecessary repetition, excessive self-verification, and over-exploration of alternatives.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item199\">[199]</a>\n",
       "<a href=\"/abs/2505.07079\" id=\"2505.07079\" title=\"Abstract\">\n",
       "        arXiv:2505.07079\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.07079\" href=\"/pdf/2505.07079\" id=\"pdf-2505.07079\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.07079\" href=\"https://arxiv.org/html/2505.07079v2\" id=\"html-2505.07079\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.07079\" href=\"/format/2505.07079\" id=\"oth-2505.07079\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Arbitrarily Applicable Same/Opposite Relational Responding with NARS\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Johansson,+R\">Robert Johansson</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hammer,+P\">Patrick Hammer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lofthouse,+T\">Tony Lofthouse</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Same/opposite relational responding, a fundamental aspect of human symbolic cognition, allows the flexible generalization of stimulus relationships based on minimal experience. In this study, we demonstrate the emergence of \\textit{arbitrarily applicable} same/opposite relational responding within the Non-Axiomatic Reasoning System (NARS), a computational cognitive architecture designed for adaptive reasoning under uncertainty. Specifically, we extend NARS with an implementation of \\textit{acquired relations}, enabling the system to explicitly derive both symmetric (mutual entailment) and novel relational combinations (combinatorial entailment) from minimal explicit training in a contextually controlled matching-to-sample (MTS) procedure. Experimental results show that NARS rapidly internalizes explicitly trained relational rules and robustly demonstrates derived relational generalizations based on arbitrary contextual cues. Importantly, derived relational responding in critical test phases inherently combines both mutual and combinatorial entailments, such as deriving same-relations from multiple explicitly trained opposite-relations. Internal confidence metrics illustrate strong internalization of these relational principles, closely paralleling phenomena observed in human relational learning experiments. Our findings underscore the potential for integrating nuanced relational learning mechanisms inspired by learning psychology into artificial general intelligence frameworks, explicitly highlighting the arbitrary and context-sensitive relational capabilities modeled within NARS.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item200\">[200]</a>\n",
       "<a href=\"/abs/2505.13227\" id=\"2505.13227\" title=\"Abstract\">\n",
       "        arXiv:2505.13227\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.13227\" href=\"/pdf/2505.13227\" id=\"pdf-2505.13227\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.13227\" href=\"https://arxiv.org/html/2505.13227v2\" id=\"html-2505.13227\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.13227\" href=\"/format/2505.13227\" id=\"oth-2505.13227\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xie,+T\">Tianbao Xie</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Deng,+J\">Jiaqi Deng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+X\">Xiaochuan Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J\">Junlin Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+H\">Haoyuan Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jixuan Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+W\">Wenjing Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xinyuan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Y\">Yuhui Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Zekun Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Y\">Yiheng Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J\">Junli Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sahoo,+D\">Doyen Sahoo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+T\">Tao Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong,+C\">Caiming Xiong</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          49 pages, 13 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at <a class=\"link-external link-https\" href=\"https://osworld-grounding.github.io\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item201\">[201]</a>\n",
       "<a href=\"/abs/2505.19099\" id=\"2505.19099\" title=\"Abstract\">\n",
       "        arXiv:2505.19099\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.19099\" href=\"/pdf/2505.19099\" id=\"pdf-2505.19099\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.19099\" href=\"https://arxiv.org/html/2505.19099v4\" id=\"html-2505.19099\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.19099\" href=\"/format/2505.19099\" id=\"oth-2505.19099\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang,+K\">Kun Xiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H\">Heng Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+T+J\">Terry Jingchen Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+Y\">Yinya Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z\">Zirong Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qu,+P\">Peixin Qu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+J\">Jixi He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jiaqi Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+Y\">Yu-Jie Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+J\">Jianhua Han</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+H\">Hang Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H\">Hanhui Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sachan,+M\">Mrinmaya Sachan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+X\">Xiaodan Liang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          46 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Physics Education (physics.ed-ph); Popular Physics (physics.pop-ph)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item202\">[202]</a>\n",
       "<a href=\"/abs/2505.19165\" id=\"2505.19165\" title=\"Abstract\">\n",
       "        arXiv:2505.19165\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.19165\" href=\"/pdf/2505.19165\" id=\"pdf-2505.19165\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2505.19165\" href=\"/format/2505.19165\" id=\"oth-2505.19165\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          OrgAccess: A Benchmark for Role Based Access Control in Organization Scale LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sanyal,+D\">Debdeep Sanyal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Maharana,+U\">Umakanta Maharana</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha,+Y\">Yash Sinha</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+H+M\">Hong Ming Tan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Karande,+S\">Shirish Karande</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kankanhalli,+M\">Mohan Kankanhalli</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mandal,+M\">Murari Mandal</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          56 Pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Role-based access control (RBAC) and hierarchical structures are foundational to how information flows and decisions are made within virtually all organizations. As the potential of Large Language Models (LLMs) to serve as unified knowledge repositories and intelligent assistants in enterprise settings becomes increasingly apparent, a critical, yet under explored, challenge emerges: \\textit{can these models reliably understand and operate within the complex, often nuanced, constraints imposed by organizational hierarchies and associated permissions?} Evaluating this crucial capability is inherently difficult due to the proprietary and sensitive nature of real-world corporate data and access control policies. We introduce a synthetic yet representative \\textbf{OrgAccess} benchmark consisting of 40 distinct types of permissions commonly relevant across different organizational roles and levels. We further create three types of permissions: 40,000 easy (1 permission), 10,000 medium (3-permissions tuple), and 20,000 hard (5-permissions tuple) to test LLMs' ability to accurately assess these permissions and generate responses that strictly adhere to the specified hierarchical rules, particularly in scenarios involving users with overlapping or conflicting permissions. Our findings reveal that even state-of-the-art LLMs struggle significantly to maintain compliance with role-based structures, even with explicit instructions, with their performance degrades further when navigating interactions involving two or more conflicting permissions. Specifically, even \\textbf{GPT-4.1 only achieves an F1-Score of 0.27 on our hardest benchmark}. This demonstrates a critical limitation in LLMs' complex rule following and compositional reasoning capabilities beyond standard factual or STEM-based benchmarks, opening up a new paradigm for evaluating their fitness for practical, structured environments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item203\">[203]</a>\n",
       "<a href=\"/abs/2505.19676\" id=\"2505.19676\" title=\"Abstract\">\n",
       "        arXiv:2505.19676\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.19676\" href=\"/pdf/2505.19676\" id=\"pdf-2505.19676\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2505.19676\" href=\"/format/2505.19676\" id=\"oth-2505.19676\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=McGinness,+L\">Lachlan McGinness</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Baumgartner,+P\">Peter Baumgartner</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          There are errors in the evaluation of model faithfulness to reasoning strategies and completeness of reasoning. The analysis will be re-conducted correctly and a new corresponding pre-print will be released\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we develop methods for assessing LLM response accuracy and correct answer correlation.\n",
       "<br/>Our results show that progress in improving LLM reasoning abilities has stalled over the nine month period. By tracking completion tokens, we show that almost all improvement in reasoning ability since GPT-4 was released can be attributed to either hidden system prompts or the training of models to automatically use generic Chain of Thought prompting strategies. Among the ATP reasoning strategies tried, we found that current frontier LLMs are best able to follow the bottom-up (also known as forward-chaining) strategy. A low positive correlation was found between an LLM response containing correct reasoning and arriving at the correct conclusion.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item204\">[204]</a>\n",
       "<a href=\"/abs/2506.01391\" id=\"2506.01391\" title=\"Abstract\">\n",
       "        arXiv:2506.01391\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.01391\" href=\"/pdf/2506.01391\" id=\"pdf-2506.01391\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.01391\" href=\"/format/2506.01391\" id=\"oth-2506.01391\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhong Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yaxi Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+Y\">Yikun Fu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huo,+Y\">Yupeng Huo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+S\">Shenzhi Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yesai Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+H\">Han Si</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cong,+X\">Xin Cong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+H\">Haotian Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+Y\">Yankai Lin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xie,+J\">Jie Xie</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+W\">Wei Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+W\">Wang Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Y\">Yuanheng Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Su,+Z\">Zhou Su</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai,+Z\">Zhongwu Zhai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+X\">Xiaoming Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mei,+Y\">Yudong Mei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+J\">Jianming Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tian,+H\">Hongyan Tian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+C\">Chongyi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+C\">Chi Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+Y\">Yuan Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z\">Zhiyuan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+M\">Maosong Sun</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Updated results in Table 2 and Table 3; The project is available at <a class=\"link-external link-https\" href=\"https://github.com/OpenBMB/AgentCPM-GUI\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The recent progress of large language model agents has opened new possibilities for automating tasks through graphical user interfaces (GUIs), especially in mobile environments where intelligent interaction can greatly enhance usability. However, practical deployment of such agents remains constrained by several key challenges. Existing training data is often noisy and lack semantic diversity, which hinders the learning of precise grounding and planning. Models trained purely by imitation tend to overfit to seen interface patterns and fail to generalize in unfamiliar scenarios. Moreover, most prior work focuses on English interfaces while overlooks the growing diversity of non-English applications such as those in the Chinese mobile ecosystem. In this work, we present AgentCPM-GUI, an 8B-parameter GUI agent built for robust and efficient on-device GUI interaction. Our training pipeline includes grounding-aware pre-training to enhance perception, supervised fine-tuning on high-quality Chinese and English trajectories to imitate human-like actions, and reinforcement fine-tuning with GRPO to improve reasoning capability. We also introduce a compact action space that reduces output length and supports low-latency execution on mobile devices. AgentCPM-GUI achieves state-of-the-art performance on five public benchmarks and a new Chinese GUI benchmark called CAGUI, reaching $96.9\\%$ Type-Match and $91.3\\%$ Exact-Match. To facilitate reproducibility and further research, we publicly release all code, model checkpoint, and evaluation data.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item205\">[205]</a>\n",
       "<a href=\"/abs/2506.08026\" id=\"2506.08026\" title=\"Abstract\">\n",
       "        arXiv:2506.08026\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.08026\" href=\"/pdf/2506.08026\" id=\"pdf-2506.08026\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.08026\" href=\"https://arxiv.org/html/2506.08026v2\" id=\"html-2506.08026\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.08026\" href=\"/format/2506.08026\" id=\"oth-2506.08026\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xibai Wang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Computational Finance (q-fin.CP)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This paper proposes TIP-Search, a time-predictable inference scheduling framework for real-time market prediction under uncertain workloads. Motivated by the strict latency demands in high-frequency financial systems, TIP-Search dynamically selects a deep learning model from a heterogeneous pool, aiming to maximize predictive accuracy while satisfying per-task deadline constraints. Our approach profiles latency and generalization performance offline, then performs online task-aware selection without relying on explicit input domain labels. We evaluate TIP-Search on three real-world limit order book datasets (FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms static baselines with up to 8.5% improvement in accuracy and 100% deadline satisfaction. Our results highlight the effectiveness of TIP-Search in robust low-latency financial inference under uncertainty.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item206\">[206]</a>\n",
       "<a href=\"/abs/2506.09250\" id=\"2506.09250\" title=\"Abstract\">\n",
       "        arXiv:2506.09250\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.09250\" href=\"/pdf/2506.09250\" id=\"pdf-2506.09250\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.09250\" href=\"https://arxiv.org/html/2506.09250v2\" id=\"html-2506.09250\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.09250\" href=\"/format/2506.09250\" id=\"oth-2506.09250\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lawsen,+A\">A. Lawsen</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Comment on: <a class=\"link-https\" data-arxiv-id=\"2506.06941\" href=\"https://arxiv.org/abs/2506.06941\">arXiv:2506.06941</a> Latest version removes Claude as a co-author, in line with arXiv policies, it also corrects mistakes in sections 4 and 6 of the original submission, as well as several typographical errors\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Shojaee et al. (2025) report that Large Reasoning Models (LRMs) exhibit \"accuracy collapse\" on planning puzzles beyond certain complexity thresholds. We demonstrate that their findings primarily reflect experimental design limitations rather than fundamental reasoning failures. Our analysis reveals three critical issues: (1) Tower of Hanoi experiments risk exceeding model output token limits, with models explicitly acknowledging these constraints in their outputs; (2) The authors' automated evaluation framework fails to distinguish between reasoning failures and practical constraints, leading to misclassification of model capabilities; (3) Most concerningly, their River Crossing benchmarks include mathematically impossible instances for N &gt; 5 due to insufficient boat capacity, yet models are scored as failures for not solving these unsolvable problems. When we control for these experimental artifacts, by requesting generating functions instead of exhaustive move lists, preliminary experiments across multiple models indicate high accuracy on Tower of Hanoi instances previously reported as complete failures. These findings highlight the importance of careful experimental design when evaluating AI reasoning capabilities.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item207\">[207]</a>\n",
       "<a href=\"/abs/2506.10130\" id=\"2506.10130\" title=\"Abstract\">\n",
       "        arXiv:2506.10130\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.10130\" href=\"/pdf/2506.10130\" id=\"pdf-2506.10130\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.10130\" href=\"/format/2506.10130\" id=\"oth-2506.10130\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Floridi,+L\">Luciano Floridi</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          version 3\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          This article introduces a conjecture that formalises a fundamental trade-off between provable correctness and broad data-mapping capacity in Artificial Intelligence (AI) systems. When an AI system is engineered for deductively watertight guarantees (demonstrable certainty about the error-free nature of its outputs) -- as in classical symbolic AI -- its operational domain must be narrowly circumscribed and pre-structured. Conversely, a system that can input high-dimensional data to produce rich information outputs -- as in contemporary generative models -- necessarily relinquishes the possibility of zero-error performance, incurring an irreducible risk of errors or misclassification. By making this previously implicit trade-off explicit and open to rigorous verification, the conjecture significantly reframes both engineering ambitions and philosophical expectations for AI. After reviewing the historical motivations for this tension, the article states the conjecture in information-theoretic form and contextualises it within broader debates in epistemology, formal verification, and the philosophy of technology. It then offers an analysis of its implications and consequences, drawing on notions of underdetermination, prudent epistemic risk, and moral responsibility. The discussion clarifies how, if correct, the conjecture would help reshape evaluation standards, governance frameworks, and hybrid system design. The conclusion underscores the importance of eventually proving or refuting the inequality for the future of trustworthy AI.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item208\">[208]</a>\n",
       "<a href=\"/abs/2506.12376\" id=\"2506.12376\" title=\"Abstract\">\n",
       "        arXiv:2506.12376\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.12376\" href=\"/pdf/2506.12376\" id=\"pdf-2506.12376\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.12376\" href=\"https://arxiv.org/html/2506.12376v2\" id=\"html-2506.12376\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.12376\" href=\"/format/2506.12376\" id=\"oth-2506.12376\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hong,+Z\">Zhaochen Hong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H\">Haofei Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=You,+J\">Jiaxuan You</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at ACL 2025 Main Conference\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Evaluating consistency in large language models (LLMs) is crucial for ensuring reliability, particularly in complex, multi-step interactions between humans and LLMs. Traditional self-consistency methods often miss subtle semantic changes in natural language and functional shifts in code or equations, which can accumulate over multiple transformations. To address this, we propose ConsistencyChecker, a tree-based evaluation framework designed to measure consistency through sequences of reversible transformations, including machine translation tasks and AI-assisted programming tasks. In our framework, nodes represent distinct text states, while edges correspond to pairs of inverse operations. Dynamic and LLM-generated benchmarks ensure a fair assessment of the model's generalization ability and eliminate benchmark leakage. Consistency is quantified based on similarity across different depths of the transformation tree. Experiments on eight models from various families and sizes show that ConsistencyChecker can distinguish the performance of different models. Notably, our consistency scores-computed entirely without using WMT paired data-correlate strongly (r &gt; 0.7) with WMT 2024 auto-ranking, demonstrating the validity of our benchmark-free approach. Our implementation is available at: <a class=\"link-external link-https\" href=\"https://github.com/ulab-uiuc/consistencychecker\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item209\">[209]</a>\n",
       "<a href=\"/abs/2506.12508\" id=\"2506.12508\" title=\"Abstract\">\n",
       "        arXiv:2506.12508\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.12508\" href=\"/pdf/2506.12508\" id=\"pdf-2506.12508\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.12508\" href=\"https://arxiv.org/html/2506.12508v2\" id=\"html-2506.12508\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.12508\" href=\"/format/2506.12508\" id=\"oth-2506.12508\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+W\">Wentao Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+C\">Ce Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+Y\">Yilei Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+R\">Rui Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yang Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+Y\">Yahui Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=An,+B\">Bo An</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Artificial Intelligence (cs.AI)</span>\n",
       "</div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advances in agent systems based on large language models (LLMs) have demonstrated strong capabilities in solving complex tasks. However, most current methods lack mechanisms for coordinating specialized agents and have limited ability to generalize to new or diverse domains. We introduce \\projectname, a hierarchical multi-agent framework for general-purpose task solving that integrates high-level planning with modular agent collaboration. Inspired by the way a conductor orchestrates a symphony and guided by the principles of \\textit{extensibility}, \\textit{multimodality}, \\textit{modularity}, and \\textit{coordination}, \\projectname features a central planning agent that decomposes complex objectives and delegates sub-tasks to a team of specialized agents. Each sub-agent is equipped with general programming and analytical tools, as well as abilities to tackle a wide range of real-world specific tasks, including data analysis, file operations, web navigation, and interactive reasoning in dynamic multimodal environments. \\projectname supports flexible orchestration through explicit sub-goal formulation, inter-agent communication, and adaptive role allocation. We evaluate the framework on three widely used benchmark datasets covering various real-world tasks, searching web pages, reasoning over heterogeneous modalities, etc. Experimental results demonstrate that \\projectname consistently outperforms flat-agent and monolithic baselines in task success rate and adaptability. These findings highlight the effectiveness of hierarchical organization and role specialization in building scalable and general-purpose LLM-based agent systems.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item210\">[210]</a>\n",
       "<a href=\"/abs/2307.15220\" id=\"2307.15220\" title=\"Abstract\">\n",
       "        arXiv:2307.15220\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2307.15220\" href=\"/pdf/2307.15220\" id=\"pdf-2307.15220\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2307.15220\" href=\"https://arxiv.org/html/2307.15220v5\" id=\"html-2307.15220\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2307.15220\" href=\"/format/2307.15220\" id=\"oth-2307.15220\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+K\">Kun Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vinkle\">Vinkle Srivastav</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+T\">Tong Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lavanchy,+J+L\">Joel L. Lavanchy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Marescaux,+J\">Jacques Marescaux</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mascagni,+P\">Pietro Mascagni</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Navab,+N\">Nassir Navab</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Padoy,+N\">Nicolas Padoy</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by Medical Image Analysis (MedIA), 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advancements in surgical computer vision applications have been driven by vision-only models, which do not explicitly integrate the rich semantics of language into their design. These methods rely on manually annotated surgical videos to predict a fixed set of object categories, limiting their generalizability to unseen surgical procedures and downstream tasks. In this work, we put forward the idea that the surgical video lectures available through open surgical e-learning platforms can provide effective vision and language supervisory signals for multi-modal representation learning without relying on manual annotations. We address the surgery-specific linguistic challenges present in surgical video lectures by employing multiple complementary automatic speech recognition systems to generate text transcriptions. We then present a novel method, SurgVLP - Surgical Vision Language Pre-training, for multi-modal representation learning. Extensive experiments across diverse surgical procedures and tasks demonstrate that the multi-modal representations learned by SurgVLP exhibit strong transferability and adaptability in surgical video analysis. Furthermore, our zero-shot evaluations highlight SurgVLP's potential as a general-purpose foundation model for surgical workflow analysis, reducing the reliance on extensive manual annotations for downstream tasks, and facilitating adaptation methods such as few-shot learning to build a scalable and data-efficient solution for various downstream surgical applications. The [training code](<a class=\"link-external link-https\" href=\"https://github.com/CAMMA-public/PeskaVLP\" rel=\"external noopener nofollow\">this https URL</a>) and [weights](<a class=\"link-external link-https\" href=\"https://github.com/CAMMA-public/SurgVLP\" rel=\"external noopener nofollow\">this https URL</a>) are public.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item211\">[211]</a>\n",
       "<a href=\"/abs/2312.16490\" id=\"2312.16490\" title=\"Abstract\">\n",
       "        arXiv:2312.16490\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2312.16490\" href=\"/pdf/2312.16490\" id=\"pdf-2312.16490\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2312.16490\" href=\"https://arxiv.org/html/2312.16490v2\" id=\"html-2312.16490\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2312.16490\" href=\"/format/2312.16490\" id=\"oth-2312.16490\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Exploring news intent and its application: A theory-driven approach\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Zhengjia Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+D\">Danding Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sheng,+Q\">Qiang Sheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cao,+J\">Juan Cao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+S\">Siyuan Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+H\">Haonan Cheng</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted to Information Processing &amp; Management. DOI: <a class=\"link-external link-https\" href=\"https://doi.org/10.1016/j.ipm.2025.104229\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Understanding the intent behind information is crucial. However, news as a medium of public discourse still lacks a structured investigation of perceived news intent and its application. To advance this field, this paper reviews interdisciplinary studies on intentional action and introduces a conceptual deconstruction-based news intent understanding framework (NINT). This framework identifies the components of intent, facilitating a structured representation of news intent and its applications. Building upon NINT, we contribute a new intent perception dataset. Moreover, we investigate the potential of intent assistance on news-related tasks, such as significant improvement (+2.2% macF1) in the task of fake news detection. We hope that our findings will provide valuable insights into action-based intent cognition and computational social science.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item212\">[212]</a>\n",
       "<a href=\"/abs/2402.05804\" id=\"2402.05804\" title=\"Abstract\">\n",
       "        arXiv:2402.05804\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2402.05804\" href=\"/pdf/2402.05804\" id=\"pdf-2402.05804\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2402.05804\" href=\"https://arxiv.org/html/2402.05804v4\" id=\"html-2402.05804\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2402.05804\" href=\"/format/2402.05804\" id=\"oth-2402.05804\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          InkSight: Offline-to-Online Handwriting Conversion by Teaching Vision-Language Models to Read and Write\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mitrevski,+B\">Blagoj Mitrevski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rak,+A\">Arina Rak</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schnitzler,+J\">Julian Schnitzler</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Chengkun Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Maksai,+A\">Andrii Maksai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Berent,+J\">Jesse Berent</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Musat,+C\">Claudiu Musat</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by Transactions on Machine Learning Research\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in a vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice that is still favored by a vast majority. Our work InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore, it generalizes beyond its training domain into simple sketches. Our human evaluation reveals that 87% of the samples produced by our model on the challenging HierText dataset are considered as a valid tracing of the input image and 67% look like a pen trajectory traced by a human.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item213\">[213]</a>\n",
       "<a href=\"/abs/2405.15863\" id=\"2405.15863\" title=\"Abstract\">\n",
       "        arXiv:2405.15863\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2405.15863\" href=\"/pdf/2405.15863\" id=\"pdf-2405.15863\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2405.15863\" href=\"https://arxiv.org/html/2405.15863v4\" id=\"html-2405.15863\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2405.15863\" href=\"/format/2405.15863\" id=\"oth-2405.15863\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Quality-aware Masked Diffusion Transformer for Enhanced Music Generation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Chang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+R\">Ruoyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+L\">Lijuan Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+J\">Jun Du</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+Y\">Yixuan Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+Z\">Zilu Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhenrong Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+Y\">Yuan Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+J\">Jianqing Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+F\">Feng Ma</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          IJCAI\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Text-to-music (TTM) generation, which converts textual descriptions into audio, opens up innovative avenues for multimedia creation. Achieving high quality and diversity in this process demands extensive, high-quality data, which are often scarce in available datasets. Most open-source datasets frequently suffer from issues like low-quality waveforms and low text-audio consistency, hindering the advancement of music generation models. To address these challenges, we propose a novel quality-aware training paradigm for generating high-quality, high-musicality music from large-scale, quality-imbalanced datasets. Additionally, by leveraging unique properties in the latent space of musical signals, we adapt and implement a masked diffusion transformer (MDT) model for the TTM task, showcasing its capacity for quality control and enhanced musicality. Furthermore, we introduce a three-stage caption refinement approach to address low-quality captions' issue. Experiments show state-of-the-art (SOTA) performance on benchmark datasets including MusicCaps and the Song-Describer Dataset with both objective and subjective metrics. Demo audio samples are available at <a class=\"link-external link-https\" href=\"https://qa-mdt.github.io/\" rel=\"external noopener nofollow\">this https URL</a>, code and pretrained checkpoints are open-sourced at <a class=\"link-external link-https\" href=\"https://github.com/ivcylc/OpenMusic\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item214\">[214]</a>\n",
       "<a href=\"/abs/2406.11147\" id=\"2406.11147\" title=\"Abstract\">\n",
       "        arXiv:2406.11147\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2406.11147\" href=\"/pdf/2406.11147\" id=\"pdf-2406.11147\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2406.11147\" href=\"https://arxiv.org/html/2406.11147v3\" id=\"html-2406.11147\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2406.11147\" href=\"/format/2406.11147\" id=\"oth-2406.11147\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+X\">Xueying Du</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+G\">Geng Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Kaixin Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zou,+Y\">Yi Zou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yujia Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Deng,+W\">Wentai Deng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+J\">Jiayi Feng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+M\">Mingwei Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+B\">Bihuan Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+X\">Xin Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ma,+T\">Tao Ma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lou,+Y\">Yiling Lou</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Although LLMs have shown promising potential in vulnerability detection, this study reveals their limitations in distinguishing between vulnerable and similar-but-benign patched code (only 0.06 - 0.14 accuracy). It shows that LLMs struggle to capture the root causes of vulnerabilities during vulnerability detection. To address this challenge, we propose enhancing LLMs with multi-dimensional vulnerability knowledge distilled from historical vulnerabilities and fixes. We design a novel knowledge-level Retrieval-Augmented Generation framework Vul-RAG, which improves LLMs with an accuracy increase of 16% - 24% in identifying vulnerable and patched code. Additionally, vulnerability knowledge generated by Vul-RAG can further (1) serve as high-quality explanations to improve manual detection accuracy (from 60% to 77%), and (2) detect 10 previously-unknown bugs in the recent Linux kernel release with 6 assigned CVEs.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item215\">[215]</a>\n",
       "<a href=\"/abs/2406.11423\" id=\"2406.11423\" title=\"Abstract\">\n",
       "        arXiv:2406.11423\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2406.11423\" href=\"/pdf/2406.11423\" id=\"pdf-2406.11423\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2406.11423\" href=\"https://arxiv.org/html/2406.11423v4\" id=\"html-2406.11423\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2406.11423\" href=\"/format/2406.11423\" id=\"oth-2406.11423\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Bridging Social Media and Search Engines: Dredge Words and the Detection of Unreliable Domains\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Williams,+E+M\">Evan M. Williams</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Carragher,+P\">Peter Carragher</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Carley,+K+M\">Kathleen M. Carley</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Proactive content moderation requires platforms to rapidly and continuously evaluate the credibility of websites. Leveraging the direct and indirect paths users follow to unreliable websites, we develop a website credibility classification and discovery system that integrates both webgraph and large-scale social media contexts. We additionally introduce the concept of dredge words, terms or phrases for which unreliable domains rank highly on search engines, and provide the first exploration of their usage on social media. Our graph neural networks that combine webgraph and social media contexts generate to state-of-the-art results in website credibility classification and significantly improves the top-k identification of unreliable domains. Additionally, we release a novel dataset of dredge words, highlighting their strong connections to both social media and online commerce platforms.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item216\">[216]</a>\n",
       "<a href=\"/abs/2406.18379\" id=\"2406.18379\" title=\"Abstract\">\n",
       "        arXiv:2406.18379\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2406.18379\" href=\"/pdf/2406.18379\" id=\"pdf-2406.18379\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2406.18379\" href=\"https://arxiv.org/html/2406.18379v3\" id=\"html-2406.18379\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2406.18379\" href=\"/format/2406.18379\" id=\"oth-2406.18379\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+H\">Haolang Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+H\">Hongrui Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nan,+G\">Guoshun Nan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+J\">Jiaoyang Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+C\">Cheng Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jin,+W\">Weifei Jin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+S\">Songtao Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pan,+S\">Shengli Pan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tao,+X\">Xiaofeng Tao</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by IEEE Transactions on Information Forensics &amp; Security\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Binary malware summarization aims to automatically generate human-readable descriptions of malware behaviors from executable files, facilitating tasks like malware cracking and detection. Previous methods based on Large Language Models (LLMs) have shown great promise. However, they still face significant issues, including poor usability, inaccurate explanations,and incomplete summaries, primarily due to the obscure pseudocode structure and the lack of malware training summaries. Further, calling relationships between functions, which involve the rich interactions within a binary malware, remain largely underexplored. To this end, we propose MALSIGHT, a novel code summarization framework that can iteratively generate descriptions of binary malware by exploring malicious source code and benign pseudocode. Specifically, we construct the first malware summary dataset, MalS and MalP, using an LLM and manually refine this dataset with human effort. At the training stage, we tune our proposed MalT5, a novel LLM-based code model, on the MalS and benign pseudocode datasets. Then, at the test stage, we iteratively feed the pseudocode functions into MalT5 to obtain the summary. Such a procedure facilitates the understanding of pseudocode structure and captures the intricate interactions between functions, thereby benefiting summaries' usability, accuracy, and completeness. Additionally, we propose a novel evaluation benchmark, BLEURT-sum, to measure the quality of summaries. Experiments on three datasets show the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5, with only 0.77B parameters, delivers comparable performance to much larger Code-Llama.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item217\">[217]</a>\n",
       "<a href=\"/abs/2409.05144\" id=\"2409.05144\" title=\"Abstract\">\n",
       "        arXiv:2409.05144\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2409.05144\" href=\"/pdf/2409.05144\" id=\"pdf-2409.05144\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2409.05144\" href=\"https://arxiv.org/html/2409.05144v3\" id=\"html-2409.05144\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2409.05144\" href=\"/format/2409.05144\" id=\"oth-2409.05144\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors with Variance-bounded REINFORCE\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Zhao,+J\">Junjie Zhao</a>, <a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Zhang,+C\">Chengxi Zhang</a>, <a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Qin,+M\">Min Qin</a>, <a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Yang,+P\">Peng Yang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          16 pages, 9 figures\n",
       "        </div>\n",
       "<div class=\"list-journal-ref\"><span class=\"descriptor\">Journal-ref:</span>\n",
       "          IEEE Transactions on Signal Processing, 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Alpha factor mining aims to discover investment signals from the historical financial market data, which can be used to predict asset returns and gain excess profits. Powerful deep learning methods for alpha factor mining lack interpretability, making them unacceptable in the risk-sensitive real markets. Formulaic alpha factors are preferred for their interpretability, while the search space is complex and powerful explorative methods are urged. Recently, a promising framework is proposed for generating formulaic alpha factors using deep reinforcement learning, and quickly gained research focuses from both academia and industries. This paper first argues that the originally employed policy training method, i.e., Proximal Policy Optimization (PPO), faces several important issues in the context of alpha factors mining. Herein, a novel reinforcement learning algorithm based on the well-known REINFORCE algorithm is proposed. REINFORCE employs Monte Carlo sampling to estimate the policy gradient-yielding unbiased but high variance estimates. The minimal environmental variability inherent in the underlying state transition function, which adheres to the Dirac distribution, can help alleviate this high variance issue, making REINFORCE algorithm more appropriate than PPO. A new dedicated baseline is designed to theoretically reduce the commonly suffered high variance of REINFORCE. Moreover, the information ratio is introduced as a reward shaping mechanism to encourage the generation of steady alpha factors that can better adapt to changes in market volatility. Evaluations on real assets data indicate the proposed algorithm boosts correlation with returns by 3.83\\%, and a stronger ability to obtain excess returns compared to the latest alpha factors mining methods, which meets the theoretical results well.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item218\">[218]</a>\n",
       "<a href=\"/abs/2409.06997\" id=\"2409.06997\" title=\"Abstract\">\n",
       "        arXiv:2409.06997\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2409.06997\" href=\"/pdf/2409.06997\" id=\"pdf-2409.06997\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2409.06997\" href=\"https://arxiv.org/html/2409.06997v2\" id=\"html-2409.06997\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2409.06997\" href=\"/format/2409.06997\" id=\"oth-2409.06997\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          What is the Right Notion of Distance between Predict-then-Optimize Tasks?\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rodriguez-Diaz,+P\">Paula Rodriguez-Diaz</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kong,+L\">Lingkai Kong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Kai Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Alvarez-Melis,+D\">David Alvarez-Melis</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tambe,+M\">Milind Tambe</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Comparing datasets is a fundamental task in machine learning, essential for various learning paradigms-from evaluating train and test datasets for model generalization to using dataset similarity for detecting data drift. While traditional notions of dataset distances offer principled measures of similarity, their utility has largely been assessed through prediction error minimization. However, in Predict-then-Optimize (PtO) frameworks, where predictions serve as inputs for downstream optimization tasks, model performance is measured through decision regret rather than prediction error. In this work, we propose OTD$^3$ (Optimal Transport Decision-aware Dataset Distance), a novel dataset distance that incorporates downstream decisions in addition to features and labels. We show that traditional feature-label distances lack informativeness in PtO settings, while OTD$^3$ more effectively captures adaptation success. We also derive a PtO-specific adaptation bound based on this distance. Empirically, we show that our proposed distance accurately predicts model transferability across three different PtO tasks from the literature. The code is available at <a class=\"link-external link-https\" href=\"https://github.com/paularodr/OTD3\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item219\">[219]</a>\n",
       "<a href=\"/abs/2409.11316\" id=\"2409.11316\" title=\"Abstract\">\n",
       "        arXiv:2409.11316\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2409.11316\" href=\"/pdf/2409.11316\" id=\"pdf-2409.11316\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2409.11316\" href=\"https://arxiv.org/html/2409.11316v4\" id=\"html-2409.11316\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2409.11316\" href=\"/format/2409.11316\" id=\"oth-2409.11316\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via Transformer-Guided Prototyping\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fateh,+A\">Amirreza Fateh</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mohammadi,+M+R\">Mohammad Reza Mohammadi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Motlagh,+M+R+J\">Mohammad Reza Jahed Motlagh</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Few-shot Semantic Segmentation addresses the challenge of segmenting objects in query images with only a handful of annotated examples. However, many previous state-of-the-art methods either have to discard intricate local semantic features or suffer from high computational complexity. To address these challenges, we propose a new Few-shot Semantic Segmentation framework based on the Transformer architecture. Our approach introduces the spatial transformer decoder and the contextual mask generation module to improve the relational understanding between support and query images. Moreover, we introduce a multi scale decoder to refine the segmentation mask by incorporating features from different resolutions in a hierarchical manner. Additionally, our approach integrates global features from intermediate encoder stages to improve contextual understanding, while maintaining a lightweight structure to reduce complexity. This balance between performance and efficiency enables our method to achieve competitive results on benchmark datasets such as PASCAL-5^i and COCO-20^i in both 1-shot and 5-shot settings. Notably, our model with only 1.5 million parameters demonstrates competitive performance while overcoming limitations of existing methodologies. <a class=\"link-external link-https\" href=\"https://github.com/amirrezafateh/MSDNet\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item220\">[220]</a>\n",
       "<a href=\"/abs/2409.17655\" id=\"2409.17655\" title=\"Abstract\">\n",
       "        arXiv:2409.17655\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2409.17655\" href=\"/pdf/2409.17655\" id=\"pdf-2409.17655\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2409.17655\" href=\"https://arxiv.org/html/2409.17655v2\" id=\"html-2409.17655\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2409.17655\" href=\"/format/2409.17655\" id=\"oth-2409.17655\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+N\">Nan Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mao,+B\">Bo Mao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yongchang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+D\">Di Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+H\">Huaping Liu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          8 pages, 10 figures, 6 tables\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Current service robots suffer from limited natural language communication abilities, heavy reliance on predefined commands, ongoing human intervention, and, most notably, a lack of proactive collaboration awareness in human-populated environments. This results in narrow applicability and low utility. In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed for autonomous operation in realworld scenarios with high accuracy. AssistantX employs a multi-agent framework consisting of 4 specialized LLM agents, each dedicated to perception, planning, decision-making, and reflective review, facilitating advanced inference capabilities and comprehensive collaboration awareness, much like a human assistant by your side. We built a dataset of 210 real-world tasks to validate AssistantX, which includes instruction content and status information on whether relevant personnel are available. Extensive experiments were conducted in both text-based simulations and a real office environment over the course of a month and a half. Our experiments demonstrate the effectiveness of the proposed framework, showing that AssistantX can reactively respond to user instructions, actively adjust strategies to adapt to contingencies, and proactively seek assistance from humans to ensure successful task completion. More details and videos can be found at https://assistantx-agent. <a class=\"link-external link-http\" href=\"http://github.io/AssistantX/\" rel=\"external noopener nofollow\">this http URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item221\">[221]</a>\n",
       "<a href=\"/abs/2410.01444\" id=\"2410.01444\" title=\"Abstract\">\n",
       "        arXiv:2410.01444\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2410.01444\" href=\"/pdf/2410.01444\" id=\"pdf-2410.01444\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2410.01444\" href=\"https://arxiv.org/html/2410.01444v5\" id=\"html-2410.01444\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2410.01444\" href=\"/format/2410.01444\" id=\"oth-2410.01444\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Geometric Signatures of Compositionality Across a Language Model's Lifetime\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+J+H\">Jin Hwa Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiralerspong,+T\">Thomas Jiralerspong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+L\">Lei Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bengio,+Y\">Yoshua Bengio</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+E\">Emily Cheng</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Published at ACL 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          By virtue of linguistic compositionality, few syntactic rules and a finite lexicon can generate an unbounded number of sentences. That is, language, though seemingly high-dimensional, can be explained using relatively few degrees of freedom. An open question is whether contemporary language models (LMs) reflect the intrinsic simplicity of language that is enabled by compositionality. We take a geometric view of this problem by relating the degree of compositionality in a dataset to the intrinsic dimension (ID) of its representations under an LM, a measure of feature complexity. We find not only that the degree of dataset compositionality is reflected in representations' ID, but that the relationship between compositionality and geometric complexity arises due to learned linguistic features over training. Finally, our analyses reveal a striking contrast between nonlinear and linear dimensionality, showing they respectively encode semantic and superficial aspects of linguistic composition.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item222\">[222]</a>\n",
       "<a href=\"/abs/2410.21264\" id=\"2410.21264\" title=\"Abstract\">\n",
       "        arXiv:2410.21264\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2410.21264\" href=\"/pdf/2410.21264\" id=\"pdf-2410.21264\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2410.21264\" href=\"https://arxiv.org/html/2410.21264v2\" id=\"html-2410.21264\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2410.21264\" href=\"/format/2410.21264\" id=\"oth-2410.21264\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Hanyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Suri,+S\">Saksham Suri</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ren,+Y\">Yixuan Ren</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+H\">Hao Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shrivastava,+A\">Abhinav Shrivastava</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ICLR 2025. Project page: <a class=\"link-external link-https\" href=\"https://hywang66.github.io/larp/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present LARP, a novel video tokenizer designed to overcome limitations in current video tokenization methods for autoregressive (AR) generative models. Unlike traditional patchwise tokenizers that directly encode local visual patches into discrete tokens, LARP introduces a holistic tokenization scheme that gathers information from the visual content using a set of learned holistic queries. This design allows LARP to capture more global and semantic representations, rather than being limited to local patch-level information. Furthermore, it offers flexibility by supporting an arbitrary number of discrete tokens, enabling adaptive and efficient tokenization based on the specific requirements of the task. To align the discrete token space with downstream AR generation tasks, LARP integrates a lightweight AR transformer as a training-time prior model that predicts the next token on its discrete latent space. By incorporating the prior model during training, LARP learns a latent space that is not only optimized for video reconstruction but is also structured in a way that is more conducive to autoregressive generation. Moreover, this process defines a sequential order for the discrete tokens, progressively pushing them toward an optimal configuration during training, ensuring smoother and more accurate AR generation at inference time. Comprehensive experiments demonstrate LARP's strong performance, achieving state-of-the-art FVD on the UCF101 class-conditional video generation benchmark. LARP enhances the compatibility of AR models with videos and opens up the potential to build unified high-fidelity multimodal large language models (MLLMs).\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item223\">[223]</a>\n",
       "<a href=\"/abs/2412.04726\" id=\"2412.04726\" title=\"Abstract\">\n",
       "        arXiv:2412.04726\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2412.04726\" href=\"/pdf/2412.04726\" id=\"pdf-2412.04726\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2412.04726\" href=\"https://arxiv.org/html/2412.04726v3\" id=\"html-2412.04726\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2412.04726\" href=\"/format/2412.04726\" id=\"oth-2412.04726\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dipankar\">Dipankar Srirag</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Joshi,+A\">Aditya Joshi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Painter,+J\">Jordan Painter</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kanojia,+D\">Diptesh Kanojia</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Findings of ACL: ACL 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite large language models (LLMs) being known to exhibit bias against non-standard language varieties, there are no known labelled datasets for sentiment analysis of English. To address this gap, we introduce BESSTIE, a benchmark for sentiment and sarcasm classification for three varieties of English: Australian (en-AU), Indian (en-IN), and British (en-UK). We collect datasets for these language varieties using two methods: location-based for Google Places reviews, and topic-based filtering for Reddit comments. To assess whether the dataset accurately represents these varieties, we conduct two validation steps: (a) manual annotation of language varieties and (b) automatic language variety prediction. Native speakers of the language varieties manually annotate the datasets with sentiment and sarcasm labels. We perform an additional annotation exercise to validate the reliance of the annotated labels. Subsequently, we fine-tune nine LLMs (representing a range of encoder/decoder and mono/multilingual models) on these datasets, and evaluate their performance on the two tasks. Our results show that the models consistently perform better on inner-circle varieties (i.e., en-AU and en-UK), in comparison with en-IN, particularly for sarcasm classification. We also report challenges in cross-variety generalisation, highlighting the need for language variety-specific datasets such as ours. BESSTIE promises to be a useful evaluative benchmark for future research in equitable LLMs, specifically in terms of language varieties. The BESSTIE dataset is publicly available at: <a class=\"link-external link-https\" href=\"https://huggingface.co/\" rel=\"external noopener nofollow\">this https URL</a> datasets/unswnlporg/BESSTIE.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item224\">[224]</a>\n",
       "<a href=\"/abs/2412.11906\" id=\"2412.11906\" title=\"Abstract\">\n",
       "        arXiv:2412.11906\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2412.11906\" href=\"/pdf/2412.11906\" id=\"pdf-2412.11906\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2412.11906\" href=\"https://arxiv.org/html/2412.11906v2\" id=\"html-2412.11906\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2412.11906\" href=\"/format/2412.11906\" id=\"oth-2412.11906\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang,+K\">Kun Ouyang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yuanxin Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S\">Shicheng Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yi Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+H\">Hao Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Meng,+F\">Fandong Meng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+J\">Jie Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+X\">Xu Sun</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This is the camera-ready version for ACL 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Multimodal punchlines, which involve humor or sarcasm conveyed in image-caption pairs, are a popular way of communication on online multimedia platforms. With the rapid development of multimodal large language models (MLLMs), it is essential to assess their ability to effectively comprehend these punchlines. However, existing benchmarks on punchline comprehension suffer from three major limitations: 1) language shortcuts that allow models to solely rely on text, 2) lack of question diversity, and 3) narrow focus on a specific domain of multimodal content (e.g., cartoon). To address these limitations, we introduce a multimodal \\textbf{Punch}line comprehension \\textbf{Bench}mark, named \\textbf{PunchBench}, which is tailored for accurate and comprehensive evaluation of punchline comprehension. To enhance the evaluation accuracy, we generate synonymous and antonymous captions by modifying original captions, which mitigates the impact of shortcuts in the captions. To provide a comprehensive evaluation, PunchBench incorporates diverse question formats and image-captions from various domains. On this basis, we conduct extensive evaluations and reveal a significant gap between state-of-the-art MLLMs and humans in punchline comprehension. To improve punchline comprehension, we propose Simple-to-Complex Chain-of-Question (SC-CoQ) strategy, enabling the models to incrementally address complicated questions by first mastering simple ones. SC-CoQ effectively enhances the performance of various MLLMs on PunchBench, surpassing in-context learning and chain-of-thought.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item225\">[225]</a>\n",
       "<a href=\"/abs/2412.12221\" id=\"2412.12221\" title=\"Abstract\">\n",
       "        arXiv:2412.12221\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2412.12221\" href=\"/pdf/2412.12221\" id=\"pdf-2412.12221\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2412.12221\" href=\"https://arxiv.org/html/2412.12221v2\" id=\"html-2412.12221\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2412.12221\" href=\"/format/2412.12221\" id=\"oth-2412.12221\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Parallel Greedy Best-First Search with a Bound on Expansions Relative to Sequential Search\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shimoda,+T\">Takumi Shimoda</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fukunaga,+A\">Alex Fukunaga</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Parallelization of non-admissible search algorithms such as GBFS poses a challenge because straightforward parallelization can result in search behavior which significantly deviates from sequential search. Previous work proposed PUHF, a parallel search algorithm which is constrained to only expand states that can be expanded by some tie-breaking strategy for GBFS. We show that despite this constraint, the number of states expanded by PUHF is not bounded by a constant multiple of the number of states expanded by sequential GBFS with the worst-case tie-breaking strategy. We propose and experimentally evaluate One Bench At a Time (OBAT), a parallel greedy search which guarantees that the number of states expanded is within a constant factor of the number of states expanded by sequential GBFS with some tie-breaking policy.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item226\">[226]</a>\n",
       "<a href=\"/abs/2412.18047\" id=\"2412.18047\" title=\"Abstract\">\n",
       "        arXiv:2412.18047\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2412.18047\" href=\"/pdf/2412.18047\" id=\"pdf-2412.18047\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2412.18047\" href=\"https://arxiv.org/html/2412.18047v4\" id=\"html-2412.18047\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2412.18047\" href=\"/format/2412.18047\" id=\"oth-2412.18047\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Ting,+L+P\">Lo Pang-Yun Ting</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=%C5%9Eenol,+A\">Ali Şenol</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Wang,+H\">Huan-Yang Wang</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Lai,+H\">Hsu-Chao Lai</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Chuang,+K\">Kun-Ta Chuang</a>, <a href=\"https://arxiv.org/search/eess?searchtype=author&amp;query=Liu,+H\">Huan Liu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The advanced bidirectional EV charging and discharging technology, aimed at supporting grid stability and emergency operations, has driven a growing interest in workplace applications. It not only reduces electricity expenses but also enhances the resilience in handling practical matters, such as peak power limitation, fluctuating energy prices, and unpredictable EV departures. Considering these factors systematically can benefit energy efficiency in office buildings and for EV users simultaneously. To employ AI to address these issues, we propose HUCA, a novel real-time charging control for regulating energy demands for both the building and EVs. HUCA employs hierarchical actor-critic networks to dynamically reduce electricity costs in buildings, accounting for the needs of EV charging in the dynamic pricing scenario. To tackle the uncertain EV departures, we introduce a new critic augmentation to account for departure uncertainties in evaluating the charging decisions, while maintaining the robustness of the charging control. Experiments on real-world electricity datasets under both simulated certain and uncertain departure scenarios demonstrate that HUCA outperforms baselines in terms of total electricity costs while maintaining competitive performance in fulfilling EV charging requirements. A case study also manifests that HUCA effectively balances energy supply between the building and EVs based on real-time information, showcasing its potential as a key AI-driven solution for vehicle charging control.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item227\">[227]</a>\n",
       "<a href=\"/abs/2501.02621\" id=\"2501.02621\" title=\"Abstract\">\n",
       "        arXiv:2501.02621\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2501.02621\" href=\"/pdf/2501.02621\" id=\"pdf-2501.02621\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2501.02621\" href=\"/format/2501.02621\" id=\"oth-2501.02621\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yifei Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ye,+H\">Hengwei Ye</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S\">Shuhang Li</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          The result is no longer believeable. Teaching force issue exists in the infer time of LLM\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Decoding human activity from EEG signals has long been a popular research topic. While recent studies have increasingly shifted focus from single-subject to cross-subject analysis, few have explored the model's ability to perform zero-shot predictions on EEG signals from previously unseen subjects. This research aims to investigate whether deep learning methods can capture subject-independent semantic information inherent in human EEG signals. Such insights are crucial for Brain-Computer Interfaces (BCI) because, on one hand, they demonstrate the model's robustness against subject-specific temporal biases, and on the other, they significantly enhance the generalizability of downstream tasks. We employ Large Language Models (LLMs) as denoising agents to extract subject-independent semantic features from noisy EEG signals. Experimental results, including ablation studies, highlight the pivotal role of LLMs in decoding subject-independent semantic information from noisy EEG data. We hope our findings will contribute to advancing BCI research and assist both academia and industry in applying EEG signals to a broader range of applications.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item228\">[228]</a>\n",
       "<a href=\"/abs/2501.04227\" id=\"2501.04227\" title=\"Abstract\">\n",
       "        arXiv:2501.04227\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2501.04227\" href=\"/pdf/2501.04227\" id=\"pdf-2501.04227\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2501.04227\" href=\"/format/2501.04227\" id=\"oth-2501.04227\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Agent Laboratory: Using LLM Agents as Research Assistants\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schmidgall,+S\">Samuel Schmidgall</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Su,+Y\">Yusheng Su</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Ze Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+X\">Ximeng Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J\">Jialian Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+X\">Xiaodong Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J\">Jiang Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Moor,+M\">Michael Moor</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z\">Zicheng Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Barsoum,+E\">Emad Barsoum</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Historically, scientific discovery has been a lengthy and costly process, demanding substantial time and resources from initial conception to final results. To accelerate scientific discovery, reduce research costs, and improve research quality, we introduce Agent Laboratory, an autonomous LLM-based framework capable of completing the entire research process. This framework accepts a human-provided research idea and progresses through three stages--literature review, experimentation, and report writing to produce comprehensive research outputs, including a code repository and a research report, while enabling users to provide feedback and guidance at each stage. We deploy Agent Laboratory with various state-of-the-art LLMs and invite multiple researchers to assess its quality by participating in a survey, providing human feedback to guide the research process, and then evaluate the final paper. We found that: (1) Agent Laboratory driven by o1-preview generates the best research outcomes; (2) The generated machine learning code is able to achieve state-of-the-art performance compared to existing methods; (3) Human involvement, providing feedback at each stage, significantly improves the overall quality of research; (4) Agent Laboratory significantly reduces research expenses, achieving an 84% decrease compared to previous autonomous research methods. We hope Agent Laboratory enables researchers to allocate more effort toward creative ideation rather than low-level coding and writing, ultimately accelerating scientific discovery.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item229\">[229]</a>\n",
       "<a href=\"/abs/2501.05478\" id=\"2501.05478\" title=\"Abstract\">\n",
       "        arXiv:2501.05478\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2501.05478\" href=\"/pdf/2501.05478\" id=\"pdf-2501.05478\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2501.05478\" href=\"https://arxiv.org/html/2501.05478v2\" id=\"html-2501.05478\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2501.05478\" href=\"/format/2501.05478\" id=\"oth-2501.05478\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Language and Planning in Robotic Navigation: A Multilingual Evaluation of State-of-the-Art Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mansour,+M\">Malak Mansour</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Aly,+A\">Ahmed Aly</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tharwat,+B\">Bahey Tharwat</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hashmi,+S\">Sarim Hashmi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=An,+D\">Dong An</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Reid,+I\">Ian Reid</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This work has been accepted for presentation at LM4Plan@AAAI'25. For more details, please check: <a class=\"link-external link-https\" href=\"https://llmforplanning.github.io/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large Language Models (LLMs) such as GPT-4, trained on huge amount of datasets spanning multiple domains, exhibit significant reasoning, understanding, and planning capabilities across various tasks. This study presents the first-ever work in Arabic language integration within the Vision-and-Language Navigation (VLN) domain in robotics, an area that has been notably underexplored in existing research. We perform a comprehensive evaluation of state-of-the-art multi-lingual Small Language Models (SLMs), including GPT-4o mini, Llama 3 8B, and Phi-3 medium 14B, alongside the Arabic-centric LLM, Jais. Our approach utilizes the NavGPT framework, a pure LLM-based instruction-following navigation agent, to assess the impact of language on navigation reasoning through zero-shot sequential action prediction using the R2R dataset. Through comprehensive experiments, we demonstrate that our framework is capable of high-level planning for navigation tasks when provided with instructions in both English and Arabic. However, certain models struggled with reasoning and planning in the Arabic language due to inherent limitations in their capabilities, sub-optimal performance, and parsing issues. These findings highlight the importance of enhancing planning and reasoning capabilities in language models for effective navigation, emphasizing this as a key area for further development while also unlocking the potential of Arabic-language models for impactful real-world applications.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item230\">[230]</a>\n",
       "<a href=\"/abs/2501.10970\" id=\"2501.10970\" title=\"Abstract\">\n",
       "        arXiv:2501.10970\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2501.10970\" href=\"/pdf/2501.10970\" id=\"pdf-2501.10970\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2501.10970\" href=\"/format/2501.10970\" id=\"oth-2501.10970\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Calderon,+N\">Nitay Calderon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Reichart,+R\">Roi Reichart</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dror,+R\">Rotem Dror</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The \"LLM-as-an-annotator\" and \"LLM-as-a-judge\" paradigms employ Large Language Models (LLMs) as annotators, judges, and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure, the Alternative Annotator Test (alt-test), that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM annotators and judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming the open-source LLMs we examine, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item231\">[231]</a>\n",
       "<a href=\"/abs/2501.18045\" id=\"2501.18045\" title=\"Abstract\">\n",
       "        arXiv:2501.18045\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2501.18045\" href=\"/pdf/2501.18045\" id=\"pdf-2501.18045\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2501.18045\" href=\"https://arxiv.org/html/2501.18045v3\" id=\"html-2501.18045\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2501.18045\" href=\"/format/2501.18045\" id=\"oth-2501.18045\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          From tools to thieves: Measuring and understanding public perceptions of AI through crowdsourced metaphors\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+M\">Myra Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+A+Y\">Angela Y. Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rapuano,+K\">Kristina Rapuano</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Niederhoffer,+K\">Kate Niederhoffer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liebscher,+A\">Alex Liebscher</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hancock,+J\">Jeffrey Hancock</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          To appear at the ACM Conference on Fairness, Accountability, and Transparency 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          How has the public responded to the increasing prevalence of artificial intelligence (AI)-based technologies? We investigate public perceptions of AI by collecting over 12,000 responses over 12 months from a nationally representative U.S. sample. Participants provided open-ended metaphors reflecting their mental models of AI, a methodology that overcomes the limitations of traditional self-reported measures by capturing more nuance. Using a mixed-methods approach combining quantitative clustering and qualitative coding, we identify 20 dominant metaphors shaping public understanding of AI. To analyze these metaphors systematically, we present a scalable framework integrating language modeling (LM)-based techniques to measure key dimensions of public perception: anthropomorphism (attribution of human-like qualities), warmth, and competence. We find that Americans generally view AI as warm and competent, and that over the past year, perceptions of AI's human-likeness and warmth have significantly increased ($+34\\%, r = 0.80, p &lt; 0.01; +41\\%, r = 0.62, p &lt; 0.05$). These implicit perceptions, along with the identified dominant metaphors, strongly predict trust in and willingness to adopt AI ($r^2 = 0.21, 0.18, p &lt; 0.001$). Moreover, we uncover systematic demographic differences in metaphors and implicit perceptions, such as the higher propensity of women, older individuals, and people of color to anthropomorphize AI, which shed light on demographic disparities in trust and adoption. In addition to our dataset and framework for tracking evolving public attitudes, we provide actionable insights on using metaphors for inclusive and responsible AI development.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item232\">[232]</a>\n",
       "<a href=\"/abs/2502.05017\" id=\"2502.05017\" title=\"Abstract\">\n",
       "        arXiv:2502.05017\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.05017\" href=\"/pdf/2502.05017\" id=\"pdf-2502.05017\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.05017\" href=\"https://arxiv.org/html/2502.05017v2\" id=\"html-2502.05017\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.05017\" href=\"/format/2502.05017\" id=\"oth-2502.05017\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J+C\">Joshua C. Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bachmann,+F\">Fynn Bachmann</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          In Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25), 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Democratic processes increasingly aim to integrate large-scale voting with face-to-face deliberation, addressing the challenge of reconciling individual preferences with collective decision-making. This work introduces new methods that use algorithms and computational tools to bridge online voting with face-to-face deliberation, tested in two real-world scenarios: Kultur Komitee 2024 (KK24) and vTaiwan. These case studies highlight the practical applications and impacts of the proposed methods.\n",
       "<br/>We present three key contributions: (1) Preference-based Clustering for Deliberation (PCD), which enables both in-depth and broad discussions in deliberative settings by computing homogeneous and heterogeneous group compositions with balanced and adjustable group sizes; (2) Human-in-the-loop MES, a practical method that enhances the Method of Equal Shares (MES) algorithm with real-time digital feedback. This builds algorithmic trust by giving participants full control over how much decision-making is delegated to the voting aggregation algorithm as compared to deliberation; and (3) the ReadTheRoom deliberation method, which uses opinion space mapping to identify agreement and divergence, along with spectrum-based preference visualisation to track opinion shifts during deliberation. This approach enhances transparency by clarifying collective sentiment and fosters collaboration by encouraging participants to engage constructively with differing perspectives. By introducing these actionable frameworks, this research extends in-person deliberation with scalable digital methods that address the complexities of modern decision-making in participatory processes.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item233\">[233]</a>\n",
       "<a href=\"/abs/2502.07250\" id=\"2502.07250\" title=\"Abstract\">\n",
       "        arXiv:2502.07250\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.07250\" href=\"/pdf/2502.07250\" id=\"pdf-2502.07250\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.07250\" href=\"https://arxiv.org/html/2502.07250v2\" id=\"html-2502.07250\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.07250\" href=\"/format/2502.07250\" id=\"oth-2502.07250\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          NAROCE: A Neural Algorithmic Reasoner Framework for Online Complex Event Detection\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+L\">Liying Han</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dong,+G\">Gaofeng Dong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ouyang,+X\">Xiaomin Ouyang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan,+L\">Lance Kaplan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cerutti,+F\">Federico Cerutti</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mani\">Mani Srivastava</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Modern machine learning models excel at detecting individual actions, objects, or scene attributes from short, local observations. However, many real-world tasks, such as in smart cities and healthcare, require reasoning over complex events (CEs): (spatio)temporal, rule-governed patterns of short-term atomic events (AEs) that reflect high-level understanding and critical changes in the environment. These CEs are difficult to detect online: they are often rare, require long-range reasoning over noisy sensor data, must generalize rules beyond fixed-length traces, and suffer from limited real-world datasets due to the high annotation burden. We propose NAROCE, a Neural Algorithmic Reasoning framework for Online CE detection that separates the task into two stages: (i) learning CE rules from large-scale, low-cost pseudo AE concept traces generated by simulators or LLMs, and (ii) training an adapter to map real sensor data into the learned reasoning space using fewer labeled sensor samples. Experiments show that NAROCE outperforms the strongest baseline in accuracy, generalization to longer, unseen sequences, and data efficiency, achieving comparable performance with less than half the labeled data. These results suggest that decoupling CE rule learning from raw sensor inputs improves both data efficiency and robustness.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item234\">[234]</a>\n",
       "<a href=\"/abs/2502.11425\" id=\"2502.11425\" title=\"Abstract\">\n",
       "        arXiv:2502.11425\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.11425\" href=\"/pdf/2502.11425\" id=\"pdf-2502.11425\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2502.11425\" href=\"/format/2502.11425\" id=\"oth-2502.11425\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+J\">Jongho Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hwang,+S\">Seung-won Hwang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ACL 2025 main (short)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite the advanced capabilities of large language models (LLMs), their temporal reasoning ability remains underdeveloped. Prior works have highlighted this limitation, particularly in maintaining temporal consistency when understanding events. For example, models often confuse mutually exclusive temporal relations like ``before'' and ``after'' between events and make inconsistent predictions. In this work, we tackle the issue of temporal inconsistency in LLMs by proposing a novel counterfactual prompting approach. Our method generates counterfactual questions and enforces collective constraints, enhancing the model's consistency. We evaluate our method on multiple datasets, demonstrating significant improvements in event ordering for explicit and implicit events and temporal commonsense understanding by effectively addressing temporal inconsistencies.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item235\">[235]</a>\n",
       "<a href=\"/abs/2502.13174\" id=\"2502.13174\" title=\"Abstract\">\n",
       "        arXiv:2502.13174\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.13174\" href=\"/pdf/2502.13174\" id=\"pdf-2502.13174\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.13174\" href=\"https://arxiv.org/html/2502.13174v2\" id=\"html-2502.13174\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.13174\" href=\"/format/2502.13174\" id=\"oth-2502.13174\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Diverse Topology Optimization using Modulated Neural Fields\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Radler,+A\">Andreas Radler</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Volkmann,+E\">Eric Volkmann</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Brandstetter,+J\">Johannes Brandstetter</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Berzins,+A\">Arturs Berzins</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          22 pages, 14 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Topology optimization (TO) is a family of computational methods that derive near-optimal geometries from formal problem descriptions. Despite their success, established TO methods are limited to generating single solutions, restricting the exploration of alternative designs. To address this limitation, we introduce Topology Optimization using Modulated Neural Fields (TOM) - a data-free method that trains a neural network to generate structurally compliant shapes and explores diverse solutions through an explicit diversity constraint. The network is trained with a solver-in-the-loop, optimizing the material distribution in each iteration. The trained model produces diverse shapes that closely adhere to the design requirements. We validate TOM on 2D and 3D TO problems. Our results show that TOM generates more diverse solutions than any previous method, all while maintaining near-optimality and without relying on a dataset. These findings open new avenues for engineering and design, offering enhanced flexibility and innovation in structural optimization.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item236\">[236]</a>\n",
       "<a href=\"/abs/2502.13497\" id=\"2502.13497\" title=\"Abstract\">\n",
       "        arXiv:2502.13497\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.13497\" href=\"/pdf/2502.13497\" id=\"pdf-2502.13497\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.13497\" href=\"https://arxiv.org/html/2502.13497v3\" id=\"html-2502.13497\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.13497\" href=\"/format/2502.13497\" id=\"oth-2502.13497\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Towards Geo-Culturally Grounded LLM Generations\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lertvittayakumjorn,+P\">Piyawat Lertvittayakumjorn</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kinney,+D\">David Kinney</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Prabhakaran,+V\">Vinodkumar Prabhakaran</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Martin,+D\">Donald Martin Jr.</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dev,+S\">Sunipa Dev</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          ACL 2025 (main conference)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Generative large language models (LLMs) have demonstrated gaps in diverse cultural awareness across the globe. We investigate the effect of retrieval augmented generation and search-grounding techniques on LLMs' ability to display familiarity with various national cultures. Specifically, we compare the performance of standard LLMs, LLMs augmented with retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs augmented with retrievals from a web search (i.e., search grounding) on multiple cultural awareness benchmarks. We find that search grounding significantly improves the LLM performance on multiple-choice benchmarks that test propositional knowledge (e.g., cultural norms, artifacts, and institutions), while KB grounding's effectiveness is limited by inadequate knowledge base coverage and a suboptimal retriever. However, search grounding also increases the risk of stereotypical judgments by language models and fails to improve evaluators' judgments of cultural familiarity in a human evaluation with adequate statistical power. These results highlight the distinction between propositional cultural knowledge and open-ended cultural fluency when it comes to evaluating LLMs' cultural awareness.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item237\">[237]</a>\n",
       "<a href=\"/abs/2502.14445\" id=\"2502.14445\" title=\"Abstract\">\n",
       "        arXiv:2502.14445\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.14445\" href=\"/pdf/2502.14445\" id=\"pdf-2502.14445\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.14445\" href=\"https://arxiv.org/html/2502.14445v2\" id=\"html-2502.14445\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.14445\" href=\"/format/2502.14445\" id=\"oth-2502.14445\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          PredictaBoard: Benchmarking LLM Score Predictability\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pacchiardi,+L\">Lorenzo Pacchiardi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Voudouris,+K\">Konstantinos Voudouris</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Slater,+B\">Ben Slater</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Plumed,+F\">Fernando Martínez-Plumed</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hern%C3%A1ndez-Orallo,+J\">José Hernández-Orallo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+L\">Lexin Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schellaert,+W\">Wout Schellaert</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted at ACL Findings 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Despite possessing impressive skills, Large Language Models (LLMs) often fail unpredictably, demonstrating inconsistent success in even basic common sense reasoning tasks. This unpredictability poses a significant challenge to ensuring their safe deployment, as identifying and operating within a reliable \"safe zone\" is essential for mitigating risks. To address this, we present PredictaBoard, a novel collaborative benchmarking framework designed to evaluate the ability of score predictors (referred to as assessors) to anticipate LLM errors on specific task instances (i.e., prompts) from existing datasets. PredictaBoard evaluates pairs of LLMs and assessors by considering the rejection rate at different tolerance errors. As such, PredictaBoard stimulates research into developing better assessors and making LLMs more predictable, not only with a higher average performance. We conduct illustrative experiments using baseline assessors and state-of-the-art LLMs. PredictaBoard highlights the critical need to evaluate predictability alongside performance, paving the way for safer AI systems where errors are not only minimised but also anticipated and effectively mitigated. Code for our benchmark can be found at <a class=\"link-external link-https\" href=\"https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item238\">[238]</a>\n",
       "<a href=\"/abs/2502.15077\" id=\"2502.15077\" title=\"Abstract\">\n",
       "        arXiv:2502.15077\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.15077\" href=\"/pdf/2502.15077\" id=\"pdf-2502.15077\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.15077\" href=\"https://arxiv.org/html/2502.15077v3\" id=\"html-2502.15077\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.15077\" href=\"/format/2502.15077\" id=\"oth-2502.15077\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Hardware-Friendly Static Quantization Method for Video Diffusion Transformers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yi,+S\">Sanghyun Yi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Q\">Qingfeng Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=El-Khamy,+M\">Mostafa El-Khamy</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted to MIPR 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Diffusion Transformers for video generation have gained significant research interest since the impressive performance of SORA. Efficient deployment of such generative-AI models on GPUs has been demonstrated with dynamic quantization. However, resource-constrained devices cannot support dynamic quantization, and need static quantization of the models for their efficient deployment on AI processors. In this paper, we propose a novel method for the post-training quantization of OpenSora\\cite{opensora}, a Video Diffusion Transformer, without relying on dynamic quantization techniques. Our approach employs static quantization, achieving video quality comparable to FP16 and dynamically quantized ViDiT-Q methods, as measured by CLIP, and VQA metrics. In particular, we utilize per-step calibration data to adequately provide a post-training statically quantized model for each time step, incorporating channel-wise quantization for weights and tensor-wise quantization for activations. By further applying the smooth-quantization technique, we can obtain high-quality video outputs with the statically quantized models. Extensive experimental results demonstrate that static quantization can be a viable alternative to dynamic quantization for video diffusion transformers, offering a more efficient approach without sacrificing performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item239\">[239]</a>\n",
       "<a href=\"/abs/2502.16611\" id=\"2502.16611\" title=\"Abstract\">\n",
       "        arXiv:2502.16611\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.16611\" href=\"/pdf/2502.16611\" id=\"pdf-2502.16611\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.16611\" href=\"https://arxiv.org/html/2502.16611v2\" id=\"html-2502.16611\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.16611\" href=\"/format/2502.16611\" id=\"oth-2502.16611\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+S\">Shitong Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Y\">Yiyuan Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Trigoni,+N\">Niki Trigoni</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Markham,+A\">Andrew Markham</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          11 pages, 6 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Target speaker extraction focuses on isolating a specific speaker's voice from an audio mixture containing multiple speakers. To provide information about the target speaker's identity, prior works have utilized clean audio samples as conditioning inputs. However, such clean audio examples are not always readily available. For instance, obtaining a clean recording of a stranger's voice at a cocktail party without leaving the noisy environment is generally infeasible. Limited prior research has explored extracting the target speaker's characteristics from noisy enrollments, which may contain overlapping speech from interfering speakers. In this work, we explore a novel enrollment strategy that encodes target speaker information from the noisy enrollment by comparing segments where the target speaker is talking (Positive Enrollments) with segments where the target speaker is silent (Negative Enrollments). Experiments show the effectiveness of our model architecture, which achieves over 2.1 dB higher SI-SNRi compared to prior works in extracting the monaural speech from the mixture of two speakers. Additionally, the proposed two-stage training strategy accelerates convergence, reducing the number of optimization steps required to reach 3 dB SNR by 60\\%. Overall, our method achieves state-of-the-art performance in the monaural target speaker extraction conditioned on noisy enrollments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item240\">[240]</a>\n",
       "<a href=\"/abs/2502.17421\" id=\"2502.17421\" title=\"Abstract\">\n",
       "        arXiv:2502.17421\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.17421\" href=\"/pdf/2502.17421\" id=\"pdf-2502.17421\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.17421\" href=\"https://arxiv.org/html/2502.17421v2\" id=\"html-2502.17421\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.17421\" href=\"/format/2502.17421\" id=\"oth-2502.17421\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LongSpec: Long-Context Lossless Speculative Decoding with Efficient Drafting and Verification\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+P\">Penghui Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+C\">Cunxiao Du</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+F\">Fengzhuo Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Haonan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pang,+T\">Tianyu Pang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+C\">Chao Du</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=An,+B\">Bo An</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          As Large Language Models (LLMs) can now process extremely long contexts, efficient inference over these extended inputs has become increasingly important, especially for emerging applications like LLM agents that highly depend on this capability. Speculative decoding (SD) offers a promising lossless acceleration technique compared to lossy alternatives such as quantization and model cascades. However, most state-of-the-art SD methods are trained on short texts (typically fewer than 4k tokens), making them unsuitable for long-context scenarios. Specifically, adapting these methods to long contexts presents three key challenges: (1) the excessive memory demands posed by draft models due to large Key-Value (KV) cache; (2) performance degradation resulting from the mismatch between short-context training and long-context inference; and (3) inefficiencies in tree attention mechanisms when managing long token sequences. This work introduces LongSpec, a framework that addresses these challenges through three core innovations: a memory-efficient draft model with a constant-sized KV cache; novel position indices that mitigate the training-inference mismatch; and an attention aggregation strategy that combines fast prefix computation with standard tree attention to enable efficient decoding. Experimental results confirm the effectiveness of LongSpec, achieving up to a 3.26x speedup over strong Flash Attention baselines across five long-context understanding datasets, as well as a 2.25x reduction in wall-clock time on the AIME24 long reasoning task with the QwQ model, demonstrating significant latency improvements for long-context applications. The code is available at <a class=\"link-external link-https\" href=\"https://github.com/sail-sg/LongSpec\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item241\">[241]</a>\n",
       "<a href=\"/abs/2502.17514\" id=\"2502.17514\" title=\"Abstract\">\n",
       "        arXiv:2502.17514\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.17514\" href=\"/pdf/2502.17514\" id=\"pdf-2502.17514\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.17514\" href=\"https://arxiv.org/html/2502.17514v2\" id=\"html-2502.17514\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.17514\" href=\"/format/2502.17514\" id=\"oth-2502.17514\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SAE-V: Interpreting Multimodal Models for Enhanced Alignment\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lou,+H\">Hantao Lou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C\">Changye Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ji,+J\">Jiaming Ji</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Y\">Yaodong Yang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          17 pages, 13 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          With the integration of image modality, the semantic space of multimodal large language models (MLLMs) is more complex than text-only models, making their interpretability more challenging and their alignment less stable, particularly susceptible to low-quality data, which can lead to inconsistencies between modalities, hallucinations, and biased outputs. As a result, developing interpretability methods for MLLMs is crucial for improving alignment quality and efficiency. In text-only LLMs, Sparse Autoencoders (SAEs) have gained attention for their ability to interpret latent representations. However, extending SAEs to multimodal settings presents new challenges due to modality fusion and the difficulty of isolating cross-modal representations. To address these challenges, we introduce SAE-V, a mechanistic interpretability framework that extends the SAE paradigm to MLLMs. By identifying and analyzing interpretable features along with their corresponding data, SAE-V enables fine-grained interpretation of both model behavior and data quality, facilitating a deeper understanding of cross-modal interactions and alignment dynamics. Moreover, by utilizing cross-modal feature weighting, SAE-V provides an intrinsic data filtering mechanism to enhance model alignment without requiring additional models. Specifically, when applied to the alignment process of MLLMs, SAE-V-based data filtering methods could achieve more than 110% performance with less than 50% data. Our results highlight SAE-V's ability to enhance interpretability and alignment in MLLMs, providing insights into their internal mechanisms.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item242\">[242]</a>\n",
       "<a href=\"/abs/2502.18770\" id=\"2502.18770\" title=\"Abstract\">\n",
       "        arXiv:2502.18770\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2502.18770\" href=\"/pdf/2502.18770\" id=\"pdf-2502.18770\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2502.18770\" href=\"https://arxiv.org/html/2502.18770v3\" id=\"html-2502.18770\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2502.18770\" href=\"/format/2502.18770\" id=\"oth-2502.18770\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Reward Shaping to Mitigate Reward Hacking in RLHF\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+J\">Jiayi Fu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+X\">Xuandong Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+C\">Chengyuan Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Heng Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+Q\">Qi Han</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao,+Y\">Yanghua Xiao</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          24 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to \\emph{reward hacking}, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. Although reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests two key design principles: (1) the RL reward should be bounded, and (2) the RL reward benefits from rapid initial growth followed by gradual convergence. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model as the signal for reinforcement learning. We evaluated PAR on two base models, Gemma2-2B, and Llama3-8B, using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate of at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. The code is available at <a class=\"link-external link-https\" href=\"https://github.com/PorUna-byte/PAR\" rel=\"external noopener nofollow\">this https URL</a>, and the Work done during the internship at StepFun by Jiayi Fu.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item243\">[243]</a>\n",
       "<a href=\"/abs/2503.06926\" id=\"2503.06926\" title=\"Abstract\">\n",
       "        arXiv:2503.06926\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.06926\" href=\"/pdf/2503.06926\" id=\"pdf-2503.06926\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.06926\" href=\"https://arxiv.org/html/2503.06926v2\" id=\"html-2503.06926\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.06926\" href=\"/format/2503.06926\" id=\"oth-2503.06926\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Effect of Selection Format on LLM Performance\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+Y\">Yuchen Han</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+Y\">Yucheng Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Willard,+J\">Jeffrey Willard</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This paper investigates a critical aspect of large language model (LLM) performance: the optimal formatting of classification task options in prompts. Through an extensive experimental study, we compared two selection formats -- bullet points and plain English -- to determine their impact on model performance. Our findings suggest that presenting options via bullet points generally yields better results, although there are some exceptions. Furthermore, our research highlights the need for continued exploration of option formatting to drive further improvements in model performance.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item244\">[244]</a>\n",
       "<a href=\"/abs/2503.08669\" id=\"2503.08669\" title=\"Abstract\">\n",
       "        arXiv:2503.08669\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.08669\" href=\"/pdf/2503.08669\" id=\"pdf-2503.08669\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2503.08669\" href=\"/format/2503.08669\" id=\"oth-2503.08669\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SOPBench: Evaluating Language Agents at Following Standard Operating Procedures and Constraints\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zekun Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+S\">Shinda Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J\">Jiangtian Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+N\">Nathan Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniades,+A\">Antonis Antoniades</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hua,+W\">Wenyue Hua</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+K\">Kaijie Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+S\">Sirui Zeng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+C\">Chi Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+W+Y\">William Yang Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yan,+X\">Xifeng Yan</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Code, data, and over 24k agent trajectories are released at <a class=\"link-external link-https\" href=\"https://github.com/Leezekun/SOPBench\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          As language agents increasingly automate critical tasks, their ability to follow domain-specific standard operating procedures (SOPs), policies, and constraints when taking actions and making tool calls becomes essential yet remains underexplored. To address this gap, we develop an automated evaluation pipeline SOPBench with: (1) executable environments containing 167 tools/functions across seven customer service domains with service-specific SOPs and rule-based verifiers, (2) an automated test generation framework producing over 900 verified test cases, and (3) an automated evaluation framework to rigorously assess agent adherence from multiple dimensions. Our approach transforms each service-specific SOP code program into a directed graph of executable functions and requires agents to call these functions based on natural language SOP descriptions. The original code serves as oracle rule-based verifiers to assess compliance, reducing reliance on manual annotations and LLM-based evaluations. We evaluate 18 leading models, and results show the task is challenging even for top-tier models (like GPT-4o, Claude-3.7-Sonnet), with variances across domains. Reasoning models like o4-mini-high show superiority while other powerful models perform less effectively (pass rates of 30%-50%), and small models (7B, 8B) perform significantly worse. Additionally, language agents can be easily jailbroken to overlook SOPs and constraints. Code, data, and over 24k agent trajectories are released at <a class=\"link-external link-https\" href=\"https://github.com/Leezekun/SOPBench\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item245\">[245]</a>\n",
       "<a href=\"/abs/2503.10512\" id=\"2503.10512\" title=\"Abstract\">\n",
       "        arXiv:2503.10512\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.10512\" href=\"/pdf/2503.10512\" id=\"pdf-2503.10512\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.10512\" href=\"https://arxiv.org/html/2503.10512v2\" id=\"html-2503.10512\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.10512\" href=\"/format/2503.10512\" id=\"oth-2503.10512\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Conformal Prediction Sets for Deep Generative Models via Reduction to Conformal Regression\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shahrokhi,+H\">Hooman Shahrokhi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Roy,+D+R\">Devjeet Raj Roy</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yan,+Y\">Yan Yan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Arnaoudova,+V\">Venera Arnaoudova</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Doppa,+J+R\">Janaradhan Rao Doppa</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We consider the problem of generating valid and small prediction sets by sampling outputs (e.g., software code and natural language text) from a black-box deep generative model for a given input (e.g., textual prompt). The validity of a prediction set is determined by a user-defined binary admissibility function depending on the target application. For example, requiring at least one program in the set to pass all test cases in code generation application. To address this problem, we develop a simple and effective conformal inference algorithm referred to as Generative Prediction Sets (GPS). Given a set of calibration examples and black-box access to a deep generative model, GPS can generate prediction sets with provable guarantees. The key insight behind GPS is to exploit the inherent structure within the distribution over the minimum number of samples needed to obtain an admissible output to develop a simple conformal regression approach over the minimum number of samples. Experiments on multiple datasets for code and math word problems using different large language models demonstrate the efficacy of GPS over state-of-the-art methods.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item246\">[246]</a>\n",
       "<a href=\"/abs/2503.13562\" id=\"2503.13562\" title=\"Abstract\">\n",
       "        arXiv:2503.13562\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.13562\" href=\"/pdf/2503.13562\" id=\"pdf-2503.13562\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.13562\" href=\"https://arxiv.org/html/2503.13562v2\" id=\"html-2503.13562\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.13562\" href=\"/format/2503.13562\" id=\"oth-2503.13562\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Achieving Unbiased Multi-Instance Learning via Balanced Fine-Grained Positive-Unlabeled Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Jia,+L\">Lin-Han Jia</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Guo,+L\">Lan-Zhe Guo</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Zhou,+Z\">Zhi Zhou</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Han,+S\">Si-Ye Han</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Li,+Z\">Zi-Wen Li</a>, <a href=\"https://arxiv.org/search/stat?searchtype=author&amp;query=Li,+Y\">Yu-Feng Li</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          In real-world applications, it is often challenging to detect anomalous samples when the anomalous information they contain is extremely limited. In such cases, both macro-level and micro-level detection using multi-instance learning (MIL) encounter significant difficulties. The former struggles because normal and anomalous samples are highly similar and hard to distinguish at the macro level, while the latter is limited by the lack of labels at the micro level. In MIL, micro-level labels are inferred from macro-level labels, which can lead to severe bias. Moreover, the more imbalanced the distribution between normal and anomalous samples, the more pronounced these limitations become. In this study, we observe that the MIL problem can be elegantly transformed into a fine-grained Positive-Unlabeled (PU) learning problem. This transformation allows us to address the imbalance issue in an unbiased manner using a micro-level balancing mechanism. To this end, we propose a novel framework-Balanced Fine-Grained Positive-Unlabeled (BFGPU)-based on rigorous theoretical foundations to address the challenges above. Extensive experiments on both public and real-world datasets demonstrate the effectiveness of BFGPU, which outperforms existing methods, even in extreme scenarios where both macro and micro-level distributions are highly imbalanced. The code is open-sourced at <a class=\"link-external link-https\" href=\"https://github.com/BFGPU/BFGPU\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item247\">[247]</a>\n",
       "<a href=\"/abs/2503.16974\" id=\"2503.16974\" title=\"Abstract\">\n",
       "        arXiv:2503.16974\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.16974\" href=\"/pdf/2503.16974\" id=\"pdf-2503.16974\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2503.16974\" href=\"/format/2503.16974\" id=\"oth-2503.16974\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Wang,+J+J\">Julian Junyan Wang</a>, <a href=\"https://arxiv.org/search/q-fin?searchtype=author&amp;query=Wang,+V+X\">Victor Xiaoqi Wang</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          89 pages, 20 tables, 15 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">General Finance (q-fin.GN)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model (LLM) outputs in finance and accounting research. We evaluate how consistently LLMs produce outputs given identical inputs through extensive experimentation with 50 independent runs across five common tasks: classification, sentiment analysis, summarization, text generation, and prediction. Using three OpenAI models (GPT-3.5-turbo, GPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse financial source texts and data, covering MD&amp;As, FOMC statements, finance news articles, earnings call transcripts, and financial statements. Our findings reveal substantial but task-dependent consistency, with binary classification and sentiment analysis achieving near-perfect reproducibility, while complex tasks show greater variability. More advanced models do not consistently demonstrate better consistency and reproducibility, with task-specific patterns emerging. LLMs significantly outperform expert human annotators in consistency and maintain high agreement even where human experts significantly disagree. We further find that simple aggregation strategies across 3-5 runs dramatically improve consistency. We also find that aggregation may come with an additional benefit of improved accuracy for sentiment analysis when using newer models. Simulation analysis reveals that despite measurable inconsistency in LLM outputs, downstream statistical inferences remain remarkably robust. These findings address concerns about what we term \"G-hacking,\" the selective reporting of favorable outcomes from multiple Generative AI runs, by demonstrating that such risks are relatively low for finance and accounting tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item248\">[248]</a>\n",
       "<a href=\"/abs/2503.20848\" id=\"2503.20848\" title=\"Abstract\">\n",
       "        arXiv:2503.20848\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.20848\" href=\"/pdf/2503.20848\" id=\"pdf-2503.20848\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.20848\" href=\"https://arxiv.org/html/2503.20848v2\" id=\"html-2503.20848\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.20848\" href=\"/format/2503.20848\" id=\"oth-2503.20848\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          The Backfiring Effect of Weak AI Safety Regulation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Laufer,+B\">Benjamin Laufer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kleinberg,+J\">Jon Kleinberg</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Heidari,+H\">Hoda Heidari</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          35 pages, 5 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Theoretical Economics (econ.TH)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent policy proposals aim to improve the safety of general-purpose AI, but there is little understanding of the efficacy of different regulatory approaches to AI safety. We present a strategic model that explores the interactions between safety regulation, the general-purpose AI creators, and domain specialists--those who adapt the technology for specific applications. Our analysis examines how different regulatory measures, targeting different parts of the AI development chain, affect the outcome of this game. In particular, we assume AI technology is characterized by two key attributes: safety and performance. The regulator first sets a minimum safety standard that applies to one or both players, with strict penalties for non-compliance. The general-purpose creator then invests in the technology, establishing its initial safety and performance levels. Next, domain specialists refine the AI for their specific use cases, updating the safety and performance levels and taking the product to market. The resulting revenue is then distributed between the specialist and generalist through a revenue-sharing parameter. Our analysis reveals two key insights: First, weak safety regulation imposed predominantly on domain specialists can backfire. While it might seem logical to regulate AI use cases, our analysis shows that weak regulations targeting domain specialists alone can unintentionally reduce safety. This effect persists across a wide range of settings. Second, in sharp contrast to the previous finding, we observe that stronger, well-placed regulation can in fact mutually benefit all players subjected to it. When regulators impose appropriate safety standards on both general-purpose AI creators and domain specialists, the regulation functions as a commitment device, leading to safety and performance gains, surpassing what is achieved under no regulation or regulating one player alone.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item249\">[249]</a>\n",
       "<a href=\"/abs/2503.23394\" id=\"2503.23394\" title=\"Abstract\">\n",
       "        arXiv:2503.23394\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2503.23394\" href=\"/pdf/2503.23394\" id=\"pdf-2503.23394\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2503.23394\" href=\"https://arxiv.org/html/2503.23394v2\" id=\"html-2503.23394\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2503.23394\" href=\"/format/2503.23394\" id=\"oth-2503.23394\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Bae,+S\">Sangyoon Bae</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Kwon,+J\">Junbeom Kwon</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Yoo,+S\">Shinjae Yoo</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Cha,+J\">Jiook Cha</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Understanding how the brain's complex nonlinear dynamics give rise to cognitive function remains a central challenge in neuroscience. While brain functional dynamics exhibits scale-free and multifractal properties across temporal scales, conventional neuroimaging analytics assume linearity and stationarity, failing to capture frequency-specific neural computations. Here, we introduce Multi-Band Brain Net (MBBN), the first transformer-based framework to explicitly model frequency-specific spatiotemporal brain dynamics from fMRI. MBBN integrates biologically-grounded frequency decomposition with multi-band self-attention mechanisms, enabling discovery of previously undetectable frequency-dependent network interactions. Trained on 49,673 individuals across three large-scale cohorts (UK Biobank, ABCD, ABIDE), MBBN sets a new state-of-the-art in predicting psychiatric and cognitive outcomes (depression, ADHD, ASD), showing particular strength in classification tasks with up to 52.5\\% higher AUROC and provides a novel framework for predicting cognitive intelligence scores. Frequency-resolved analyses uncover disorder-specific signatures: in ADHD, high-frequency fronto-sensorimotor connectivity is attenuated and opercular somatosensory nodes emerge as dynamic hubs; in ASD, orbitofrontal-somatosensory circuits show focal high-frequency disruption together with enhanced ultra-low-frequency coupling between the temporo-parietal junction and prefrontal cortex. By integrating scale-aware neural dynamics with deep learning, MBBN delivers more accurate and interpretable biomarkers, opening avenues for precision psychiatry and developmental neuroscience.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item250\">[250]</a>\n",
       "<a href=\"/abs/2504.16005\" id=\"2504.16005\" title=\"Abstract\">\n",
       "        arXiv:2504.16005\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2504.16005\" href=\"/pdf/2504.16005\" id=\"pdf-2504.16005\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2504.16005\" href=\"/format/2504.16005\" id=\"oth-2504.16005\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          CAPO: Cost-Aware Prompt Optimization\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zehle,+T\">Tom Zehle</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schlager,+M\">Moritz Schlager</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hei%C3%9F,+T\">Timo Heiß</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Feurer,+M\">Matthias Feurer</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Submitted to AutoML 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language models (LLMs) have revolutionized natural language processing by solving a wide range of tasks simply guided by a prompt. Yet their performance is highly sensitive to prompt formulation. While automatic prompt optimization addresses this challenge by finding optimal prompts, current methods require a substantial number of LLM calls and input tokens, making prompt optimization expensive. We introduce CAPO (Cost-Aware Prompt Optimization), an algorithm that enhances prompt optimization efficiency by integrating AutoML techniques. CAPO is an evolutionary approach with LLMs as operators, incorporating racing to save evaluations and multi-objective optimization to balance performance with prompt length. It jointly optimizes instructions and few-shot examples while leveraging task descriptions for improved robustness. Our extensive experiments across diverse datasets and LLMs demonstrate that CAPO outperforms state-of-the-art discrete prompt optimization methods in 11/15 cases with improvements up to 21%p in accuracy. Our algorithm achieves better performances already with smaller budgets, saves evaluations through racing, and decreases average prompt length via a length penalty, making it both cost-efficient and cost-aware. Even without few-shot examples, CAPO outperforms its competitors and generally remains robust to initial prompts. CAPO represents an important step toward making prompt optimization more powerful and accessible by improving cost-efficiency.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item251\">[251]</a>\n",
       "<a href=\"/abs/2505.00039\" id=\"2505.00039\" title=\"Abstract\">\n",
       "        arXiv:2505.00039\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.00039\" href=\"/pdf/2505.00039\" id=\"pdf-2505.00039\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.00039\" href=\"https://arxiv.org/html/2505.00039v3\" id=\"html-2505.00039\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.00039\" href=\"/format/2505.00039\" id=\"oth-2505.00039\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Graph RAG for Legal Norms: A Hierarchical, Temporal and Deterministic Approach\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=de+Martim,+H\">Hudson de Martim</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This version enhances the theoretical underpinnings of the proposed Graph RAG methodology, including the introduction of a formal, FRBRoo-based model for versioning, and enabling multi-language support for both content and metadata\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This article proposes an adaptation of Graph Retrieval-Augmented Generation (Graph RAG) specifically designed for the analysis and comprehension of legal norms. Legal texts are characterized by a predefined hierarchical structure, an extensive network of references and a continuous evolution through multiple temporal versions. This temporal dynamism poses a significant challenge for standard AI systems, demanding a deterministic representation of the law at any given point in time. To address this, our approach grounds the knowledge graph construction in a formal, FRBRoo-inspired model that distinguishes abstract legal works from their concrete textual expressions. We introduce a multi-layered representation of Temporal Versions (capturing date-specific changes) and Language Versions (capturing linguistic variations). By modeling normative evolution as a precise sequence of these versioned entities, we enable the construction of a knowledge graph that serves as a verifiable \"ground truth\". This allows Large Language Models to generate responses based on accurate, context-aware, and point-in-time correct legal information, overcoming the risk of temporal inaccuracies. Through a detailed analysis of this formal Graph RAG approach and its application to legal norm datasets, this article aims to advance the field of Artificial Intelligence applied to Law, creating opportunities for more effective and reliable systems in legal research, legislative analysis, and decision support.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item252\">[252]</a>\n",
       "<a href=\"/abs/2505.06987\" id=\"2505.06987\" title=\"Abstract\">\n",
       "        arXiv:2505.06987\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.06987\" href=\"/pdf/2505.06987\" id=\"pdf-2505.06987\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.06987\" href=\"https://arxiv.org/html/2505.06987v4\" id=\"html-2505.06987\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.06987\" href=\"/format/2505.06987\" id=\"oth-2505.06987\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Convert Language Model into a Value-based Strategic Planner\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xiaoyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+Y\">Yue Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gu,+Q\">Qingqing Gu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+Z\">Zhonglin Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+X\">Xiaokai Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+Y\">Yong Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ji,+L\">Luo Ji</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          13 pages, 6 figures, Accepted by ACL 2025 Industry Track\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Emotional support conversation (ESC) aims to alleviate the emotional distress of individuals through effective conversations. Although large language models (LLMs) have obtained remarkable progress on ESC, most of these studies might not define the diagram from the state model perspective, therefore providing a suboptimal solution for long-term satisfaction. To address such an issue, we leverage the Q-learning on LLMs, and propose a framework called straQ*. Our framework allows a plug-and-play LLM to bootstrap the planning during ESC, determine the optimal strategy based on long-term returns, and finally guide the LLM to response. Substantial experiments on ESC datasets suggest that straQ* outperforms many baselines, including direct inference, self-refine, chain of thought, finetuning, and finite state machines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item253\">[253]</a>\n",
       "<a href=\"/abs/2505.07819\" id=\"2505.07819\" title=\"Abstract\">\n",
       "        arXiv:2505.07819\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.07819\" href=\"/pdf/2505.07819\" id=\"pdf-2505.07819\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.07819\" href=\"https://arxiv.org/html/2505.07819v2\" id=\"html-2505.07819\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.07819\" href=\"/format/2505.07819\" id=\"oth-2505.07819\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          H$^3$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yiyang Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tian,+Y\">Yufeng Tian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+Z\">Zhecheng Yuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xianbang Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hua,+P\">Pu Hua</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xue,+Z\">Zhengrong Xue</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+H\">Huazhe Xu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Visuomotor policy learning has witnessed substantial progress in robotic manipulation, with recent approaches predominantly relying on generative models to model the action distribution. However, these methods often overlook the critical coupling between visual perception and action prediction. In this work, we introduce $\\textbf{Triply-Hierarchical Diffusion Policy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework that explicitly incorporates hierarchical structures to strengthen the integration between visual features and action generation. H$^{3}$DP contains $\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes RGB-D observations based on depth information; (2) multi-scale visual representations that encode semantic features at varying levels of granularity; and (3) a hierarchically conditioned diffusion process that aligns the generation of coarse-to-fine actions with corresponding visual features. Extensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$ average relative improvement over baselines across $\\mathbf{44}$ simulation tasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual real-world manipulation tasks. Project Page: <a class=\"link-external link-https\" href=\"https://lyy-iiis.github.io/h3dp/\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item254\">[254]</a>\n",
       "<a href=\"/abs/2505.07897\" id=\"2505.07897\" title=\"Abstract\">\n",
       "        arXiv:2505.07897\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.07897\" href=\"/pdf/2505.07897\" id=\"pdf-2505.07897\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.07897\" href=\"https://arxiv.org/html/2505.07897v2\" id=\"html-2505.07897\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.07897\" href=\"/format/2505.07897\" id=\"oth-2505.07897\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          LongCodeBench: Evaluating Coding LLMs at 1M Context Windows\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rando,+S\">Stefano Rando</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Romani,+L\">Luca Romani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sampieri,+A\">Alessio Sampieri</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Franco,+L\">Luca Franco</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+J\">John Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kyuragi,+Y\">Yuta Kyuragi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Galasso,+F\">Fabio Galasso</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hashimoto,+T\">Tatsunori Hashimoto</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Context lengths for models have grown rapidly, from thousands to millions of tokens in just a few years. The extreme context sizes of modern long-context models have made it difficult to construct realistic long-context benchmarks -- not only due to the cost of collecting million-context tasks but also in identifying realistic scenarios that require significant contexts. We identify code comprehension and repair as a natural testbed and challenge task for long-context models and introduce LongCodeBench (LCB), a benchmark to test LLM coding abilities in long-context scenarios. Our benchmark tests both the comprehension and repair capabilities of LCLMs in realistic and important settings by drawing from real-world GitHub issues and constructing QA (LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the complexity of our benchmark, enabling us to evaluate models across different scales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model. We find that long-context remains a weakness for all models, with performance drops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for Qwen2.5.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item255\">[255]</a>\n",
       "<a href=\"/abs/2505.11404\" id=\"2505.11404\" title=\"Abstract\">\n",
       "        arXiv:2505.11404\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.11404\" href=\"/pdf/2505.11404\" id=\"pdf-2505.11404\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.11404\" href=\"https://arxiv.org/html/2505.11404v3\" id=\"html-2505.11404\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.11404\" href=\"/format/2505.11404\" id=\"oth-2505.11404\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+W\">Wenchuan Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+P\">Penghao Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guo,+J\">Jingru Guo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+T\">Tao Cheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J\">Jie Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S\">Shuwan Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zhang Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yi,+Y\">Yuhao Yi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bu,+H\">Hong Bu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent advances in vision language models (VLMs) have enabled broad progress in the general medical field. However, pathology still remains a more challenging subdomain, with current pathology specific VLMs exhibiting limitations in both diagnostic accuracy and reasoning plausibility. Such shortcomings are largely attributable to the nature of current pathology datasets, which are primarily composed of image description pairs that lack the depth and structured diagnostic paradigms employed by real world pathologists. In this study, we leverage pathology textbooks and real world pathology experts to construct high-quality, reasoning-oriented datasets. Building on this, we introduce Patho-R1, a multimodal RL-based pathology Reasoner, trained through a three-stage pipeline: (1) continued pretraining on 3.5 million image-text pairs for knowledge infusion; (2) supervised fine-tuning on 500k high-quality Chain-of-Thought samples for reasoning incentivizing; (3) reinforcement learning using Group Relative Policy Optimization and Decoupled Clip and Dynamic sAmpling Policy Optimization strategies for multimodal reasoning quality refinement. To further assess the alignment quality of our dataset, we propose Patho-CLIP, trained on the same figure-caption corpus used for continued pretraining. Comprehensive experimental results demonstrate that both Patho-CLIP and Patho-R1 achieve robust performance across a wide range of pathology-related tasks, including zero-shot classification, cross-modal retrieval, Visual Question Answering, and Multiple Choice Question. Our project is available at the Patho-R1 repository: <a class=\"link-external link-https\" href=\"https://github.com/Wenchuan-Zhang/Patho-R1\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item256\">[256]</a>\n",
       "<a href=\"/abs/2505.11633\" id=\"2505.11633\" title=\"Abstract\">\n",
       "        arXiv:2505.11633\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.11633\" href=\"/pdf/2505.11633\" id=\"pdf-2505.11633\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.11633\" href=\"https://arxiv.org/html/2505.11633v2\" id=\"html-2505.11633\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.11633\" href=\"/format/2505.11633\" id=\"oth-2505.11633\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tykhonov,+V\">Vyacheslav Tykhonov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+H\">Han Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mayr,+P\">Philipp Mayr</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Touber,+J\">Jetze Touber</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Scharnhorst,+A\">Andrea Scharnhorst</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 3 figures, Accepted at Joint Workshop of the 5th AI + Informetrics (AII) and the 6th Extraction and Evaluation of Knowledge Entities from Scientific Documents (EEKE)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This demo paper reports on a new workflow \\textit{GhostWriter} that combines the use of Large Language Models and Knowledge Graphs (semantic artifacts) to support navigation through collections. Situated in the research area of Retrieval Augmented Generation, this specific workflow represents the creation of local and adaptable chatbots. Based on the tool-suite \\textit{EverythingData} at the backend, \\textit{GhostWriter} provides an interface that enables querying and ``chatting'' with a collection. Applied iteratively, the workflow supports the information needs of researchers when interacting with a collection of papers, whether it be to gain an overview, to learn more about a specific concept and its context, and helps the researcher ultimately to refine their research question in a controlled way. We demonstrate the workflow for a collection of articles from the \\textit{method data analysis} journal published by GESIS -- Leibniz-Institute for the Social Sciences. We also point to further application areas.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item257\">[257]</a>\n",
       "<a href=\"/abs/2505.12368\" id=\"2505.12368\" title=\"Abstract\">\n",
       "        arXiv:2505.12368\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.12368\" href=\"/pdf/2505.12368\" id=\"pdf-2505.12368\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.12368\" href=\"https://arxiv.org/html/2505.12368v2\" id=\"html-2505.12368\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.12368\" href=\"/format/2505.12368\" id=\"oth-2505.12368\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kholkar,+G\">Gauri Kholkar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ahuja,+R\">Ratinder Ahuja</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted in ACL LLMSec Workshop 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Prompt injection remains a major security risk for large language models. However, the efficacy of existing guardrail models in context-aware settings remains underexplored, as they often rely on static attack benchmarks. Additionally, they have over-defense tendencies. We introduce CAPTURE, a novel context-aware benchmark assessing both attack detection and over-defense tendencies with minimal in-domain examples. Our experiments reveal that current prompt injection guardrail models suffer from high false negatives in adversarial cases and excessive false positives in benign scenarios, highlighting critical limitations. To demonstrate our framework's utility, we train CaptureGuard on our generated data. This new model drastically reduces both false negative and false positive rates on our context-aware datasets while also generalizing effectively to external benchmarks, establishing a path toward more robust and practical prompt injection defenses.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item258\">[258]</a>\n",
       "<a href=\"/abs/2505.12442\" id=\"2505.12442\" title=\"Abstract\">\n",
       "        arXiv:2505.12442\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.12442\" href=\"/pdf/2505.12442\" id=\"pdf-2505.12442\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.12442\" href=\"https://arxiv.org/html/2505.12442v3\" id=\"html-2505.12442\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.12442\" href=\"/format/2505.12442\" id=\"oth-2505.12442\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+L\">Liwen Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+W\">Wenxuan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+S\">Shuai Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zongjie Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ji,+Z\">Zhenlan Ji</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lyu,+Z\">Zongyi Lyu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+D\">Daoyuan Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheung,+S\">Shing-Chi Cheung</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The rapid advancement of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems (MAS) to perform complex tasks through collaboration. However, the intricate nature of MAS, including their architecture and agent interactions, raises significant concerns regarding intellectual property (IP) protection. In this paper, we introduce MASLEAK, a novel attack framework designed to extract sensitive information from MAS applications. MASLEAK targets a practical, black-box setting, where the adversary has no prior knowledge of the MAS architecture or agent configurations. The adversary can only interact with the MAS through its public API, submitting attack query $q$ and observing outputs from the final agent. Inspired by how computer worms propagate and infect vulnerable network hosts, MASLEAK carefully crafts adversarial query $q$ to elicit, propagate, and retain responses from each MAS agent that reveal a full set of proprietary components, including the number of agents, system topology, system prompts, task instructions, and tool usages. We construct the first synthetic dataset of MAS applications with 810 applications and also evaluate MASLEAK against real-world MAS applications, including Coze and CrewAI. MASLEAK achieves high accuracy in extracting MAS IP, with an average attack success rate of 87% for system prompts and task instructions, and 92% for system architecture in most cases. We conclude by discussing the implications of our findings and the potential defenses.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item259\">[259]</a>\n",
       "<a href=\"/abs/2505.14661\" id=\"2505.14661\" title=\"Abstract\">\n",
       "        arXiv:2505.14661\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.14661\" href=\"/pdf/2505.14661\" id=\"pdf-2505.14661\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.14661\" href=\"https://arxiv.org/html/2505.14661v2\" id=\"html-2505.14661\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.14661\" href=\"/format/2505.14661\" id=\"oth-2505.14661\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Abacus: A Cost-Based Optimizer for Semantic Operator Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Russo,+M\">Matthew Russo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sudhir,+S\">Sivaprasad Sudhir</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vitagliano,+G\">Gerardo Vitagliano</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+C\">Chunwei Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kraska,+T\">Tim Kraska</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Madden,+S\">Samuel Madden</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cafarella,+M\">Michael Cafarella</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          16 pages, 6 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          LLMs enable an exciting new class of data processing applications over large collections of unstructured documents. Several new programming frameworks have enabled developers to build these applications by composing them out of semantic operators: a declarative set of AI-powered data transformations with natural language specifications. These include LLM-powered maps, filters, joins, etc. used for document processing tasks such as information extraction, summarization, and more. While systems of semantic operators have achieved strong performance on benchmarks, they can be difficult to optimize. An optimizer for this setting must determine how to physically implement each semantic operator in a way that optimizes the system globally. Existing optimizers are limited in the number of optimizations they can apply, and most (if not all) cannot optimize system quality, cost, or latency subject to constraint(s) on the other dimensions. In this paper we present Abacus, an extensible, cost-based optimizer which searches for the best implementation of a semantic operator system given a (possibly constrained) optimization objective. Abacus estimates operator performance by leveraging a minimal set of validation examples and, if available, prior beliefs about operator performance. We evaluate Abacus on document processing workloads in the biomedical and legal domains (BioDEX; CUAD) and multi-modal question answering (MMQA). We demonstrate that systems optimized by Abacus achieve 18.7%-39.2% better quality and up to 23.6x lower cost and 4.2x lower latency than the next best system.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item260\">[260]</a>\n",
       "<a href=\"/abs/2505.14719\" id=\"2505.14719\" title=\"Abstract\">\n",
       "        arXiv:2505.14719\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.14719\" href=\"/pdf/2505.14719\" id=\"pdf-2505.14719\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.14719\" href=\"https://arxiv.org/html/2505.14719v2\" id=\"html-2505.14719\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.14719\" href=\"/format/2505.14719\" id=\"oth-2505.14719\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hua,+W\">Wei Hua</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+C\">Chenlin Zhou</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J\">Jibin Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chua,+Y\">Yansong Chua</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shu,+Y\">Yangyang Shu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          11pages, 2figures, accepted by IJCAI'25 (34th International Joint Conference on Artificial Intelligence)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The combination of Spiking Neural Networks (SNNs) with Vision Transformer architectures has garnered significant attention due to their potential for energy-efficient and high-performance computing paradigms. However, a substantial performance gap still exists between SNN-based and ANN-based transformer architectures. While existing methods propose spiking self-attention mechanisms that are successfully combined with SNNs, the overall architectures proposed by these methods suffer from a bottleneck in effectively extracting features from different image scales. In this paper, we address this issue and propose MSVIT. This novel spike-driven Transformer architecture firstly uses multi-scale spiking attention (MSSA) to enhance the capabilities of spiking attention blocks. We validate our approach across various main datasets. The experimental results show that MSVIT outperforms existing SNN-based models, positioning itself as a state-of-the-art solution among SNN-transformer architectures. The codes are available at <a class=\"link-external link-https\" href=\"https://github.com/Nanhu-AI-Lab/MSViT\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item261\">[261]</a>\n",
       "<a href=\"/abs/2505.20613\" id=\"2505.20613\" title=\"Abstract\">\n",
       "        arXiv:2505.20613\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.20613\" href=\"/pdf/2505.20613\" id=\"pdf-2505.20613\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.20613\" href=\"https://arxiv.org/html/2505.20613v2\" id=\"html-2505.20613\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.20613\" href=\"/format/2505.20613\" id=\"oth-2505.20613\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+Z\">Ziju Shen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+N\">Naohao Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+F\">Fanyi Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y\">Yutong Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gao,+G\">Guoxiong Gao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+T\">Tianyi Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+J\">Jiedong Jiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+W\">Wanyi He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+P\">Pu Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+M\">Mengzhou Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ju,+H\">Haocheng Ju</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+P\">Peihao Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+B\">Bryan Dai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dong,+B\">Bin Dong</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Nowadays, formal theorem provers have made monumental progress on high-school and competition-level mathematics, but few of them generalize to more advanced mathematics. In this paper, we present REAL-Prover, a new open-source stepwise theorem prover for Lean 4 to push this boundary. This prover, based on our fine-tuned large language model (REAL-Prover-v1) and integrated with a retrieval system (Leansearch-PS), notably boosts performance on solving college-level mathematics problems. To train REAL-Prover-v1, we developed HERALD-AF, a data extraction pipeline that converts natural language math problems into formal statements, and a new open-source Lean 4 interactive environment (Jixia-interactive) to facilitate synthesis data collection. In our experiments, our prover using only supervised fine-tune achieves competitive results with a 23.7% success rate (Pass@64) on the ProofNet dataset-comparable to state-of-the-art (SOTA) models. To further evaluate our approach, we introduce FATE-M, a new benchmark focused on algebraic problems, where our prover achieves a SOTA success rate of 56.7% (Pass@64).\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item262\">[262]</a>\n",
       "<a href=\"/abs/2505.21652\" id=\"2505.21652\" title=\"Abstract\">\n",
       "        arXiv:2505.21652\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.21652\" href=\"/pdf/2505.21652\" id=\"pdf-2505.21652\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.21652\" href=\"https://arxiv.org/html/2505.21652v3\" id=\"html-2505.21652\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.21652\" href=\"/format/2505.21652\" id=\"oth-2505.21652\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yin,+Y\">Yifan Yin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+Z\">Zhengtao Han</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Aarya,+S\">Shivam Aarya</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J\">Jianxin Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+S\">Shuhang Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+J\">Jiawei Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+A\">Angtian Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuille,+A\">Alan Yuille</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shu,+T\">Tianmin Shu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Fine-grained robot manipulation, such as lifting and rotating a bottle to display the label on the cap, requires robust reasoning about object parts and their relationships with intended tasks. Despite recent advances in training general-purpose robot manipulation policies guided by language instructions, there is a notable lack of large-scale datasets for fine-grained manipulation tasks with part-level instructions and diverse 3D object instances annotated with part-level labels. In this work, we introduce PartInstruct, the first large-scale benchmark for training and evaluating fine-grained robot manipulation models using part-level instructions. PartInstruct comprises 513 object instances across 14 categories, each annotated with part-level information, and 1302 fine-grained manipulation tasks organized into 16 task classes. Our training set consists of over 10,000 expert demonstrations synthesized in a 3D simulator, where each demonstration is paired with a high-level task instruction, a chain of base part-based skill instructions, and ground-truth 3D information about the object and its parts. Additionally, we designed a comprehensive test suite to evaluate the generalizability of learned policies across new states, objects, and tasks. We evaluated several state-of-the-art robot manipulation approaches, including end-to-end vision-language policy learning and bi-level planning models for robot manipulation on our benchmark. The experimental results reveal that current models struggle to robustly ground part concepts and predict actions in 3D space, and face challenges when manipulating object parts in long-horizon tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item263\">[263]</a>\n",
       "<a href=\"/abs/2505.23145\" id=\"2505.23145\" title=\"Abstract\">\n",
       "        arXiv:2505.23145\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.23145\" href=\"/pdf/2505.23145\" id=\"pdf-2505.23145\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.23145\" href=\"https://arxiv.org/html/2505.23145v2\" id=\"html-2505.23145\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.23145\" href=\"/format/2505.23145\" id=\"oth-2505.23145\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+J\">Jeongsol Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hong,+Y\">Yeobin Hong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ye,+J+C\">Jong Chul Ye</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Recent inversion-free, flow-based image editing methods such as FlowEdit leverages a pre-trained noise-to-image flow model such as Stable Diffusion 3, enabling text-driven manipulation by solving an ordinary differential equation (ODE). While the lack of exact latent inversion is a core advantage of these methods, it often results in unstable editing trajectories and poor source consistency. To address this limitation, we propose FlowAlign, a novel inversion-free flow-based framework for consistent image editing with principled trajectory control. FlowAlign introduces a flow-matching loss as a regularization mechanism to promote smoother and more stable trajectories during the editing process. Notably, the flow-matching loss is shown to explicitly balance semantic alignment with the edit prompt and structural consistency with the source image along the trajectory. Furthermore, FlowAlign naturally supports reverse editing by simply reversing the ODE trajectory, highlighting the reversible and consistent nature of the transformation. Extensive experiments demonstrate that FlowAlign outperforms existing methods in both source preservation and editing controllability.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item264\">[264]</a>\n",
       "<a href=\"/abs/2505.23247\" id=\"2505.23247\" title=\"Abstract\">\n",
       "        arXiv:2505.23247\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.23247\" href=\"/pdf/2505.23247\" id=\"pdf-2505.23247\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.23247\" href=\"https://arxiv.org/html/2505.23247v2\" id=\"html-2505.23247\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.23247\" href=\"/format/2505.23247\" id=\"oth-2505.23247\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Accelerating RLHF Training with Reward Variance Increase\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+Z\">Zonglin Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gu,+Z\">Zhexuan Gu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qi,+H\">Houduo Qi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yuan,+Y\">Yancheng Yuan</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Reinforcement learning from human feedback (RLHF) is an essential technique for ensuring that large language models (LLMs) are aligned with human values and preferences during the post-training phase. As an effective RLHF approach, group relative policy optimization (GRPO) has demonstrated success in many LLM-based applications. However, efficient GRPO-based RLHF training remains a challenge. Recent studies reveal that a higher reward variance of the initial policy model leads to faster RLHF training. Inspired by this finding, we propose a practical reward adjustment model to accelerate RLHF training by provably increasing the reward variance and preserving the relative preferences and reward expectation. Our reward adjustment method inherently poses a nonconvex optimization problem, which is NP-hard to solve in general. To overcome the computational challenges, we design a novel $O(n \\log n)$ algorithm to find a global solution of the nonconvex reward adjustment model by explicitly characterizing the extreme points of the feasible set. As an important application, we naturally integrate this reward adjustment model into the GRPO algorithm, leading to a more efficient GRPO with reward variance increase (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we provide an indirect explanation for the empirical effectiveness of GRPO with rule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment results demonstrate that the GRPOVI algorithm can significantly improve the RLHF training efficiency compared to the original GRPO algorithm.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item265\">[265]</a>\n",
       "<a href=\"/abs/2505.23354\" id=\"2505.23354\" title=\"Abstract\">\n",
       "        arXiv:2505.23354\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.23354\" href=\"/pdf/2505.23354\" id=\"pdf-2505.23354\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.23354\" href=\"https://arxiv.org/html/2505.23354v2\" id=\"html-2505.23354\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.23354\" href=\"/format/2505.23354\" id=\"oth-2505.23354\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Representing local protein environments with atomistic foundation models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Bojan,+M\">Meital Bojan</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Vedula,+S\">Sanketh Vedula</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Maddipatla,+A\">Advaith Maddipatla</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Sellam,+N+B\">Nadav Bojan Sellam</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Napoli,+F\">Federico Napoli</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Schanda,+P\">Paul Schanda</a>, <a href=\"https://arxiv.org/search/q-bio?searchtype=author&amp;query=Bronstein,+A+M\">Alex M. Bronstein</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item266\">[266]</a>\n",
       "<a href=\"/abs/2505.23873\" id=\"2505.23873\" title=\"Abstract\">\n",
       "        arXiv:2505.23873\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.23873\" href=\"/pdf/2505.23873\" id=\"pdf-2505.23873\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.23873\" href=\"https://arxiv.org/html/2505.23873v2\" id=\"html-2505.23873\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.23873\" href=\"/format/2505.23873\" id=\"oth-2505.23873\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          KGMark: A Diffusion Watermark for Knowledge Graphs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+H\">Hongrui Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+H\">Haolang Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+Y\">Yuanlong Yu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fu,+W\">Weiye Fu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+K\">Kun Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Nan,+G\">Guoshun Nan</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Accepted by ICML2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Knowledge graphs (KGs) are ubiquitous in numerous real-world applications, and watermarking facilitates protecting intellectual property and preventing potential harm from AI-generated content. Existing watermarking methods mainly focus on static plain text or image data, while they can hardly be applied to dynamic graphs due to spatial and temporal variations of structured data. This motivates us to propose KGMARK, the first graph watermarking framework that aims to generate robust, detectable, and transparent diffusion fingerprints for dynamic KG data. Specifically, we propose a novel clustering-based alignment method to adapt the watermark to spatial variations. Meanwhile, we present a redundant embedding strategy to harden the diffusion watermark against various attacks, facilitating the robustness of the watermark to the temporal variations. Additionally, we introduce a novel learnable mask matrix to improve the transparency of diffusion fingerprints. By doing so, our KGMARK properly tackles the variation challenges of structured data. Experiments on various public benchmarks show the effectiveness of our proposed KGMARK. Our code is available at <a class=\"link-external link-https\" href=\"https://github.com/phrara/kgmark\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item267\">[267]</a>\n",
       "<a href=\"/abs/2505.24120\" id=\"2505.24120\" title=\"Abstract\">\n",
       "        arXiv:2505.24120\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2505.24120\" href=\"/pdf/2505.24120\" id=\"pdf-2505.24120\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2505.24120\" href=\"https://arxiv.org/html/2505.24120v2\" id=\"html-2505.24120\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2505.24120\" href=\"/format/2505.24120\" id=\"oth-2505.24120\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jian,+A\">Ai Jian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu,+W\">Weijie Qiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X\">Xiaokun Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+P\">Peiyu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hao,+Y\">Yunzhuo Hao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pei,+J\">Jiangbo Pei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wei,+Y\">Yichen Wei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+Y\">Yi Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+X\">Xuchen Song</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          36 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal understanding, yet their capabilities for scientific reasoning remain inadequately assessed. Current multimodal benchmarks predominantly evaluate generic image comprehension or text-driven reasoning, lacking authentic scientific contexts that require domain-specific knowledge integration with visual evidence analysis. To fill this gap, we present CSVQA, a diagnostic multimodal benchmark specifically designed for evaluating scientific reasoning through domain-grounded visual question answering. Our benchmark features 1,378 carefully constructed question-answer pairs spanning diverse STEM disciplines, each demanding domain knowledge, integration of visual evidence, and higher-order reasoning. Compared to prior multimodal benchmarks, CSVQA places greater emphasis on real-world scientific content and complex reasoning. We additionally propose a rigorous evaluation protocol to systematically assess whether model predictions are substantiated by valid intermediate reasoning steps based on curated explanations. Our comprehensive evaluation of 15 VLMs on this benchmark reveals notable performance disparities, as even the top-ranked proprietary model attains only 49.6% accuracy. This empirical evidence underscores the pressing need for advancing scientific reasoning capabilities in VLMs. Our CSVQA is released at <a class=\"link-external link-https\" href=\"https://huggingface.co/datasets/Skywork/CSVQA\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item268\">[268]</a>\n",
       "<a href=\"/abs/2506.00555\" id=\"2506.00555\" title=\"Abstract\">\n",
       "        arXiv:2506.00555\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.00555\" href=\"/pdf/2506.00555\" id=\"pdf-2506.00555\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.00555\" href=\"https://arxiv.org/html/2506.00555v2\" id=\"html-2506.00555\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.00555\" href=\"/format/2506.00555\" id=\"oth-2506.00555\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xia,+P\">Peng Xia</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J\">Jinglu Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Peng,+Y\">Yibo Peng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+K\">Kaide Zeng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+X\">Xian Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tang,+X\">Xiangru Tang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+H\">Hongtu Zhu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y\">Yun Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+S\">Shujie Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+Y\">Yan Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+H\">Huaxiu Yao</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential in multimodal diagnostic tasks. However, existing single-agent models struggle to generalize across diverse medical specialties, limiting their performance. Recent efforts introduce multi-agent collaboration frameworks inspired by clinical workflows, where general practitioners (GPs) and specialists interact in a fixed sequence. Despite improvements, these static pipelines lack flexibility and adaptability in reasoning. To address this, we propose MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that enables dynamic, optimized collaboration among medical agents. Specifically, we train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to assign patients to appropriate specialties, while the attending physician integrates the judgments from multi-specialists and its own knowledge to make final decisions. To address the inconsistency in specialist outputs, we introduce a curriculum learning (CL)-guided RL strategy that progressively teaches the attending physician to balance between imitating specialists and correcting their mistakes. Experiments on five medical VQA benchmarks demonstrate that MMedAgent-RL not only outperforms both open-source and proprietary Med-LVLMs, but also exhibits human-like reasoning patterns. Notably, it achieves an average performance gain of 20.7% over supervised fine-tuning baselines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item269\">[269]</a>\n",
       "<a href=\"/abs/2506.00854\" id=\"2506.00854\" title=\"Abstract\">\n",
       "        arXiv:2506.00854\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.00854\" href=\"/pdf/2506.00854\" id=\"pdf-2506.00854\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.00854\" href=\"https://arxiv.org/html/2506.00854v2\" id=\"html-2506.00854\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.00854\" href=\"/format/2506.00854\" id=\"oth-2506.00854\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          EEG2TEXT-CN: An Exploratory Study of Open-Vocabulary Chinese Text-EEG Alignment via Large Language Model and Contrastive Learning on ChineseEEG\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+J+T\">Jacky Tai-Yu Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chiang,+J\">Jung Chiang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+C\">Chi-Sheng Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tung,+A+N\">Anna Nai-Yun Tung</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+H+W\">Hsiang Wei Hu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng,+Y+C\">Yuan Chiao Cheng</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Neurons and Cognition (q-bio.NC)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We propose EEG2TEXT-CN, which, to the best of our knowledge, represents one of the earliest open-vocabulary EEG-to-text generation frameworks tailored for Chinese. Built on a biologically grounded EEG encoder (NICE-EEG) and a compact pretrained language model (MiniLM), our architecture aligns multichannel brain signals with natural language representations via masked pretraining and contrastive learning. Using a subset of the ChineseEEG dataset, where each sentence contains approximately ten Chinese characters aligned with 128-channel EEG recorded at 256 Hz, we segment EEG into per-character embeddings and predict full sentences in a zero-shot setting. The decoder is trained with teacher forcing and padding masks to accommodate variable-length sequences. Evaluation on over 1,500 training-validation sentences and 300 held-out test samples shows promising lexical alignment, with a best BLEU-1 score of 6.38\\%. While syntactic fluency remains a challenge, our findings demonstrate the feasibility of non-phonetic, cross-modal language decoding from EEG. This work opens a new direction in multilingual brain-to-text research and lays the foundation for future cognitive-language interfaces in Chinese.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item270\">[270]</a>\n",
       "<a href=\"/abs/2506.01413\" id=\"2506.01413\" title=\"Abstract\">\n",
       "        arXiv:2506.01413\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.01413\" href=\"/pdf/2506.01413\" id=\"pdf-2506.01413\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.01413\" href=\"https://arxiv.org/html/2506.01413v4\" id=\"html-2506.01413\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.01413\" href=\"/format/2506.01413\" id=\"oth-2506.01413\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qin,+Y\">Yulei Qin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+G\">Gang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Z\">Zongyi Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Z\">Zihan Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+Y\">Yuchen Shi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+Z\">Zhekai Lin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+X\">Xiao Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+K\">Ke Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+X\">Xing Sun</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          13 pages of main body, 3 tables, 5 figures, 45 pages of appendix\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Existing large language models (LLMs) face challenges of following complex instructions, especially when multiple constraints are present and organized in paralleling, chaining, and branching structures. One intuitive solution, namely chain-of-thought (CoT), is expected to universally improve capabilities of LLMs. However, we find that the vanilla CoT exerts a negative impact on performance due to its superficial reasoning pattern of simply paraphrasing the instructions. It fails to peel back the compositions of constraints for identifying their relationship across hierarchies of types and dimensions. To this end, we propose a systematic method to boost LLMs in dealing with complex instructions via incentivizing reasoning for test-time compute scaling. First, we stem from the decomposition of complex instructions under existing taxonomies and propose a reproducible data acquisition method. Second, we exploit reinforcement learning (RL) with verifiable rule-centric reward signals to cultivate reasoning specifically for instruction following. We address the shallow, non-essential nature of reasoning under complex instructions via sample-wise contrast for superior CoT enforcement. We also exploit behavior cloning of experts to facilitate steady distribution shift from fast-thinking LLMs to skillful reasoners. Extensive evaluations on seven comprehensive benchmarks confirm the validity of the proposed method, where a 1.5B LLM achieves 11.74% gains with performance comparable to a 8B LLM. Codes and data will be available later (under review).\n",
       "<br/>Keywords: reinforcement learning with verifiable rewards (RLVR), instruction following, complex instructions\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item271\">[271]</a>\n",
       "<a href=\"/abs/2506.04079\" id=\"2506.04079\" title=\"Abstract\">\n",
       "        arXiv:2506.04079\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.04079\" href=\"/pdf/2506.04079\" id=\"pdf-2506.04079\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.04079\" href=\"https://arxiv.org/html/2506.04079v2\" id=\"html-2506.04079\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.04079\" href=\"/format/2506.04079\" id=\"oth-2506.04079\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          EuroLLM-9B: Technical Report\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Martins,+P+H\">Pedro Henrique Martins</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Alves,+J\">João Alves</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fernandes,+P\">Patrick Fernandes</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Guerreiro,+N+M\">Nuno M. Guerreiro</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rei,+R\">Ricardo Rei</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Farajian,+A\">Amin Farajian</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Klimaszewski,+M\">Mateusz Klimaszewski</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Alves,+D+M\">Duarte M. Alves</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Pombal,+J\">José Pombal</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Boizard,+N\">Nicolas Boizard</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Faysse,+M\">Manuel Faysse</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Colombo,+P\">Pierre Colombo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yvon,+F\">François Yvon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Haddow,+B\">Barry Haddow</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=de+Souza,+J+G+C\">José G. C. de Souza</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Birch,+A\">Alexandra Birch</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Martins,+A+F+T\">André F. T. Martins</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          56 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This report presents EuroLLM-9B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-9B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. We describe the pre-training data collection and filtering pipeline, including the creation of EuroFilter, an AI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a novel synthetic dataset for post-training that enhances language coverage for European languages. Evaluation results demonstrate EuroLLM-9B's competitive performance on multilingual benchmarks and machine translation tasks, establishing it as the leading open European-made LLM of its size. To support open research and adoption, we release all major components of this work, including the base and instruction-tuned models, the EuroFilter classifier, and the synthetic post-training dataset.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item272\">[272]</a>\n",
       "<a href=\"/abs/2506.06290\" id=\"2506.06290\" title=\"Abstract\">\n",
       "        arXiv:2506.06290\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.06290\" href=\"/pdf/2506.06290\" id=\"pdf-2506.06290\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.06290\" href=\"https://arxiv.org/html/2506.06290v2\" id=\"html-2506.06290\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.06290\" href=\"/format/2506.06290\" id=\"oth-2506.06290\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lu,+M\">Mingyu Lu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Weinberger,+E\">Ethan Weinberger</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+C\">Chanwoo Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+S\">Su-In Lee</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          High-content screening (HCS) assays based on high-throughput microscopy techniques such as Cell Painting have enabled the interrogation of cells' morphological responses to perturbations at an unprecedented scale. The collection of such data promises to facilitate a better understanding of the relationships between different perturbations and their effects on cellular state. Towards achieving this goal, recent advances in cross-modal contrastive learning could, in theory, be leveraged to learn a unified latent space that aligns perturbations with their corresponding morphological effects. However, the application of such methods to HCS data is not straightforward due to substantial differences in the semantics of Cell Painting images compared to natural images, and the difficulty of representing different classes of perturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent space. In response to these challenges, here we introduce CellCLIP, a cross-modal contrastive learning framework for HCS data. CellCLIP leverages pre-trained image encoders coupled with a novel channel encoding scheme to better capture relationships between different microscopy channels in image embeddings, along with natural language encoders for representing perturbations. Our framework outperforms current open-source models, demonstrating the best performance in both cross-modal retrieval and biologically meaningful downstream tasks while also achieving significant reductions in computation time.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item273\">[273]</a>\n",
       "<a href=\"/abs/2506.06499\" id=\"2506.06499\" title=\"Abstract\">\n",
       "        arXiv:2506.06499\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.06499\" href=\"/pdf/2506.06499\" id=\"pdf-2506.06499\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.06499\" href=\"https://arxiv.org/html/2506.06499v2\" id=\"html-2506.06499\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.06499\" href=\"/format/2506.06499\" id=\"oth-2506.06499\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Havrilla,+A\">Alex Havrilla</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hughes,+E\">Edward Hughes</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Samvelyan,+M\">Mikayel Samvelyan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Abernethy,+J\">Jacob Abernethy</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Large language model (LLM) driven synthetic data generation has emerged as a powerful method for improving model reasoning capabilities. However, most methods either distill large state-of-the-art models into small students or use natural ground-truth problem statements to guarantee problem statement quality. This limits the scalability of these approaches to more complex and diverse problem domains. To address this, we present SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms, a novel approach for generating high-quality and diverse synthetic math problem and solution pairs using only a single model by measuring a problem's solve-rate: a proxy for problem difficulty. Starting from a seed dataset of 7.5K samples, we generate over 20 million new problem-solution pairs. We show that filtering the generated data by difficulty and then fine-tuning the same model on the resulting data improves relative model performance by up to 24\\%. Additionally, we conduct ablations studying the impact of synthetic data quantity, quality and diversity on model generalization. We find that higher quality, as measured by problem difficulty, facilitates better in-distribution performance. Further, while generating diverse synthetic data does not as strongly benefit in-distribution performance, filtering for more diverse data facilitates more robust OOD generalization. We also confirm the existence of model and data scaling laws for synthetically generated problems, which positively benefit downstream model generalization.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item274\">[274]</a>\n",
       "<a href=\"/abs/2506.07801\" id=\"2506.07801\" title=\"Abstract\">\n",
       "        arXiv:2506.07801\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.07801\" href=\"/pdf/2506.07801\" id=\"pdf-2506.07801\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.07801\" href=\"https://arxiv.org/html/2506.07801v2\" id=\"html-2506.07801\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.07801\" href=\"/format/2506.07801\" id=\"oth-2506.07801\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sirbu,+I\">Iustin Sirbu</a> (1), <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Popovici,+R\">Robert-Adrian Popovici</a> (1), <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Caragea,+C\">Cornelia Caragea</a> (2), <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Trausan-Matu,+S\">Stefan Trausan-Matu</a> (1), <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Rebedea,+T\">Traian Rebedea</a> (1 and 3) ((1) National University of Science and Technology POLITEHNICA Bucharest, (2) University of Illinois Chicago, (3) NVIDIA)</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm combining the paradigms of co-training and consistency regularization with pseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label weighting module designed for three key purposes: selecting and filtering pseudo-labels based on head agreement and model confidence, and weighting them according to the perceived classification difficulty. This novel module enhances and unifies three existing techniques -- heads agreement from Multihead Co-training, self-adaptive thresholds from FreeMatch, and Average Pseudo-Margins from MarginMatch -- resulting in a holistic approach that improves robustness and performance in SSL settings. Experimental results on benchmark datasets highlight the superior performance of MultiMatch, achieving state-of-the-art results on 9 out of 10 setups from 5 natural language processing datasets and ranking first according to the Friedman test among 19 methods. Furthermore, MultiMatch demonstrates exceptional robustness in highly imbalanced settings, outperforming the second-best approach by 3.26% -- and data imbalance is a key factor for many text classification tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item275\">[275]</a>\n",
       "<a href=\"/abs/2506.08001\" id=\"2506.08001\" title=\"Abstract\">\n",
       "        arXiv:2506.08001\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.08001\" href=\"/pdf/2506.08001\" id=\"pdf-2506.08001\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.08001\" href=\"https://arxiv.org/html/2506.08001v3\" id=\"html-2506.08001\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.08001\" href=\"/format/2506.08001\" id=\"oth-2506.08001\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Reparameterized LLM Training via Orthogonal Equivalence Transformation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qiu,+Z\">Zeju Qiu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Buchholz,+S\">Simon Buchholz</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xiao,+T+Z\">Tim Z. Xiao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dax,+M\">Maximilian Dax</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sch%C3%B6lkopf,+B\">Bernhard Schölkopf</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+W\">Weiyang Liu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Technical report v3 (38 pages, 26 figures, project page: <a class=\"link-external link-https\" href=\"https://spherelab.ai/poet/\" rel=\"external noopener nofollow\">this https URL</a>, v3: added singular spectrum and energy analyses in Section 4)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          While large language models (LLMs) are driving the rapid advancement of artificial intelligence, effectively and reliably training these large models remains one of the field's most significant challenges. To address this challenge, we propose POET, a novel reParameterized training algorithm that uses Orthogonal Equivalence Transformation to optimize neurons. Specifically, POET reparameterizes each neuron with two learnable orthogonal matrices and a fixed random weight matrix. Because of its provable preservation of spectral properties of weight matrices, POET can stably optimize the objective function with improved generalization. We further develop efficient approximations that make POET flexible and scalable for training large-scale neural networks. Extensive experiments validate the effectiveness and scalability of POET in training LLMs.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item276\">[276]</a>\n",
       "<a href=\"/abs/2506.08915\" id=\"2506.08915\" title=\"Abstract\">\n",
       "        arXiv:2506.08915\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.08915\" href=\"/pdf/2506.08915\" id=\"pdf-2506.08915\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.08915\" href=\"https://arxiv.org/html/2506.08915v3\" id=\"html-2506.08915\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.08915\" href=\"/format/2506.08915\" id=\"oth-2506.08915\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Inherently Faithful Attention Maps for Vision Transformers\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Aniraj,+A\">Ananthu Aniraj</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dantas,+C+F\">Cassio F. Dantas</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ienco,+D\">Dino Ienco</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Marcos,+D\">Diego Marcos</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We introduce an attention-based method that uses learned binary attention masks to ensure that only attended image regions influence the prediction. Context can strongly affect object perception, sometimes leading to biased representations, particularly when objects appear in out-of-distribution backgrounds. At the same time, many image-level object-centric tasks require identifying relevant regions, often requiring context. To address this conundrum, we propose a two-stage framework: stage 1 processes the full image to discover object parts and identify task-relevant regions, while stage 2 leverages input attention masking to restrict its receptive field to these regions, enabling a focused analysis while filtering out potentially spurious information. Both stages are trained jointly, allowing stage 2 to refine stage 1. Extensive experiments across diverse benchmarks demonstrate that our approach significantly improves robustness against spurious correlations and out-of-distribution backgrounds. Code: <a class=\"link-external link-https\" href=\"https://github.com/ananthu-aniraj/ifam\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item277\">[277]</a>\n",
       "<a href=\"/abs/2506.09081\" id=\"2506.09081\" title=\"Abstract\">\n",
       "        arXiv:2506.09081\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.09081\" href=\"/pdf/2506.09081\" id=\"pdf-2506.09081\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.09081\" href=\"https://arxiv.org/html/2506.09081v2\" id=\"html-2506.09081\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.09081\" href=\"/format/2506.09081\" id=\"oth-2506.09081\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          FlagEvalMM: A Flexible Framework for Comprehensive Multimodal Model Evaluation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Z\">Zheqi He</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yesheng Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zheng,+J\">Jing-shu Zheng</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+X\">Xuejing Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yao,+J\">Jin-Ge Yao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Qin,+B\">Bowen Qin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xuan,+R\">Richeng Xuan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+X\">Xi Yang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present FlagEvalMM, an open-source evaluation framework designed to comprehensively assess multimodal models across a diverse range of vision-language understanding and generation tasks, such as visual question answering, text-to-image/video generation, and image-text retrieval. We decouple model inference from evaluation through an independent evaluation service, thus enabling flexible resource allocation and seamless integration of new tasks and models. Moreover, FlagEvalMM utilizes advanced inference acceleration tools (e.g., vLLM, SGLang) and asynchronous data loading to significantly enhance evaluation efficiency. Extensive experiments show that FlagEvalMM offers accurate and efficient insights into model strengths and limitations, making it a valuable tool for advancing multimodal research. The framework is publicly accessible athttps://github.com/flageval-baai/FlagEvalMM.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item278\">[278]</a>\n",
       "<a href=\"/abs/2506.10274\" id=\"2506.10274\" title=\"Abstract\">\n",
       "        arXiv:2506.10274\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.10274\" href=\"/pdf/2506.10274\" id=\"pdf-2506.10274\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.10274\" href=\"https://arxiv.org/html/2506.10274v2\" id=\"html-2506.10274\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.10274\" href=\"/format/2506.10274\" id=\"oth-2506.10274\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Discrete Audio Tokens: More Than a Survey!\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mousavi,+P\">Pooneh Mousavi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Maimon,+G\">Gallil Maimon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Moumen,+A\">Adel Moumen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Petermann,+D\">Darius Petermann</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shi,+J\">Jiatong Shi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+H\">Haibin Wu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+H\">Haici Yang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kuznetsova,+A\">Anastasia Kuznetsova</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ploujnikov,+A\">Artem Ploujnikov</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Marxer,+R\">Ricard Marxer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ramabhadran,+B\">Bhuvana Ramabhadran</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Elizalde,+B\">Benjamin Elizalde</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lugosch,+L\">Loren Lugosch</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+J\">Jinyu Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Subakan,+C\">Cem Subakan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Woodland,+P\">Phil Woodland</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+M\">Minje Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+H\">Hung-yi Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe,+S\">Shinji Watanabe</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Adi,+Y\">Yossi Adi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ravanelli,+M\">Mirco Ravanelli</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Discrete audio tokens are compact representations that aim to preserve perceptual quality, phonetic content, and speaker characteristics while enabling efficient storage and inference, as well as competitive performance across diverse downstream tasks. They provide a practical alternative to continuous features, enabling the integration of speech and audio into modern large language models (LLMs). As interest in token-based audio processing grows, various tokenization methods have emerged, and several surveys have reviewed the latest progress in the field. However, existing studies often focus on specific domains or tasks and lack a unified comparison across various benchmarks. This paper presents a systematic review and benchmark of discrete audio tokenizers, covering three domains: speech, music, and general audio. We propose a taxonomy of tokenization approaches based on encoder-decoder, quantization techniques, training paradigm, streamability, and application domains. We evaluate tokenizers on multiple benchmarks for reconstruction, downstream performance, and acoustic language modeling, and analyze trade-offs through controlled ablation studies. Our findings highlight key limitations, practical considerations, and open challenges, providing insight and guidance for future research in this rapidly evolving area. For more information, including our main results and tokenizer database, please refer to our website: <a class=\"link-external link-https\" href=\"https://poonehmousavi.github.io/dates-website/\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item279\">[279]</a>\n",
       "<a href=\"/abs/2506.11054\" id=\"2506.11054\" title=\"Abstract\">\n",
       "        arXiv:2506.11054\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.11054\" href=\"/pdf/2506.11054\" id=\"pdf-2506.11054\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.11054\" href=\"https://arxiv.org/html/2506.11054v2\" id=\"html-2506.11054\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.11054\" href=\"/format/2506.11054\" id=\"oth-2506.11054\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kanneganti,+D\">Deepak Kanneganti</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mistry,+S\">Sajib Mistry</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fattah,+S+M+M\">Sheik Mohammad Mostakim Fattah</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Krishna,+A\">Aneesh Krishna</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bhuyan,+M\">Monowar Bhuyan</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The dynamic nature of Internet of Things (IoT) environments challenges the long-term effectiveness of Machine Learning as a Service (MLaaS) compositions. The uncertainty and variability of IoT environments lead to fluctuations in data distribution, e.g., concept drift and data heterogeneity, and evolving system requirements, e.g., scalability demands and resource limitations. This paper proposes an adaptive MLaaS composition framework to ensure a seamless, efficient, and scalable MLaaS composition. The framework integrates a service assessment model to identify underperforming MLaaS services and a candidate selection model to filter optimal replacements. An adaptive composition mechanism is developed that incrementally updates MLaaS compositions using a contextual multi-armed bandit optimization strategy. By continuously adapting to evolving IoT constraints, the approach maintains Quality of Service (QoS) while reducing the computational cost associated with recomposition from scratch. Experimental results on a real-world dataset demonstrate the efficiency of our proposed approach.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item280\">[280]</a>\n",
       "<a href=\"/abs/2506.11421\" id=\"2506.11421\" title=\"Abstract\">\n",
       "        arXiv:2506.11421\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.11421\" href=\"/pdf/2506.11421\" id=\"pdf-2506.11421\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.11421\" href=\"/format/2506.11421\" id=\"oth-2506.11421\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shao,+J\">Junli Shao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dong,+J\">Jing Dong</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+D\">Dingzhou Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shih,+K\">Kowei Shih</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+D\">Dannier Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+C\">Chengrui Zhou</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          With the rapid growth of Internet services, recommendation systems play a central role in delivering personalized content. Faced with massive user requests and complex model architectures, the key challenge for real-time recommendation systems is how to reduce inference latency and increase system throughput without sacrificing recommendation quality. This paper addresses the high computational cost and resource bottlenecks of deep learning models in real-time settings by proposing a combined set of modeling- and system-level acceleration and optimization strategies. At the model level, we dramatically reduce parameter counts and compute requirements through lightweight network design, structured pruning, and weight quantization. At the system level, we integrate multiple heterogeneous compute platforms and high-performance inference libraries, and we design elastic inference scheduling and load-balancing mechanisms based on real-time load characteristics. Experiments show that, while maintaining the original recommendation accuracy, our methods cut latency to less than 30% of the baseline and more than double system throughput, offering a practical solution for deploying large-scale online recommendation services.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item281\">[281]</a>\n",
       "<a href=\"/abs/2506.12468\" id=\"2506.12468\" title=\"Abstract\">\n",
       "        arXiv:2506.12468\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.12468\" href=\"/pdf/2506.12468\" id=\"pdf-2506.12468\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.12468\" href=\"https://arxiv.org/html/2506.12468v2\" id=\"html-2506.12468\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.12468\" href=\"/format/2506.12468\" id=\"oth-2506.12468\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S\">Suyeon Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kang,+S\">SeongKu Kang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+D\">Dongwoo Kim</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ok,+J\">Jungseul Ok</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H\">Hwanjo Yu</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          12 pages\n",
       "        </div>\n",
       "<div class=\"list-journal-ref\"><span class=\"descriptor\">Journal-ref:</span>\n",
       "          KDD 2025\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Graph Neural Networks (GNNs) have achieved state-of-the-art performance in node classification tasks but struggle with label noise in real-world data. Existing studies on graph learning with label noise commonly rely on class-dependent label noise, overlooking the complexities of instance-dependent noise and falling short of capturing real-world corruption patterns. We introduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a new benchmark that provides realistic graph datasets with various noise types and comprehensively evaluates noise-handling strategies across GNN architectures, noisy label detection, and noise-robust learning. To simulate instance-dependent corruptions, BeGIN introduces algorithmic methods and LLM-based simulations. Our experiments reveal the challenges of instance-dependent noise, particularly LLM-based corruption, and underscore the importance of node-specific parameterization to enhance GNN robustness. By comprehensively evaluating noise-handling strategies, BeGIN provides insights into their effectiveness, efficiency, and key performance factors. We expect that BeGIN will serve as a valuable resource for advancing research on label noise in graphs and fostering the development of robust GNN training methods. The code is available at <a class=\"link-external link-https\" href=\"https://github.com/kimsu55/BeGIN\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item282\">[282]</a>\n",
       "<a href=\"/abs/2506.13087\" id=\"2506.13087\" title=\"Abstract\">\n",
       "        arXiv:2506.13087\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13087\" href=\"/pdf/2506.13087\" id=\"pdf-2506.13087\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13087\" href=\"/format/2506.13087\" id=\"oth-2506.13087\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          IKDiffuser: Fast and Diverse Inverse Kinematics Solution Generation for Multi-arm Robotic Systems\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+Z\">Zeyu Zhang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jiao,+Z\">Ziyuan Jiao</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          under review\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Solving Inverse Kinematics (IK) problems is fundamental to robotics, but has primarily been successful with single serial manipulators. For multi-arm robotic systems, IK remains challenging due to complex self-collisions, coupled joints, and high-dimensional redundancy. These complexities make traditional IK solvers slow, prone to failure, and lacking in solution diversity. In this paper, we present IKDiffuser, a diffusion-based model designed for fast and diverse IK solution generation for multi-arm robotic systems. IKDiffuser learns the joint distribution over the configuration space, capturing complex dependencies and enabling seamless generalization to multi-arm robotic systems of different structures. In addition, IKDiffuser can incorporate additional objectives during inference without retraining, offering versatility and adaptability for task-specific requirements. In experiments on 6 different multi-arm systems, the proposed IKDiffuser achieves superior solution accuracy, precision, diversity, and computational efficiency compared to existing solvers. The proposed IKDiffuser framework offers a scalable, unified approach to solving multi-arm IK problems, facilitating the potential of multi-arm robotic systems in real-time manipulation tasks.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item283\">[283]</a>\n",
       "<a href=\"/abs/2506.13172\" id=\"2506.13172\" title=\"Abstract\">\n",
       "        arXiv:2506.13172\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13172\" href=\"/pdf/2506.13172\" id=\"pdf-2506.13172\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"oth-2506.13172\" href=\"/format/2506.13172\" id=\"oth-2506.13172\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          AI-Facilitated Analysis of Abstracts and Conclusions: Flagging Unsubstantiated Claims and Ambiguous Pronouns\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Markhasin,+E\">Evgeny Markhasin</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          13 pages\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present and evaluate a suite of proof-of-concept (PoC), structured workflow prompts designed to elicit human-like hierarchical reasoning while guiding Large Language Models (LLMs) in the high-level semantic and linguistic analysis of scholarly manuscripts. The prompts target two non-trivial analytical tasks within academic summaries (abstracts and conclusions): identifying unsubstantiated claims (informational integrity) and flagging semantically confusing ambiguous pronoun references (linguistic clarity). We conducted a systematic, multi-run evaluation on two frontier models (Gemini Pro 2.5 Pro and ChatGPT Plus o3) under varied context conditions. Our results for the informational integrity task reveal a significant divergence in model performance: while both models successfully identified an unsubstantiated head of a noun phrase (95% success), ChatGPT consistently failed (0% success) to identify an unsubstantiated adjectival modifier that Gemini correctly flagged (95% success), raising a question regarding the potential influence of the target's syntactic role. For the linguistic analysis task, both models performed well (80-90% success) with full manuscript context. Surprisingly, in a summary-only setting, Gemini's performance was substantially degraded, while ChatGPT achieved a perfect (100%) success rate. Our findings suggest that while structured prompting is a viable methodology for complex textual analysis, prompt performance may be highly dependent on the interplay between the model, task type, and context, highlighting the need for rigorous, model-specific testing.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item284\">[284]</a>\n",
       "<a href=\"/abs/2506.13244\" id=\"2506.13244\" title=\"Abstract\">\n",
       "        arXiv:2506.13244\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13244\" href=\"/pdf/2506.13244\" id=\"pdf-2506.13244\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13244\" href=\"https://arxiv.org/html/2506.13244v2\" id=\"html-2506.13244\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13244\" href=\"/format/2506.13244\" id=\"oth-2506.13244\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          No-Regret Learning Under Adversarial Resource Constraints: A Spending Plan Is All You Need!\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Stradi,+F+E\">Francesco Emanuele Stradi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Castiglioni,+M\">Matteo Castiglioni</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Marchesi,+A\">Alberto Marchesi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gatti,+N\">Nicola Gatti</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kroer,+C\">Christian Kroer</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We study online decision making problems under resource constraints, where both reward and cost functions are drawn from distributions that may change adversarially over time. We focus on two canonical settings: $(i)$ online resource allocation where rewards and costs are observed before action selection, and $(ii)$ online learning with resource constraints where they are observed after action selection, under full feedback or bandit feedback. It is well known that achieving sublinear regret in these settings is impossible when reward and cost distributions may change arbitrarily over time. To address this challenge, we analyze a framework in which the learner is guided by a spending plan--a sequence prescribing expected resource usage across rounds. We design general (primal-)dual methods that achieve sublinear regret with respect to baselines that follow the spending plan. Crucially, the performance of our algorithms improves when the spending plan ensures a well-balanced distribution of the budget across rounds. We additionally provide a robust variant of our methods to handle worst-case scenarios where the spending plan is highly imbalanced. To conclude, we study the regret of our algorithms when competing against benchmarks that deviate from the prescribed spending plan.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item285\">[285]</a>\n",
       "<a href=\"/abs/2506.13277\" id=\"2506.13277\" title=\"Abstract\">\n",
       "        arXiv:2506.13277\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13277\" href=\"/pdf/2506.13277\" id=\"pdf-2506.13277\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13277\" href=\"https://arxiv.org/html/2506.13277v2\" id=\"html-2506.13277\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13277\" href=\"/format/2506.13277\" id=\"oth-2506.13277\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          SeqPE: Transformer with Sequential Position Encoding\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H\">Huayang Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y\">Yahui Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+H\">Hongyu Sun</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cai,+D\">Deng Cai</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+L\">Leyang Cui</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Bi,+W\">Wei Bi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao,+P\">Peilin Zhao</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Watanabe,+T\">Taro Watanabe</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Since self-attention layers in Transformers are permutation invariant by design, positional encodings must be explicitly incorporated to enable spatial understanding. However, fixed-size lookup tables used in traditional learnable position embeddings (PEs) limit extrapolation capabilities beyond pre-trained sequence lengths. Expert-designed methods such as ALiBi and RoPE, mitigate this limitation but demand extensive modifications for adapting to new modalities, underscoring fundamental challenges in adaptability and scalability. In this work, we present SeqPE, a unified and fully learnable position encoding framework that represents each $n$-dimensional position index as a symbolic sequence and employs a lightweight sequential position encoder to learn their embeddings in an end-to-end manner. To regularize SeqPE's embedding space, we introduce two complementary objectives: a contrastive objective that aligns embedding distances with a predefined position-distance function, and a knowledge distillation loss that anchors out-of-distribution position embeddings to in-distribution teacher representations, further enhancing extrapolation performance. Experiments across language modeling, long-context question answering, and 2D image classification demonstrate that SeqPE not only surpasses strong baselines in perplexity, exact match (EM), and accuracy--particularly under context length extrapolation--but also enables seamless generalization to multi-dimensional inputs without requiring manual architectural redesign. We release our code, data, and checkpoints at <a class=\"link-external link-https\" href=\"https://github.com/ghrua/seqpe\" rel=\"external noopener nofollow\">this https URL</a>.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item286\">[286]</a>\n",
       "<a href=\"/abs/2506.13300\" id=\"2506.13300\" title=\"Abstract\">\n",
       "        arXiv:2506.13300\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13300\" href=\"/pdf/2506.13300\" id=\"pdf-2506.13300\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13300\" href=\"https://arxiv.org/html/2506.13300v2\" id=\"html-2506.13300\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13300\" href=\"/format/2506.13300\" id=\"oth-2506.13300\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+B\">Bo Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+C\">Chengben Xu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+W\">Wufeng Zhang</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          This paper presents Seewo's systems for both tracks of the Multilingual Conversational Speech Language Model Challenge (MLC-SLM), addressing automatic speech recognition (ASR) and speaker diarization with ASR (SD-ASR). We introduce a multi-stage training pipeline that explicitly enhances reasoning and self-correction in speech language models for ASR. Our approach combines curriculum learning for progressive capability acquisition, Chain-of-Thought data augmentation to foster intermediate reflection, and Reinforcement Learning with Verifiable Rewards (RLVR) to further refine self-correction through reward-driven optimization. This approach achieves substantial improvements over the official challenge baselines. On the evaluation set, our best system attains a WER/CER of 11.57% for Track 1 and a tcpWER/tcpCER of 17.67% for Track 2. Comprehensive ablation studies demonstrate the effectiveness of each component under challenge constraints.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item287\">[287]</a>\n",
       "<a href=\"/abs/2506.13472\" id=\"2506.13472\" title=\"Abstract\">\n",
       "        arXiv:2506.13472\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13472\" href=\"/pdf/2506.13472\" id=\"pdf-2506.13472\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13472\" href=\"https://arxiv.org/html/2506.13472v2\" id=\"html-2506.13472\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13472\" href=\"/format/2506.13472\" id=\"oth-2506.13472\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Yoon,+J\">Junho Yoon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+G\">Geom Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jeon,+D\">Donghyeon Jeon</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kang,+I\">Inho Kang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Na,+S\">Seung-Hoon Na</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          10 pages, 2 figures\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Quantization has been widely studied as an effective technique for reducing the memory requirement of large language models (LLMs), potentially improving the latency time as well. Utilizing the characteristic of rotational invariance of transformer, we propose the rotation-based saliency-aware weight quantization (ROSAQ), which identifies salient channels in the projection feature space, not in the original feature space, where the projected \"principal\" dimensions are naturally considered as \"salient\" features. The proposed ROSAQ consists of 1) PCA-based projection, which first performs principal component analysis (PCA) on a calibration set and transforms via the PCA projection, 2) Salient channel dentification, which selects dimensions corresponding to the K-largest eigenvalues as salient channels, and 3) Saliency-aware quantization with mixed-precision, which uses FP16 for salient dimensions and INT3/4 for other dimensions. Experiment results show that ROSAQ shows improvements over the baseline saliency-aware quantization on the original feature space and other existing quantization methods. With kernel fusion, ROSAQ presents about 2.3x speed up over FP16 implementation in generating 256 tokens with a batch size of 64.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item288\">[288]</a>\n",
       "<a href=\"/abs/2506.13566\" id=\"2506.13566\" title=\"Abstract\">\n",
       "        arXiv:2506.13566\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13566\" href=\"/pdf/2506.13566\" id=\"pdf-2506.13566\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13566\" href=\"https://arxiv.org/html/2506.13566v2\" id=\"html-2506.13566\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13566\" href=\"/format/2506.13566\" id=\"oth-2506.13566\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          A Production Scheduling Framework for Reinforcement Learning Under Real-World Constraints\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hoss,+J\">Jonathan Hoss</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Schelling,+F\">Felix Schelling</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Klarmann,+N\">Noah Klarmann</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          This paper has been accepted for presentation at the IEEE 21st International Conference on Automation Science and Engineering (CASE 2025)\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          The classical Job Shop Scheduling Problem (JSSP) focuses on optimizing makespan under deterministic constraints. Real-world production environments introduce additional complexities that cause traditional scheduling approaches to be less effective. Reinforcement learning (RL) holds potential in addressing these challenges, as it allows agents to learn adaptive scheduling strategies. However, there is a lack of a comprehensive, general-purpose frameworks for effectively training and evaluating RL agents under real-world constraints. To address this gap, we propose a modular framework that extends classical JSSP formulations by incorporating key real-world constraints inherent to the shopfloor, including transport logistics, buffer management, machine breakdowns, setup times, and stochastic processing conditions, while also supporting multi-objective optimization. The framework is a customizable solution that offers flexibility in defining problem instances and configuring simulation parameters, enabling adaptation to diverse production scenarios. A standardized interface ensures compatibility with various RL approaches, providing a robust environment for training RL agents and facilitating the standardized comparison of different scheduling methods under dynamic and uncertain conditions. We release JobShopLab as an open-source tool for both research and industrial applications, accessible at: <a class=\"link-external link-https\" href=\"https://github.com/proto-lab-ro/jobshoplab\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item289\">[289]</a>\n",
       "<a href=\"/abs/2506.13628\" id=\"2506.13628\" title=\"Abstract\">\n",
       "        arXiv:2506.13628\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13628\" href=\"/pdf/2506.13628\" id=\"pdf-2506.13628\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13628\" href=\"https://arxiv.org/html/2506.13628v2\" id=\"html-2506.13628\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13628\" href=\"/format/2506.13628\" id=\"oth-2506.13628\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Graph-Convolutional-Beta-VAE for Synthetic Abdominal Aorta Aneurysm Generation\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Fabbri,+F\">Francesco Fabbri</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Scarpolini,+M+A\">Martino Andrea Scarpolini</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Iollo,+A\">Angelo Iollo</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Viola,+F\">Francesco Viola</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tudisco,+F\">Francesco Tudisco</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Typo in the title\n",
       "        </div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Tissues and Organs (q-bio.TO)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Synthetic data generation plays a crucial role in medical research by mitigating privacy concerns and enabling large-scale patient data analysis. This study presents a beta-Variational Autoencoder Graph Convolutional Neural Network framework for generating synthetic Abdominal Aorta Aneurysms (AAA). Using a small real-world dataset, our approach extracts key anatomical features and captures complex statistical relationships within a compact disentangled latent space. To address data limitations, low-impact data augmentation based on Procrustes analysis was employed, preserving anatomical integrity. The generation strategies, both deterministic and stochastic, manage to enhance data diversity while ensuring realism. Compared to PCA-based approaches, our model performs more robustly on unseen data by capturing complex, nonlinear anatomical variations. This enables more comprehensive clinical and statistical analyses than the original dataset alone. The resulting synthetic AAA dataset preserves patient privacy while providing a scalable foundation for medical research, device testing, and computational modeling.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item290\">[290]</a>\n",
       "<a href=\"/abs/2506.13674\" id=\"2506.13674\" title=\"Abstract\">\n",
       "        arXiv:2506.13674\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13674\" href=\"/pdf/2506.13674\" id=\"pdf-2506.13674\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13674\" href=\"https://arxiv.org/html/2506.13674v2\" id=\"html-2506.13674\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13674\" href=\"/format/2506.13674\" id=\"oth-2506.13674\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          Prefix-Tuning+: Modernizing Prefix-Tuning by Decoupling the Prefix from Attention\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+H\">Haonan Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+B\">Brian Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+S\">Siquan Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+X\">Xinhe Liang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+H+K\">Hwee Kuan Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kawaguchi,+K\">Kenji Kawaguchi</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+T\">Tianyang Hu</a></div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          Parameter-Efficient Fine-Tuning (PEFT) methods have become crucial for rapidly adapting large language models (LLMs) to downstream tasks. Prefix-Tuning, an early and effective PEFT technique, demonstrated the ability to achieve performance comparable to full fine-tuning with significantly reduced computational and memory overhead. However, despite its earlier success, its effectiveness in training modern state-of-the-art LLMs has been very limited. In this work, we demonstrate empirically that Prefix-Tuning underperforms on LLMs because of an inherent tradeoff between input and prefix significance within the attention head. This motivates us to introduce Prefix-Tuning+, a novel architecture that generalizes the principles of Prefix-Tuning while addressing its shortcomings by shifting the prefix module out of the attention head itself. We further provide an overview of our construction process to guide future users when constructing their own context-based methods. Our experiments show that, across a diverse set of benchmarks, Prefix-Tuning+ consistently outperforms existing Prefix-Tuning methods. Notably, it achieves performance on par with the widely adopted LoRA method on several general benchmarks, highlighting the potential modern extension of Prefix-Tuning approaches. Our findings suggest that by overcoming its inherent limitations, Prefix-Tuning can remain a competitive and relevant research direction in the landscape of parameter-efficient LLM adaptation.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "<dt>\n",
       "<a name=\"item291\">[291]</a>\n",
       "<a href=\"/abs/2506.13754\" id=\"2506.13754\" title=\"Abstract\">\n",
       "        arXiv:2506.13754\n",
       "      </a>\n",
       "          (replaced)\n",
       "\n",
       "        [<a aria-labelledby=\"pdf-2506.13754\" href=\"/pdf/2506.13754\" id=\"pdf-2506.13754\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13754\" href=\"https://arxiv.org/html/2506.13754v2\" id=\"html-2506.13754\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13754\" href=\"/format/2506.13754\" id=\"oth-2506.13754\" title=\"Other formats\">other</a>]\n",
       "    </dt>\n",
       "<dd>\n",
       "<div class=\"meta\">\n",
       "<div class=\"list-title mathjax\"><span class=\"descriptor\">Title:</span>\n",
       "          VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models\n",
       "        </div>\n",
       "<div class=\"list-authors\"><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+E\">Edward Li</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Z\">Zichen Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+J\">Jiahe Huang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Park,+J+J\">Jeong Joon Park</a></div>\n",
       "<div class=\"list-comments mathjax\"><span class=\"descriptor\">Comments:</span>\n",
       "          Project page: <a class=\"link-external link-https\" href=\"https://videopde.github.io/\" rel=\"external noopener nofollow\">this https URL</a>\n",
       "</div>\n",
       "<div class=\"list-subjects\"><span class=\"descriptor\">Subjects:</span>\n",
       "<span class=\"primary-subject\">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)\n",
       "        </div>\n",
       "<p class=\"mathjax\">\n",
       "          We present a unified framework for solving partial differential equations (PDEs) using video-inpainting diffusion transformer models. Unlike existing methods that devise specialized strategies for either forward or inverse problems under full or partial observation, our approach unifies these tasks under a single, flexible generative framework. Specifically, we recast PDE-solving as a generalized inpainting problem, e.g., treating forward prediction as inferring missing spatiotemporal information of future states from initial conditions. To this end, we design a transformer-based architecture that conditions on arbitrary patterns of known data to infer missing values across time and space. Our method proposes pixel-space video diffusion models for fine-grained, high-fidelity inpainting and conditioning, while enhancing computational efficiency through hierarchical modeling. Extensive experiments show that our video inpainting-based diffusion model offers an accurate and versatile solution across a wide range of PDEs and problem setups, outperforming state-of-the-art baselines.\n",
       "        </p>\n",
       "</div>\n",
       "</dd>\n",
       "</dl>\n",
       "<div class=\"paging\">Total of 291 entries \n",
       "    </div>\n",
       "<div class=\"morefewer\">Showing up to 2000 entries per page:\n",
       "          <a href=\"/list/cs.AI/new?skip=0&amp;show=1000\" rel=\"nofollow\">\n",
       "      fewer</a>\n",
       " |\n",
       "          <span style=\"color: #454545\">more</span>\n",
       " |\n",
       "          <span style=\"color: #454545\">all</span>\n",
       "</div>\n",
       "</div>\n",
       "</div> </div>\n",
       "</main>\n",
       "<footer style=\"clear: both;\">\n",
       "<div aria-label=\"Secondary\" class=\"columns is-desktop\" role=\"navigation\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\n",
       "<!-- Macro-Column 1 -->\n",
       "<div class=\"column\" style=\"padding: 0;\">\n",
       "<div class=\"columns\">\n",
       "<div class=\"column\">\n",
       "<ul style=\"list-style: none; line-height: 2;\">\n",
       "<li><a href=\"https://info.arxiv.org/about\">About</a></li>\n",
       "<li><a href=\"https://info.arxiv.org/help\">Help</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"column\">\n",
       "<ul style=\"list-style: none; line-height: 2;\">\n",
       "<li>\n",
       "<svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"></path></svg>\n",
       "<a href=\"https://info.arxiv.org/help/contact.html\"> Contact</a>\n",
       "</li>\n",
       "<li>\n",
       "<svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"></path></svg>\n",
       "<a href=\"https://info.arxiv.org/help/subscribe\"> Subscribe</a>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- End Macro-Column 1 -->\n",
       "<!-- Macro-Column 2 -->\n",
       "<div class=\"column\" style=\"padding: 0;\">\n",
       "<div class=\"columns\">\n",
       "<div class=\"column\">\n",
       "<ul style=\"list-style: none; line-height: 2;\">\n",
       "<li><a href=\"https://info.arxiv.org/help/license/index.html\">Copyright</a></li>\n",
       "<li><a href=\"https://info.arxiv.org/help/policies/privacy_policy.html\">Privacy Policy</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"column sorry-app-links\">\n",
       "<ul style=\"list-style: none; line-height: 2;\">\n",
       "<li><a href=\"https://info.arxiv.org/help/web_accessibility.html\">Web Accessibility Assistance</a></li>\n",
       "<li>\n",
       "<p class=\"help\">\n",
       "<a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg class=\"icon filter-dark_grey\" role=\"presentation\" viewbox=\"0 0 256 512\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"></path></svg></a><br/>\n",
       "                    Get status notifications via\n",
       "                    <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\"><svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"></path></svg>email</a>\n",
       "                    or <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\"><svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\"></path></svg>slack</a>\n",
       "</p>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "</div> <!-- end MetaColumn 2 -->\n",
       "<!-- End Macro-Column 2 -->\n",
       "</div>\n",
       "</footer>\n",
       "</div>\n",
       "<script src=\"/static/base/1.0.1/js/member_acknowledgement.js\"></script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f67061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dt>\n",
      "<a name=\"item1\">[1]</a>\n",
      "<a href=\"/abs/2506.13768\" id=\"2506.13768\" title=\"Abstract\">\n",
      "        arXiv:2506.13768\n",
      "      </a>\n",
      "      \n",
      "        [<a aria-labelledby=\"pdf-2506.13768\" href=\"/pdf/2506.13768\" id=\"pdf-2506.13768\" title=\"Download PDF\">pdf</a>, <a aria-labelledby=\"html-2506.13768\" href=\"https://arxiv.org/html/2506.13768v1\" id=\"html-2506.13768\" rel=\"noopener noreferrer\" target=\"_blank\" title=\"View HTML\">html</a>, <a aria-labelledby=\"oth-2506.13768\" href=\"/format/2506.13768\" id=\"oth-2506.13768\" title=\"Other formats\">other</a>]\n",
      "    </dt>\n"
     ]
    }
   ],
   "source": [
    "dt = None\n",
    "dd = None\n",
    "for dt, dd in zip(soup.select(\"dl > dt\"), soup.select(\"dl > dd\")):\n",
    "    print(dt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc6a0048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/abs/2506.13768'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.find_all(title=\"Abstract\")[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c37ccc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/abs/2506.13768'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urljoin(base_url, dt.find_all(title=\"Abstract\")[0][\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6793c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/pdf/2506.13768'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urljoin(base_url, dt.find_all(title=\"Download PDF\")[0][\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e087b592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Memory States' from Almost Nothing: Representing and Computing in a Non-associative Algebra\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.find(\"div\", class_=\"list-title\").get_text(strip=True).replace(\"Title:\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "756cbc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This note presents a non-associative algebraic framework for the representation and computation of information items in high-dimensional space. This framework is consistent with the principles of spatial computing and with the empirical findings in cognitive science about memory. Computations are performed through a process of multiplication-like binding and non-associative interference-like bundling. Models that rely on associative bundling typically lose order information, which necessitates the use of auxiliary order structures, such as position markers, to represent sequential information that is important for cognitive tasks. In contrast, the non-associative bundling proposed allows the construction of sparse representations of arbitrarily long sequences that maintain their temporal structure across arbitrary lengths. In this operation, noise is a constituent element of the representation of order information, rather than a means of obscuring it. The non-associative nature of the proposed framework results in the representation of a single sequence by two distinct states. The L-state, generated through left-associative bundling, continuously updates and emphasises a recency effect, while the R-state, formed through right-associative bundling, encodes finite sequences or chunks, capturing a primacy effect. The construction of these states may be associated with activity in the prefrontal cortex in relation to short-term memory and hippocampal encoding in long-term memory, respectively. The accuracy of retrieval is contingent upon a decision-making process that is based on the mutual information between the memory states and the cue. The model is able to replicate the Serial Position Curve, which reflects the empirical recency and primacy effects observed in cognitive experiments.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.find(\"p\", class_=\"mathjax\").get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f2fa324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stefan Reimann'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.find(\"div\", class_=\"list-authors\").get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044ed04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定位所有论文条目（arXiv页面使用dl>dt+dd结构组织论文）\n",
    "papers = []\n",
    "for dt, dd in zip(soup.select(\"dl > dt\"), soup.select(\"dl > dd\")):\n",
    "    # 提取链接（dt标签包含链接信息）\n",
    "    links = dt.find_all(\"a\")\n",
    "    html_link = urljoin(base_url, dt.find_all(title=\"Abstract\")[0][\"href\"])\n",
    "    pdf_link = urljoin(base_url, dt.find_all(title=\"Download PDF\")[0][\"href\"])\n",
    "\n",
    "    # 提取标题（dd标签中的.title类）\n",
    "    title = dd.find(\"div\", class_=\"list-title\").get_text(strip=True).replace(\"Title:\", \"\")\n",
    "\n",
    "    # 提取作者信息（dd标签中的.authors类）\n",
    "    authors = dd.find(\"div\", class_=\"list-authors\").get_text(strip=True)\n",
    "\n",
    "    # 提取摘要（dd标签中的.abstract类）\n",
    "    abstract = dd.find(\"p\", class_=\"mathjax\").get_text(strip=True)\n",
    "\n",
    "    papers.append({\n",
    "        \"pdf_url\": pdf_link,\n",
    "        \"html_url\": html_link,\n",
    "        \"authors\": authors,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract\n",
    "    })\n",
    "\n",
    "# 保存为jsonl格式（每行一个JSON对象）\n",
    "with open(\"arxiv_papers.jsonl\", \"w\", encoding=\"utf-8\") as jsonl_file:\n",
    "    for paper in papers:\n",
    "        json.dump(paper, jsonl_file, ensure_ascii=False)\n",
    "        jsonl_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3348c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
